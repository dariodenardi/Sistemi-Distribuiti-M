<div align="center">

# Sistemi Distribuiti M - 2021/2022

Corso tenuto dal _Prof. Foschini_

Appunti scritti da _Dario De Nardi_, _Sofia Montebugnoli_ 

Si ringrazia _Enrico Valastro_ per aver fornito molte immagini e spiegato come realizzarle

[![Dark/Light Mode](https://img.shields.io/badge/Compatible-Dark%26Light%20Mode-1f425f.svg)](https://github.com/settings/appearance)
[![License: CC0-1.0](https://img.shields.io/badge/License-CC0%201.0-blue.svg)](http://creativecommons.org/publicdomain/zero/1.0/)
    
**√à possibile scaricare anche la versione pdf che si trova nella cartella pdf della repo**
    
Questa dispensa ha lo scopo di facilitare lo studio e il superamento dell'esame. Raccoglie tutti gli argomenti trattati (e mal spiegati) con gli appunti presi a lezione
    
Se ritieni di poter migliorare la guida o se hai trovato un errore, visita il repository GitHub e apri un issue o una pull request tramite fork. Ogni contributo √® ben accetto üôÇ
</div>

<!-- INDICE -->
## Indice
- [Modelli](#modelli)
    - [Componente](#componente)
        - [Differenza tra un componente ed un oggetto](#differenza-tra-un-componente-ed-un-oggetto)
    - [Modelli](#modelli-1)
    - [Deployment](#deployment)
    - [Architetture applicazioni Enterprise (1)](#architetture-applicazioni-enterprise-1)
    - [Modelli a contenimento](#modelli-a-contenimento)
    - [J2EE](#j2ee)
    - [Architetture applicazioni Enterprise (2)](#architetture-applicazioni-enterprise-2)
- [EJB 2.X](#ejb-2x)
    - [Scenari applicativi](#scenari-applicativi)
    - [Principi di design](#principi-di-design)
    - [Architettura](#architettura)
    - [JNDI](#jndi)
    - [Contratti](#contratti)
    - [EJB container](#ejb-container)
    - [Tipologie di componenti Bean](#tipologie-di-componenti-bean)
        - [Session Bean](#session-bean)
        - [Entity Bean](#entity-bean)
        - [Message Driven Bean](#message-driven-bean)
    - [Interazioni tra Bean](#interazioni-tra-bean)
    - [Deployment](#deployment-1)
    - [Ciclo di sviluppo](#ciclo-di-sviluppo)
    - [Interfacce EJBHome ed EJBObject](#interfacce-ejbhome-ed-ejbobject)
    - [Invocazione remota](#invocazione-remota)
    - [Invocazione locale](#invocazione-locale)
    - [Cliente](#cliente)
    - [Deployment di un'applicazione](#deployment-di-unapplicazione)
    - [Problemi riscontrati](#problemi-riscontrati)
- [Annotazioni](#annotazioni)
    - [Definizione](#definizione)
    - [Sintassi](#sintassi)
    - [Categorie di annotazioni](#categorie-di-annotazioni)
    - [Annotazioni personalizzate](#annotazioni-personalizzate)
    - [Limiti delle annotazioni personalizzate](#limiti-delle-annotazioni-personalizzate)
    - [Meta-annotazioni](#meta-annotazioni)
    - [Politiche di retention](#politiche-di-retention)
    - [Perch√® usarle](#perch√®-usarle)
- [Servizio di nomi](#sistemi-di-nomi)
    - [Sistemi di Discovery](#sistemi-di-discovery)
    - [Sistemi di Directory](#sistemi-di-directory)
        - [Directory vs DB](#directory-vs-db)
    - [Java Naming Directory Interface (JNDI)](#java-naming-directory-interface-jndi)
    - [Interfaccia Context](#interfaccia-context)
    - [Interfaccia DirContext](#interfaccia-dircontext)
    - [Uso di JNDI](#uso-di-jndi)
    - [Memorizzare i dati in un servizio nomi](#memorizzare-i-dati-in-un-servizio-nomi)
        - [Serializzazione](#serializzazione)
        - [Riferimento](#riferimento)
        - [Attributi](#attributi)
    - [Configurazione di JNDI](#configurazione-di-jndi)
- [EJB 3.X](#ejb-3x)
    - [Annotazioni e Descrittori di Deployment](#annotazioni-e-descrittori-di-deployment)
    - [Tipologie di componenti](#tipologie-di-componenti)
        - [Session Bean](#session-bean-1)
        - [Message Driven Bean](#message-driven-bean-1)
    - [Dependency Injection](#dependency-injection)
    - [Interoperabilit√† tra EJB 3.X e EJB 2.X](#interoperabilit√†-tra-ejb-3x-e-ejb-2x)
    - [Servizi di sistema](#servizi-di-sistema)
        - [Pooling e concorrenza](#pooling-e-concorrenza)
            - [Resource Pooling](#resource-pooling)
            - [Activation](#activation)
        - [Transazionalit√†](#transazionalit√†)
            - [Container-Managed Transaction](#container-managed-transaction)
            - [Bean-Managed Transaction](#bean-managed-transaction)
        - [Gestione delle connessioni a risorse](#gestione-delle-connessioni-a-risorse)
        - [Persistenza](#persistenza)
        - [Messaggistica](#messaggistica)
        - [Sicurezza](#sicurezza)
    - [Intercettori](#intercettori)
- [JPA](#jpa)
    - [Object/Relational Mapping (ORM)](#objectrelational-mapping-orm)
    - [Java Persistence API (JPA)](#java-persistence-api-jpa)
    - [Perch√® usare JPA](#perch√®-usare-jpa)
    - [Entity](#entity)
    - [Ereditariet√† e Polimorfismo](#ereditariet√†-e-polimorfismo)
    - [Strategie di Mapping](#strategie-di-mapping)
    - [Molteplicit√† nelle Relazioni](#molteplicit√†-nelle-relazioni)
    - [Direzionalit√† delle relazioni](#direzionalit√†-delle-relazioni)
    - [Gestione a runtime di Entity](#gestione-a-runtime-di-entity)
        - [Container-managed EntityManager](#container-managed-entity-manager)
        - [Application-managed EntityManager](#application-managed-entity-manager)
    - [Entity Manager singoli vs multipli](#entity-manager-singoli-vs-multipli)
    - [Ciclo di Vita](#ciclo-di-vita)
    - [Unit√† di Persistenza](#unit√†-di-persistenza)
    - [Creazione di Query](#creazione-di-query)
    - [Loading Lazy/Eager](#loading-lazyeager)
    - [Listener di Entity](#listener-di-entity)
    - [Hibernate](#hibernate)
        - [Interfaccia SessionFactory](#interfaccia-sessionfactory)
        - [Interfaccia Session](#interfaccia-session)
        - [Transazioni](#transazioni)
        - [Ciclo di Vita](#ciclo-di-vita-1)
        - [Il caching in Hibernate](#il-caching-in-hibernate)
        - [Fetching dei dati](#fetching-dei-dati)
        - [Query By Examples (QBE)](#query-by-examples-qbe)
- [JMS](#jms)
    - [Perch√® usare un servizio di messagistica](#perch√®-usare-un-servizio-di-messagistica)
    - [Modello point-to-point](#modello-point-to-point)
    - [Modello publish/subscriber](#modello-publishsubscriber)
    - [Affidabilit√† nello scambio di messaggi](#affidabilit√†-nello-scambio-di-messaggi)
    - [Transazionalit√†](#transazionalit√†-1)
    - [Sicurezza](#sicurezza-1)
    - [Java Messaging Service (JMS)](#java-messaging-service-jms)
    - [Tipi di comunicazioni](#tipi-di-comunicazioni)
    - [Messaggi JMS](#messaggi-jms)
    - [Interfaccia Destination](#interfaccia-destination)
    - [Interfaccia ConnectionFactory](#interfaccia-connectionfactory)
    - [Interfaccia Connection](#interfaccia-connection)
    - [Interfaccia Session](#interfaccia-session-1)
    - [Interfacce Message Consumer e Message Producer](#interfacce-message-consumer-e-message-producer)
    - [Riassunto API JMS](#riassunto-api-jms)
    - [Uso di JMS](#uso-di-jms)
    - [Affidabilit√† dei messaggi](#affidabilit√†-dei-messaggi)
    - [ACK](#ack)
    - [Priorit√†](#priorit√†)
    - [Affidabilit√†](#affidabilit√†)
    - [Durable Subscription](#durable-subscription)
    - [Gestione delle transazioni di JMS](#gestione-delle-transazioni-di-jms)
    - [Selettori di messaggi](#selettori-di-messaggi)
    - [JMS in EJB](#jms-in-ejb)
    - [Enterprise Service Bus (ESB)](#enterprise-service-bus-esb)
        - [Service Oriented Architecture (SOA)](#service-oriented-architecture-soa)
        - [Web Services](#web-services)
        - [Web Service Description Language (WSDL)](#web-service-description-language-wsdl)
        - [Enterprise Application Integration (EAI)](#enterprise-application-integration-eai)
        - [Hub-and-Spoke](#hub-and-spoke)
        - [Bus di Interconnessione](#bus-di-interconnessione)
        - [Concetti chiave di ESB](#concetti-chiave-di-esb)
        - [Java Business Integration (JBI)](#java-business-integration-jbi)
 - [CORBA](#corba)
    - [CORBA 2.X](#corba-2x)
    - [CORBA Component Model (CCM)](#corba-component-model-ccm)
    - [Implementazioni CCM disponibili](#implementazioni-ccm-disponibili)
    - [Comparazione CCM vs. EJB e .NET](#comparazione-ccm-vs-ejb-e-net)
    - [Running Example](#running-example)
    - [Componente CCM](#componente-ccm)
    - [Gestione Lifecycle CCM](#gestione-lifecycle-ccm)
    - [CORBA Home](#corba-home)
    - [Configurazione dinamica dei componenti](#configurazione-dinamica-dei-componenti)
    - [Supporto Runtime: Funzionalit√† Component Server](#supporto-runtime-funzionalit√†-component-server)
    - [Executor](#exectutor)
- [Spring](#spring)
    - [Perch√® usare Spring](#perch√®-usare-spring)
    - [Architettura](#architettura-1)
    - [Aspect Oriented Programming (AOP)](#aspect-oriented-programming-aop)
        - [Joinpoint](#joinpoint)
        - [Advice](#advice)
        - [Pointcut](#pointcut)
        - [Aspect](#aspect)
        - [Weaving](#weaving)
        - [Target](#target)
        - [AOP Statico](#aop-statico)
        - [AOP Dinamico](#aop-dinamico)
    - [Dependency Injection](#dependency-injection-1)
        - [Varianti per Dependency Injection](#varianti-per-dependency-injection)
        - [Oggetto BeanFactory](#oggetto-beanfactory)
        - [Injection di valori semplici](#injection-di-valori-semplici)
        - [Injection di un Bean all‚Äôinterno della stessa factory](#injection-di-un-bean-allinterno-della-stessa-factory)
        - [Naming dei Componenti](#naming-dei-componenti)
        - [HelloWorld con dependency injection](#helloworld-con-dependency-injection)
        - [Considerazioni sulla dependency injection](#considerazioni-sulla-dependency-injection)
    - [HelloWorld con AOP](#helloworld-con-aop)
    - [Intercettori](#intercettori-1)
    - [Transazioni verso DB](#transazioni-verso-db)
        - [Lost Update](#lost-update)
        - [Dirty Read](#dirty-read)
        - [Unrepeatble Read](#unrepeatble-read)
        - [Phantom Row](#phantom-row)
        - [Livelli di Isolamenti](#livelli-di-isolamenti)
    - [Transazionalit√†](#transazionalit√†)
    - [Pooling e concorrenza](#pooling-e-concorrenza-1)
    - [Autowiring](#autowiring)
    - [Dependency checking](#dependency-checking)
    - [ApplicationContext](#applicationcontext)
- [JMX](#jmx)
    - [Java Management Extensions (JMX)](#java-management-extensions-jmx)
    - [Architettura](#architettura-2)
    - [Livello instrumentation](#livello-instrumentation)
    - [Livello Agente](#livello-agente)
    - [Livello servizi distribuiti](#livello-servizi-distribuiti)
    - [Standard MBean](#standard-mbean)
    - [Registrazione MBean su Server](#registrazione-mbean-su-server)
    - [Invocazione servizi di gestione](#invocazione-servizi-di-gestione)
    - [Meccanismo di notifica](#meccanismo-di-notifica)
    - [Dynamic MBean](#dynamic-mbean)
    - [ModelMBean](#modelmbean)
    - [Servizi Standard a Livello di Agente](#servizi-standard-a-livello-di-agente)
    - [Servizio di M-let](#servizio-di-m-let)
    - [Servizio di Timer](#servizio-di-timer)
    - [Servizio di Monitoring](#servizio-di-monitoring)
    - [Servizio di Relation](#servizio-di-relation)
    - [JMX remote API](#jmx-remote-api)
    - [Esempio utilizzo degli MBean](#esempio-utilizzo-degli-mbean)
    - [JMX con JBoss/Wildfly](#jmx-con-jbosswildfly)
- [JBoss/WildFly Clustering](#jbosswildfly-clustering)
    - [Architettura JBoss](#architettura-jboss)
    - [JGroups](#jgroups)
    - [HA Partition](#ha-partition)
    - [Load-Balancing](#load-balancing)
    - [JBoss Cache](#jboss-cache)
    - [Infinispan](#infinispan)
    - [Replicazione Stato HTTP](#replicazione-stato-http)
    - [Replicazione Stato EJB](#replicazione-stato-ejb)
    - [Clustering di Componenti EJB](#clustering-di-componenti-ejb)
    - [Configurazione di JBoss/WildFly](#configurazione-di-jbosswildfly)
- [Big Data](#big-data)
    - [Definizione](#definizione-1)
    - [Stream Processing](#stream-processing)
    - [Batch Processing](#batch-processing)
        - [Hadoop Distributed File System (HDFS)](#hadoop-distributed-file-system-hdfs)
        - [MapReduce](#mapreduce)
- [Node.js](#nodejs)
    - [Utilizzo di Javascript](#utilizzo-di-javascript)
    - [Event Loop](#event-loop)
    - [Thread vs Asynchronous Event Driven](#thread-vs-asynchronous-event-driven)
    - [Thread vs Event](#thread-vs-event)
    - [Moduli](#moduli)
        - [Modulo HTTP](#modulo-http)
        - [NPM](#npm)
        - [Modulo FS](#modulo-fs)
        - [Modulo Stream](#modulo-stream)
        - [Modulo Net](#modulo-net)
        - [Modulo Express](#modulo-express)
- [Docker](#docker)
    - [Microservizi](#microservizi)
    - [DevOps](#devops)
    - [Container](#container)
    - [Docker](#docker-1)
    - [Gestione del ciclo di vita del container](#gestione-del-ciclo-di-vita-del-container)
    - [Immagini Docker](#immagini-docker)
- [Kubernates](#kubernetes)
    - [Architettura](#architettura-3)
    - [Etcd](#etcd)
    - [Controller Manager](#controller-manager)
    - [Cloud Controller Manager](#cloud-controller-manager)
    - [Kubelet](#kubelet)
    - [Pod](#pod)
    - [Service](#service)
    - [Kube proxy](#kube-proxy)
    - [Scheduler](#scheduler)
    - [Volumi](#volumi)
    - [Network](#network)
    - [Modello dichiarativo](#modello-dichiarativo)
- [FaaS](#faas)
    - [Serverless come Baas+FaaS](#serverless-come-baasfaas)
    - [Architettura](#architettura-4)
    - [Openwhisk](#openwhisk)
    - [Kantive](#knative)

## Modelli

Nella vita professione, √® molto difficile che si scriva un software da zero per diversi motivi:

- Un'azienda/cliente sta gi√† usando determinate tecnologie e non vuole cambiarle.
- Si vuole interoperare fra diversi ambienti (anche legacy).
- Il tempo di sviluppo √® molto limitato e ci sono vincoli nella consegna dell'applicazione finale.

Per questo motivo √® fondamentale usare un approccio basato su componenti e il trend attuale si sposta verso questo tipo di soluzione.

[Torna all'indice](#indice)

### Componente

Un componente √® un _pezzo di software_ che viene scritto dallo sviluppatore ed ha le seguenti caratteristiche:

- Contiene stato, metodi etc. ma espone verso l'esterno solo quei metodi che si decidono che siano visibili all'esterno grazie all'uso di un'interfaccia.
- Viene eseguito all'interno di un ambiente di esecuzione detto container/engine/middleware.

Esempi di componenti sono quelli che si usano per creare le interfacce grafiche con JavaFX: textBox, label, comboBox etc. Quando si clicca su un bottone, non si verifica se effettivamente il mouse √® sopra al tasto e lo si schiaccia ma si scrive solo il codice che deve essere eseguito se quel determinato evento si verifica.

Tuttavia, il componente del distribuito assume un concetto pi√π ampio rispetto a quello del concentrato:

- Un **componente nel concentrato** √® un componente che fa parte di un'applicazione che viene messa in esecuzione su una **sola** macchina.
- Un **componente nel distribuito** non √® vincolato a trovarsi su una sola macchina proprio per la definizione intrinseca di sistema distribuito. √à possibile spostarlo in qualsiasi momento da un nodo ad un altro. Per questo motivo il componente nel concentrato viene visto come se appartenesse ad un'applicazione _monolitica_.

Il corso si focalizza sui sistemi distribuiti quindi verranno trattati i componenti del secondo punto.

[Torna all'indice](#indice)

#### Differenza tra un componente ed un oggetto

A questo punto ci si domanda che differenza c'√® tra un componente ed un oggetto perch√® sembrano molto simili tra di loro:

- **Uguale all'oggetto**: mantiene dettagli di come √® implementato: stato, metodi etc ed espone solo alcuni dei suoi dettagli tramite l'interfaccia.
- **Diverso dall'oggetto**:
    - Il componente viene eseguito all'interno di un container/engine/middleware altrimenti non verrebbe eseguita la funzione di callback. Se si eseguisse il codice di un componente su una qualsiasi JVM non funzionerebbe. Riprendendo l'esempio di prima: chi √® che controlla che effettivamente il mouse √® posizionato sopra al bottone? Nessuno, quindi il codice non potrebbe funzionare.
    - Il componente √® di dimensioni pi√π grande di un oggetto  in termini di codice, perch√® il costo di overhead tra un'interazione e l'altra √® maggiore. Si ipotizzi che due componenti `A` e `B` interagiscano tra di loro. `A` per comunicare con `B` deve instaurare una connessione, scambiare i dati e alla fine chiuderla. Nel concentrato, invece, gli oggetti anche se sono piccoli e interagiscono spesso fra di loro non hanno questo problema di overhead. Ovviamente bisogna stare attenti a creare un componente non troppo grande per evitare di andare incontro a tutti quei problemi affrontati durante il corso di Ingegneria del Software T come la riusabilit√†.

[Torna all'indice](#indice)

### Modelli

Ogni problema presenta una soluzione diversa. Per capire meglio come risolverli √® importante studiare i modelli. Quelli che possono essere usati sono ad esempio:

- **Statici/dinamici**: l‚Äôuso di modelli statici non permette di adeguare il sistema a fronte di variazioni. I modelli dinamici invece permettono di fare evolvere il sistema a fronte di variazioni ma hanno costi pi√π elevati.
- **Preventivi/reattivi**: un sistema preventivo √® pi√π costoso di un sistema reattivo perch√® non √® detto che un evento si verifichi. Ad esempio, i sistemi operativi non utilizzano sistemi preventivi: se avviene un deadlock tra processi lo si sblocca dall‚Äôesterno tramite linea di comando.

√à meglio una soluzione statica o dinamica? Meglio una soluzione preventiva o reattiva? La risposta in generale che deve fornire un ingegnere √® sempre: _dipende_. Ogni problema ha una storia diversa. Questo perch√® **non** esistono formule precise nei sistemi distribuiti dato che ci sono troppi parametri da prendere in considerazione: famiglia del processore, sistema operativo, linguaggio di programmazione etc.

[Torna all'indice](#indice)

### Deployment

Nei sistemi distribuiti si √® interessati ad eventuali colli di bottiglia, come si comporta l'applicazione quando arrivano molte richieste etc. √à importante, quindi, osservare le performance e per far ci√≤ bisogna mettere in esecuzione l'applicazione. In questo modo si capisce che cosa andare a modificare.

Le modifiche non si effettuano sul codice stesso ma attraverso l'operazione di deployment. Quando si fa questa operazione, occorre decidere dove far eseguire il componente e di quali risorse ha bisogno per funzionare correttamente. Ad esempio, installare tutte le librerie necessarie, copiare i file che devono essere locali, distribuire i componenti su uno o pi√π nodi, mettere davanti un bilanciatore di carico etc.

Ci sono diversi approcci per effettuare il deployment:

- **Manuale**: l‚Äôutente determina ogni singolo oggetto/componente su quale √® il nodo pi√π appropriato.
- **File Script**: si devono eseguire alcuni file di script che racchiudono la sequenza dei comandi per arrivare alla configurazione che presenta le dipendenze.
- **Linguaggi dichiarativi**: supporto automatico alla configurazione attraverso linguaggi dichiarativi o modelli di funzionamento della configurazione da ottenere. Ad esempio, tramite un file .XML e annotazioni.

[Torna all'indice](#indice)

### Architetture applicazioni Enterprise (1)

Le architetture si sono evolute sempre di pi√π verso architetture a pi√π livelli perch√® l'obiettivo √® quello di separare logicamente le funzionalit√† in modo da ridurre la complessit√† degli strati:

- **Single-Tier**: c'√® un singolo super calcolatore a cui sono connessi i clienti perch√® quest'ultimi non hanno abbastanza risorse per fare elaborazione. I clienti (o meglio terminali) inviano solo le richieste al mainfraime il quale le elabora e restituisce al cliente la risposta. √à la soluzione adottata negli anni '50.
<img src="./img/img5-light.png#gh-light-mode-only" alt="Single Tier">
<img class="dark-mode" src="./img/img5-dark.png#gh-dark-mode-only" alt="Single Tier">
    - **Vantaggi**:
        - Nessuna gestione client-side.
        - Consistenza dei dati perch√® tutti i dati sono solo sul calcolatore.
    - **Svantaggi**: no scalabilit√†.

- **Two-Tier**: i clienti interagiscono con il DB, inviano query SQL e ricevono dati raw (dati _grezzi_ cio√® i dati come vengono presi dal DB cos√¨ vengono inviati). La logica di presentazione, di business e di processamento del modello dei dati si trova tutta nell‚Äôapplicazione cliente. Per questo motivo il cliente viene detto _fat_.
<img src="./img/img6-light.png#gh-light-mode-only" alt="Two Tier">
<img class="dark-mode" src="./img/img6-dark.png#gh-dark-mode-only" alt="Two Tier">
    - **Vantaggi**: indipendenza dallo specifico DB (rispetto a single-tier).
    - **Svantaggi**:
        - Difficolt√† di aggiornamento, maintenance e riutilizzo di codice perch√® tutto si trova installato sul lato cliente.
        - Raw data trasferiti verso il cliente (responsabile del loro processamento) e ci√≤ produce overhead di rete perch√® possono essere anche molti i dati.
        - Connessione al DB per ogni cliente e questo ha un forte impatto perch√® i DB relazionali non sono scalabili.

- **Three-Tier**: ci sono diversi modelli:
    - **Three Tier (basato su RPC)**: il cliente, detto _thin client_, ospita solo la logica di presentazione. La logica di business e di processamento dei dati sono delegati ad un livello intermedio. La logica di accesso ai dati √® contenuta nel terzo livello rappresentato dal database. Il middle tier si occupa di tutti i servi di sistema (gestione della concorrenza, multithreading, transazioni, sicurezza, persistenza etc).
    <img src="./img/img8-light.png#gh-light-mode-only" alt="Three Tier">
    <img class="dark-mode" src="./img/img8-dark.png#gh-dark-mode-only" alt="Three Tier">
        - **Vantaggi**: logica di business modificabile in modo pi√π flessibile.
        - **Svantaggi**: accoppiamento stretto fra clienti e middle-tier server. Ad esempio, il cliente deve conoscere IP fisico del server.
    - **Three Tier (basato su Remote Object)**:
    <img src="./img/img9-light.png#gh-light-mode-only" alt="Three Tier RMI">
    <img class="dark-mode" src="./img/img9-dark.png#gh-dark-mode-only" alt="Three Tier RMI">
        - **Vantaggi**: meno accoppiato del modello RPC.
        - **Svantaggi**: gli stessi di quello basato su RPC.
    - **Three Tier (Web Server)**: si ha un browser per il livello presentazione mentre la logica di business √® gestita tramite tecnologie come CGI, Servlet/JSP, ASP etc.
    <img src="./img/img7-light.png#gh-light-mode-only" alt="Three Tier Web">
    <img class="dark-mode" src="./img/img7-dark.png#gh-dark-mode-only" alt="Three Tier Web">
        - **Vantaggi**:
            - Cliente disponibile ovunque.
            - Nessun problema di aggiornamento del software sul client.
        - **Svantaggi**: Il middle tier resta ancora molto complesso: la logica di business deve far fronte alle problematiche specifiche dell‚Äôapplicazione e tutti i servizi di sistema (transazioni, concorrenza, sicurezza etc) sono in un‚Äôunica base di codice. Non c‚Äô√® quindi una separazione netta tra la parte funzionale e quella non funzionale.

Il trend attuale si sposta verso un mondo multi tier che disaccoppia sempre di pi√π i livelli. Come appena visto, il middle tier rimane molto complesso perch√® la parte di logica dell‚Äôapplicazione non √® ancora separata da tutti i servizi di sistema. Questo vuol dire che essi vengono duplicati per ogni applicazione. La soluzione a questa grande problematica consiste nell‚Äôintroduzione di uno strato software ulteriore, il container/engine/middleware, che si faccia carico di tutti servizi non funzionali cio√® non legati alla logica applicativa.

[Torna all'indice](#indice)

### Modelli a contenimento

Sono modelli che si basano sull'uso di un container/engine/middleware che forniscono automaticamente molte delle funzioni per supportare il servizio applicativo verso l‚Äôutente togliendo l'onere al programmatore. Ad esempio, la gestione della concorrenza.

<img src="./img/img4-light.png#gh-light-mode-only" alt="Container">
<img class="dark-mode" src="./img/img4-dark.png#gh-dark-mode" alt="Container">

L‚Äôidea che sta dietro al modello a contenimento √® quella in cui i client non interagiscono direttamente con il componente di interesse ma che passino prima attraverso il container/engine/middleware che in qualche modo facilit√† le operazioni di sistema. Il container al suo interno ospiter√† il componente.

Il container pu√≤ essere implementato in due modi:

- **Soluzioni proprietarie**: questo tipo di soluzione viene implementata in modo proprietario fornendo delle API proprietarie per richiedere le funzionalit√† di sistema. Ad esempio, Tuxedo e .NET.
- **Soluzioni basate su standard aperti**: i servizi di sistema vengono forniti in maniera ben definita in accordo a standard industriali tramite delle API standard. Ad esempio, JEE o J2EE (Java Enterprise Edition).

[Torna all'indice](#indice)

### J2EE

√à un insieme di specifiche le cui implementazioni vengono principalmente sviluppate in linguaggio di programmazione Java. Viene scritta solo la specifica non l‚Äôimplementazione: diversi produttori di software hanno realizzato diverse implementazioni. Per essere JEE compliant, basta che rispettino la specifica. Alcune implementazioni si limitano alla solo specifica, altre aggiungono funzionalit√†.

Esistono diversi software open source, che vengono spesso usati anche in ambiente di produzione come:

- **GlassFish**: √® l'implementazione di riferimento mantenuta da Oracle;
- **WildFly**: precedentemente noto come JBoss.

[Torna all'indice](#indice)

### Architetture applicazioni Enterprise (2)

Le soluzioni attuali come scritto anche in precedenza, si spostano verso questo tipo di architetture:

- **N-tier**: il middle-tier viene spacchettato in due parti:
    - **Server-side presentation**: si occupa della logica di presentazione, fa uso delle JSP e/o delle Servlet.
    - **Server-side business logic**: si occupa della logica applicativa, cio√® al suo interno ci sono i componenti.
    
<img src="./img/img10-light.png#gh-light-mode-only" alt="Multi Tier">
<img class="dark-mode" src="./img/img10-dark.png#gh-dark-mode-only" alt="Multi Tier">

Una delle tecnologie che fa uso di componenti √® EJB. Nei `Capitoli 2` e `Capitolo 5` verr√† approfondita.

[Torna all'indice](#indice)

## EJB 2.X

√à una tecnologia a componenti lato server-side che consente di creare applicazioni distribuite che siano multi-tier, transazionali, portabili, scalabili, sicure, etc.

Sebbene gli EJB portino lato server tutti i benefici del modello a componenti, separando la logica di business e il codice di sistema, non sempre essi si prestano ad essere la soluzione migliore. Il trend attuale si sposta verso altri tipi di tecnologie che verranno approfondite nei capitoli successivi.

[Torna all'indice](#indice)

### Scenari applicativi

I componenti EJB possono essere utilizzati in diverse architetture.

<img src="./img/img34-light.png#gh-light-mode-only" alt="Multi Tier EJB (1)">
<img class="dark-mode" src="./img/img34-dark.png#gh-dark-mode-only" alt="Multi Tier EJB (1)">

Le architetture possibili sono:

- **Modello 2-tier**: il cliente stand-alone, scritto in Java, interagisce direttamente con il database o con un componente EJB.
- **Modello 3-tier**: il client comunica tramite HTML con il server web che comunica a sua volta direttamente con il database oppure, delle applicazioni stand-alone EJB che comunicano direttamente con l‚ÄôEJB server e in ultima istanza con il database.
- **Modello 4-tier**: il client comunica tramite HTML con una parte di presentazione web basata su JSP e Servlet, con il componente EJB e il database con le connessioni al database.

<img src="./img/img11-light.png#gh-light-mode-only" alt="Multi Tier EJB (2)">
<img class="dark-mode" src="./img/img11-dark.png#gh-dark-mode-only" alt="Multi Tier EJB (2)">

La figura precedente pu√≤ essere rappresentata, pi√π nel dettaglio, nel seguente modo: ci sono i vari container, i componenti che vivono all‚Äôinterno di quel container, le parti di supporto cio√® il _run-time environment_ al cui interno ci sono tutte le API standardizzate per gestire per esempio la parte di naming, di transazionalit√†, di messaggistica, di accesso ai database etc. Invece, le frecce rappresentano i protocolli per gestire le interazioni (HTTP, RMI).

[Torna all'indice](#indice)

### Principi di design

I principi di progettazione che sono alla base di questa tecnologia sono i seguenti:

- Le applicazioni EJB e i loro componenti devono essere debolmente accoppiati (loosely coupled). Ad esempio, se si hanno due componenti `A` e `B`, `A` deve chiamare un metodo di `B` non molte volte. Questo perch√® nel distribuito si paga un costo di overhead piuttosto alto. Dall'altra parte, i componenti devono essere portabili da un'applicazione altra, quindi bisogna stare attenti a come si scrive il software altrimenti diventa difficile ricostruire le sue dipendenze quando si decide di usare quel codice in un altro progetto.
- Il comportamento dei componenti EJB √® definito tramite interfacce. Questo concetto non √® assolutamente nuovo perch√® basti pensare alla normale programmazione con gli oggetti.
- Lo sviluppatore **non** deve pensare a come gestire le risorse. Ci pensa tutto il container.
- Le applicazioni EJB sono N-tier.

[Torna all'indice](#indice)

### Architettura

L'immagine di seguito riportata, fa riferimento ad un'architettura three-tier: c'√® un cliente, un server e un database.

<img src="./img/img1-light.png#gh-light-mode-only" alt="Architettura EJB2">
<img class="dark-mode" src="./img/img1-dark.png#gh-dark-mode-only" alt="Architettura EJB2">

√à bene ricordare che la macchina server non √® _pura_ perch√© √® necessario installarci sopra anche un container per far girare l'applicazione costituita da componenti.

Sul'EJB Container non si troveranno solo le istanze che il programmatore ha scritto ma anche altri due oggetti che vengono automaticamente generati dal container:

- **Oggetto EJB Home**: implementa l‚Äôinterfaccia `EJBHome`. √à un proxy che intercetta la chiamata del cliente (la prima volta) e decide quale istanza logica gli deve restituire (una gi√† creata, nuova etc).
- **Oggetto EJB Object**: implementa l‚Äôinterfaccia `EJBObject`. √à un proxy che ha la stessa interfaccia del componente EJB creato dallo sviluppatore. Quando si invoca un metodo, si chiama l'EJB Object che invoca poi a sua volta il metodo del componente scritto dal programmatore.

<img src="./img/img54-light.png#gh-light-mode-only" alt="Esempio Funzionamento EJB">
<img class="dark-mode" src="./img/img54-dark.png#gh-dark-mode-only" alt="Esempio Funzionamento EJB">

Ad esempio, si consideri un'applicazione riguardante una banca dove un utente pu√≤ solo prelevare e depositare soldi:

- **Sviluppatore**: crea solo una classe che chiama `Account`. Al suo interno ci sono i metodi `prelievo()` e `deposito()`. Non bisogna occuparsi dell'allocazione/deallocazione delle istanze, della concorrenza etc ma si scrive il codice come se si avesse solo un cliente. A tutto il resto ci pensa il container. In EJB 2.X ad ogni classe creata, bisogna anche creare due interfacce: `EJBHome` e `EJBObject`.
- **Cliente**: si ipotizzi di avere due clienti: `C1` e `C2` che richiedono tutti di eseguire il metodo `prelievo()`:
    - Quando `C1` fa richiesta, essa passa prima da EJB Home il quale crea un oggetto `O1` che √® l‚Äôistanza dedicata per `C1`. EJB Home restituisce al cliente il riferimento di EJB Object.
    - Adesso, `C1` pu√≤ invocare il metodo `prelievo()` che verr√† eseguito su EJB Object che a sua volta potr√† invocare il metodo dell‚Äôoggetto `O1`.
    - `C2` fa una richiesta. L'oggetto EJB Home potr√† creare un nuovo oggetto `O2` oppure dare il riferimento di `O1` se l'interazione tra `C1` e l'oggetto `O1` √® terminata. Dipende dalla politica adottata dal container.

[Torna all'indice](#indice)

### JNDI

I clienti, ovviamente la prima volta non sanno dove si trova l'oggetto EJB Home. Serve, quindi, un servizio di nomi che svolge appunto questo compito. Ogni sistema di nomi pu√≤ avere delle API diverse per effettuare le operazioni. Per questo motivo, esse sono state standardizzate: in Java viene usata la libreria JNDI che consente di collegarsi a un qualunque servizio di nomi con API standardizzate in modo che se il servizio di nomi cambia, non si modifica il codice sorgente.

[Torna all'indice](#indice)

### Contratti

Esistono due tipi di contratto:

- **Client view contract**: contratto tra cliente e container. Un contratto client view √® costituito da:
    - **Home interface**: proxy che funge da vera e propria factory dato che assegna un'istanza dedicata al cliente. Con Home Interface si intende la `EJBHome`. √à il nome tecnico usato nella documentazione J2EE.
    - **Object interface**: proxy che ha gli stessi metodi di business della classe sviluppata dal programmatore. Con Object Interface si intende la `EJBObject`. √à il nome tecnico usato nella documentazione J2EE.
    - **Identit√† dell'oggetto**: l‚Äôidentificativo √® di fondamentale importanza per il servizio di nomi in modo da poter recuperare l'oggetto EJB Home.
- **Component contract**: contratto tra componente e container. Il contratto serve a:
    - Abilitare le invocazioni dei metodi dei clienti.
    - Implementare le interfacce `EJBHome` e `EJBObject` per ridurre il carico di lavoro da parte dello sviluppatore.
    - Gestisce la persistenza (solo in EJB 2.x, da EJB 3.x la gestione √® diversa).
    - Gestisce tutti i servizi di sistema: sicurezza, transazionalit√† etc.
    - Implementa il meccanismo delle callback: ci sono dei componenti asincroni chiamati Message Driven Bean che vengono attivati solo quando ricevono un determinato messaggio.

[Torna all'indice](#indice)

### EJB container

Come √® stato detto in precedenza, lo sviluppatore si occupa solo di scrivere la logica di business mentre il container si occupa di:

- Generare automaticamente le classi concrete delle interfaccia `EJBHome` e `EJBObject` scritte dallo sviluppatore che deve creare **solo** interfacce.
- Effettuare il binding dell‚Äôoggetto EJB Home presso il servizio di nomi.
- Persistenza.
- Transazionalit√†.
- Gestione lifecycle componenti.
- Connection pooling.
- Threading.
- Sicurezza.

[Torna all'indice](#indice)

### Tipologie di componenti Bean

I componenti possono essere classificati in due categorie:

- **Sincroni**: l'utente si blocca e aspetta la risposta da parte del server. Si classificano ulteriormente in:
    - **Session Bean**: a sua volta esistono due tipi di Session Bean:
        - **Stateful**.
        - **Stateless**.
    - **Entity Bean**: a sua volta esistono due tipi di Entity Bean:
        - **Container Managed Persistence (CMP)**.
        - **Bean Managed Persistence (BMP)**.
- **Asincroni**: l'utente non si blocca e non aspetta la risposta. Esiste un solo tipo di componente che fa parte di questa categoria:
    - **Message Driven Bean**.
    
<img src="./img/img33-light.png#gh-light-mode-only" alt="Componenti EJB2">
<img class="dark-mode" src="./img/img33-dark.png#gh-dark-mode-only" alt="Componenti EJB2">

[Torna all'indice](#indice)

#### Session Bean

Un Session Bean ha le seguenti caratteristiche:

- Viene usato quando bisogna effettuare calcoli computazionali.
- Ogni cliente ha un'istanza dedicata: se un cliente fa due interazioni in due momenti diversi con il server, non √® detto che abbia la stessa istanza fisica ma viene garantito, lo stesso, il corretto funzionamento.
- Short-lived: la vita del Bean √® pari alla vita del cliente o al massimo alla durata della sessione.
- Transient.
- No fault-tollerant: lo stato non sopravvive a crash da parte del server.
- Pu√≤ avere propriet√† transazionali: dipende se il codice fa accesso a un database oppure no.
- Implementa l‚Äôinterfaccia `javax.ejb.SessionBean`.

I Session Bean che esistono sono di due tipi:

- **Stateless**: il componente √® privo di stato. Ad esempio, quando un'azione deve essere idempotente.
- **Statefull**: il componente √® con stato. Ad esempio, quando si aggiungono i prodotti in un carrello di un sito e-commerce.

[Torna all'indice](#indice)

#### Entity Bean

Un Entity Bean ha le seguenti caratteristiche:

- Rappresenta dati che sono memorizzati in un DB.
- L'stanza √® condivisa fra clienti diversi: bisogna immaginare le istanze come una sorta di cache ad oggetti dove esiste solo una copia del dato.
- Long-lived: la vita del Bean √® pari a quella dei dati nel database.
- Persistente.
- Fault-tollerant: il componente sopravvive a crash del server, quindi, se i campi che si trovano all'interno del componente sono cambiati, viene effettuato lo stesso l'allineamento con il DB.
- Sempre transazionale.
- implementa l‚Äôinterfaccia `javax.ejb.EntityBean`.

Gli Entity Bean che esistono sono di due tipi:

- **Container Managed Persistence (CMP)**: persistenza gestita completamente dal container. I requisiti di persistenza specificati interamente nel file di deployment.
- **Bean Managed Persistence (BMP)**: √® responsabilit√† dello sviluppatore la gestione della persistenza. Di conseguenza, il codice diventa molto pi√π complesso.

[Torna all'indice](#indice)

#### Message Driven Bean

Questo Bean verr√† approfondito nel `Capitolo 7`.

[Torna all'indice](#indice)

### Interazioni tra Bean

L‚Äôimmagine seguente mostra come i clienti interagiscono con i Bean e come i Bean stessi interagiscono tra di loro:

<img src="./img/img35-light.png#gh-light-mode-only" alt="Interazioni tra Bean">
<img class="dark-mode" src="./img/img35-dark.png#gh-dark-mode-only" alt="Interazioni tra Bean">

Il cliente interagisce con i Session Bean che realizzano la logica di business della sessione (con stato/senza stato). Se fosse necessario persistere uno stato i Session Bean possono interagire con gli Entity Bean.

[Torna all'indice](#indice)

### Deployment

Il file di deployment fornisce istruzioni al container su come gestire e controllare il comportamento di componenti. Essendo scritto in un linguaggio dichiarativo si possono modificare le politiche rispetto alle funzionalit√† di sistema senza dover ricompilare il tutto. Queste decisioni vengono scritte in modo dichiarativo in un file .XML.

[Torna all'indice](#indice)

### Ciclo di sviluppo

Il ciclo di sviluppo di un‚Äôapplicazione enterprise parte dalla creazione dei Bean da parte del _Component Developer_ che si pu√≤ occupare anche di scrivere il deployment descriptor (o lo far√† un'altra figura professionale dedicata) che in maniera dichiarativa istruir√† il container sui comportamenti da assumere rispetto a tutte quelle funzionalit√† viste in precedenza (sicurezza, concorrenza, scalabilit√† etc). Il _Component Developer_ rilascia, quindi, moduli EJB. I moduli, provvenienti anche da applicazioni diverse, posso essere assemblati insieme dall‚Äô_Application Assembler_ che rilascia un‚Äôapplicazione EJB a cui il _Deployer_ aggiunge il deployment descriptor e poi effettua il deploy in un container EJB.

<img src="./img/img36-light.png#gh-light-mode-only" alt="Ciclo di sviluppo">
<img class="dark-mode" src="./img/img36-dark.png#gh-dark-mode-only" alt="Ciclo di sviluppo">

L'architettura e lo standard consentono di velocizzare lo sviluppo di applicazioni: √® possibile assemblare applicazioni utilizzando e facendo coesistere moduli sviluppati da _vendor_ diversi. Ad esempio:

<img src="./img/img37-light.png#gh-light-mode-only" alt="Applicazione 1">
<img class="dark-mode" src="./img/img37-dark.png#gh-dark-mode-only" alt="Applicazione 1">

Si supponga di avere un produttore di software `A` (vendor A) specializzato nella modellazione e creazione di componenti busta paga che quindi sviluppa il componente `Payroll`, un secondo produttore di software `B` sviluppa altri componenti `Self Service` ed `Employee`, pu√≤ utilizzare il modulo sviluppato dal vendor `A` per assemblare un‚Äôapplicazione in cui il modulo `Payroll` sviluppato da `A` coesista con i moduli sviluppati dal vendor `B`.

<img src="./img/img38-light.png#gh-light-mode-only" alt="Applicazione 2">
<img class="dark-mode" src="./img/img38-dark.png#gh-dark-mode-only" alt="Applicazione 2">

[Torna all'indice](#indice)

### Interfacce EJBHome ed EJBObject

Come detto in precedenza, lo sviluppatore, oltre al componente Java Bean, deve anche creare due tipi di interfacce:

- L'interfaccia `EJBHome`: √® un proxy che intercetta la chiamata del cliente (solo la prima volta) e decide quale istanza dedicata gli deve restituire (una gi√† creata, nuova etc). Al suo interno ci sono i metodi per la creazione, il ritrovamento e la distruzione del Bean. Ad esempio, `create()`, `find()`, `remove()` etc. Tuttavia, il programmatore definisce solo l'interfaccia mentre l'oggetto √® implementato dal container.
- L'nterfaccia `EJBObject`: √à un proxy che ha la stessa interfaccia del componente EJB creato dallo sviluppatore. Quando si invoca un metodo, si chiama l'EJB Object che invoca poi a sua volta il Java Bean. Il programmatore definisce solo l'interfaccia mentre l'oggetto √® implementato dal container. Il cliente ottiene il riferimento di EJB Object attraverso i metodi `create()` o `find()` dell‚Äôinterfaccia EJB Home.

Le interfacce possono essere remote o locali a seconda se la comunicazione del cliente avviene in locale o in remoto.

[Torna all'indice](#indice)

### Invocazione remota

Per prima cosa bisogna implementare le interfacce `EJBHome` e `EJBObject`. Di seguito viene riportato un esempio di come si dovrebbe scrivere queste interfacce:

```java
// EJBHome
package com.ejb_book.interest;

import javax.ejb.*;
import java.rmi.*;

public interface InterestHome extends EJBHome{
    public Interest create() throws CreateException, RemoteException;
}
```

```java
// EJBObject
package com.ejb_book.interest;

import javax.ejb.*;
import java.rmi.*;

public interface Interest extends EJBObject {

    // Calcola l‚Äôinteresse da pagarsi ad un dato proprietario, ad uno  specifico tasso di interesse (percentuale per term)
    public double getInterestOnPrincipal (double principal, double interestPerTerm, int terms) throws RemoteException;
}
```

Dal lato cliente, vengono invocati i metodi di oggetti che si trovano su nodi differenti e necessariamente ci deve essere un meccanismo di comunicazione tra cliente e server.

RMI √® utilizzato per la comunicazione fra cliente e server EJB. Quindi, l'utente non otterr√† l'oggetto EJB Home dal sistema di nomi ma lo stub di EJB Home. Stesso discorso vale per l'EJB Object. In generale, le operazioni RMI sono costose perch√® bisogna effettuare la serializzazione/deserializzazione dei parametri, aprire, trasferire e chiudere una connessione etc.

<img src="./img/img2-light.png#gh-light-mode-only" alt="RMI IIOP">
<img class="dark-mode" src="./img/img2-dark.png#gh-dark-mode-only" alt="RMI IIOP">

I passaggi sono i seguenti:

- **Cliente**:
    - Invoca un metodo dell‚Äôoggetto remoto.
    - Lo stub lato cliente:
        - Intercetta l‚Äôinvocazione di metodo.
        - Effettua il marshalling dei parametri.
        - Effettua la chiamata vera e propria all‚Äôoggetto remoto.
- **Oggetto remoto**:
    - Riceve l‚Äôinvocazione tramite il suo skeleton.
    - Effettua l‚Äôunmarshalling dei parametri.
    - Esegue l‚Äôinvocazione localmente.
    - Effettua il marshalling dei risultati e li invia al cliente.
- **Lo stub lato cliente**:
    - Riceve i risultati.
    - Effettua un marshalling.
    - Restituisce il risultato al programma cliente.

In realt√†, la comunicazione avviene con RMI basato su IIOP e IIOP √® un protocollo di comunicazione del mondo CORBA. C'√® una visione in RMI del mondo CORBA. CORBA consente di comunicare fra client e server scritti in due linguaggi completamente diversi. Idealmente si tiene aperta la possibilit√† di comunicare con mondi che appartengono a linguaggi diversi ma in realt√† √® tutto Java based.

[Torna all'indice](#indice)

### Invocazione locale

Per prima cosa bisogna ricordarsi di implementare le interfacce `EJBLocalHome` e `EJBLocalObject`. Le interfacce locali, si usano quando il cliente esegue sulla stessa JVM del componente EJB di interesse (e del suo container). Ad esempio, quando lo sviluppatore deve testare il codice. Non avrebbe senso pagare i costi di overhead sulla stessa macchina. In questo caso il passaggio dei parametri pu√≤ avvenire tramite riferimento proprio perch√® ci si trova sullo stesso nodo.

Inoltre, c'√® un altro possibile uso delle interfacce locali. Un Session Bean pu√≤ svolgere a sua volta il ruolo di _cliente locale_ verso altri Bean in modo da non pagare ulteriori costi di overhead.

Questa possibilit√† √® stata introdotta a partire da EJB 2.0 anche se alcune implementazioni avevano gi√† adottato delle ottimizzazioni senza che fossero inserite ufficialmente nello standard.

```java
// EJBHome
package com.ejb_book.interest;

import javax.ejb.*;
import java.rmi.*;

public interface InterestLocalHome extends EJBLocalHome {

    public InterestLocal create() throws CreateException;
}
```

```java
// EJBObject
package com.ejb_book.interest;

import javax.ejb.*;
import java.rmi.*;

public interface InterestLocal extends EJBLocalObject {

    // Calcola l‚Äôinteresse da pagarsi ad un dato proprietario, ad uno  specifico tasso di interesse (percentuale per term)
    public double getInterestOnPrincipal (double principal, double interestPerTerm, int terms);

}
```

√à bene ricordare che non √® trasparente passare da `EJBHome` a `EJBLocalHome` perch√® l'interfaccia locale non ha la `RemoteException`.

[Torna all'indice](#indice)

### Cliente

Per interagire con un componente EJB il cliente deve:

- Ottenere l‚Äôoggetto EJB Home (in realt√† un oggetto stub) via JNDI perch√® la comunicazione tra client e server avviene tramite RMI. Quindi, deve:
    - Creare l'oggetto `InitialContext`. Questo oggetto serve per poter cercare sul servizio di nomi.
    - Effettuare la `lookup` sul servizio di nomi tramite JNDI.
    - Effettuare il narrowing: dato che si √® nel mondo Java, si potrebbe usare anche un normale cast ma dato che Java ha la visione del mondo CORBA, si √® deciso di rendere l'uso pi√π generale possibile.
- Dall‚Äôoggetto EJB Home, si invoca la `create()` in modo da ottenere l'istanza dedicata dell'oggetto EJB desiderato. In realt√†, si ottiene un oggetto stub di EJB Object per lo stesso motivo di prima.
- Invocare i metodi di business tramite l‚Äôoggetto EJB Object.
- Effettuare il clean up finale per liberare le risorse. Perch√® occupare un'istanza che non si usa?

```java
public class InterestClient {

    public static void main (String[] args) throws CreateException, RemoteException, NamingException {
    
        // passo 1: ottenere un‚Äôistanza di EJBHome (in realt√† un oggetto
        // stub per l‚Äôoggetto EJBHome) via JNDI
        InitialContext initialContext = new InitialContext();
        Object o = initialContext.lookup("Interest");
        InterestHome interestHome = (InterestHome) PortableRemoteObject.narrow (o, InterestHome.class);

        // passo 2: creare un oggetto EJBObject remoto (in realt√†
        // uno stub all‚Äôoggetto EJBObject remoto
        Interest interest = interestHome.create();

        double principal = 10000.0;
        double rate = 10.0;
        int terms = 10;
        
        System.out.println("Principal = $" + principal);
        System.out.println ("Rate(%) = " + rate);
        System.out.println ("Terms = " + terms);

        // passo 3: invocazione metodi di business
        System.out.println("Interest = $" + interest.getInterestOnPrincipal(principal, rate, terms));
    
        System.out.println("Total = $" + interest.getTotalRepayment(principal, rate, terms));

        // passo 4: clean up
        interest.remove();
    }
}
```

[Torna all'indice](#indice)

### Deployment di un'applicazione

Per effettuare il deployment di un'applicazione EJB sono necessari i seguenti file:

- ***.EAR (Enterprise ARchive)**: √® tutta l'applicazione EJB che si trova lato server. Al suo interno ci sono i seguenti file:
    - ***.WAR (Web ARchive)**: modulo Web (Servlet, JSP etc). √à facoltativo perch√® non √® detto che lo si debba inserire.
    - **EJB-JAR (*.jar)**: modulo EJB al cui interno √® possibile inserire uno o pi√π componenti. In un .EAR ci possono esserci uno o pi√π moduli (dipende da come si organizza il progetto, se provvengono da altri progetti etc). Il file EJB-JAR deve contenere almeno i seguenti file:

        - **Classe Bean**: classe scritta dallo sviluppatore.
        - **Interfaccia EJBHome**: nel modulo verr√† inserita solo l'interfaccia. A tempo di esecuzione poi √® il container ad implementare la classe concreta.
        - **Interfaccia EJBObject**: nel modulo verr√† inserita solo l'interfaccia. A tempo di esecuzione poi √® il container ad implementare la classe concreta.
        - **application.xml**: descrittore di deployment. La visibilit√† √® _locale_ perch√® si limita solo all'interno del modulo.

        Per effettuare il deployment di una applicazione EJB, √® sempre necessario creare un file *.EAR anche se l‚Äôapplicazione prevede un solo modulo EJB-JAR e nessun modulo Web. Tuttavia, alcuni container permettono il deployment diretto del solo modulo EJB-JAR senza dover creare il file *.EAR.

    - **application.xml**: descrittore di deployment. La visibilit√† √® _globale_ paragonato a quello che si trova all'interno di ogni modulo.
- ***.JAR**: cliente EJB. Questo archivio consiste di tutte le classi necessarie per il corretto funzionamento del programma cliente.

[Torna all'indice](#indice)

### Problemi riscontrati

La comunit√† di sviluppatori ha riscrontrato una serie di problemi che sono emersi durante l'uso di questa versione:

- **Il modello di programmazione non sempre naturale**: oltre alla logica di business bisogna anche implementare due interfacce. L'obiettivo √® quello di scrivere in modo molto pi√π simile un componente a come si fa con gli oggetti. Inoltre, bisogna ricordare di configurare il file descriptor che √® un file diverso rispetto a quello in cui si scrive il codice della classe.
- **La lookup dei componenti √® sempre basata su JNDI**: bisogna scrivere codice per cercare il componente prima di poterlo usare. Se non si facesse questa operazione sarebbe pi√π facile la scrittura di codice.
- **Difficolt√† di uso corretto degli Entity Bean (anti-pattern)**: gli oggetti contengono al loro interno sia lo stato che le operazioni su di esso. Gli Entity Bean hanno solo lo stato e non sono orientati a un mondo object oriented. √à vero che alcune volte negli oggetti si inserisce solo lo stato ma non √® detto che sia sempre cos√¨.

Tuttavia, prima di passare a spiegare EJB 3.X, bisogna introdurre prima alcuni concetti. Nel `Capitolo 3` e `Capitolo 4`, si parler√† di annotazioni e di sistema di nomi.

[Torna all'indice](#indice)

## Annotazioni

Le annotazioni sono state gi√† viste sicuramente in altri corsi anche se non si sapeva che si chiamassero in questo modo. Di seguito vengono riportati alcuni esempi:

- `@Overrided`:
    ```java
    @Override
    public String toString() {
        ...
    }
    ```
- `@Deprecated`:
    ```java
    @Deprecated
    public class ExampleClass { ... }
    ```
- `@SuppressWarnings`:
    ```java
    @SuppressWarnings("unchecked")
    public void aMethod() {
        ...
    }
    ```

[Torna all'indice](#indice)

### Definizione

Sono metadati con cui si _decorano_ i metodi, le classi, le interfacce etc. Non modificano il comportamento del codice che lo sviluppatore scrive ma aggiungono solo informazioni che possono essere utili:

- Al compilatore.
- Alla Javadoc.
- A runtime.

Riprendendo le annotazioni scritte all'inizio del capitolo:

- `@Overrided`: serve al compilatore. Se non si mettesse questa annotazione, il codice verrebbe generato lo stesso per√≤ bisogna stare attenti a come si scrive il nome del metodo sia nella classe padre che in quella figlia perch√® se si sbagliasse a scrivere il nome, il metodo non verrebbe sostituito ma aggiunto.
- `@Deprecated`: serve a livello di documentazione per indicare che quel metodo, classe etc √® in disuso.
- `@SuppressWarnings`: serve al compilatore. Se la compilazione presenta dei warning questi vengono trascurati e non mostrati all‚Äôutente.

[Torna all'indice](#indice)

### Sintassi

Le annotazioni sono strutturate nel seguente modo: ci pu√≤ essere solo il nome dell'annotazione o in caso ci fossero dei membri vengono scritti come un insieme di coppie nome=valore. Se il membro √® solo uno, il nome si pu√≤ omettere.

Con **membro** si intende il _parametro di ingresso_ dell'annotazione.

Nel paragrafo della definizione, √® stata usata la parola _decora_ proprio perch√® vengono aggiunte all'esterno del metodo, classe, interfaccia. Ad esempio:

```java
@Override
public String toString() {
    ...
}
```

[Torna all'indice](#indice)

### Categorie di annotazioni

Le annotazioni si possono classificare nel seguente modo:

- **Marker annotation**: non hanno membri. Ad esempio: `@Override`.
- **Single-value annotation**: hanno un solo membro. Ad esempio: `@SuppressWarnings("unchecked")`.
- **Full annotation**: l'annotazione √® formata da piuÃÄ di un membro.
- **Custom annotation**: i programmatori possono crearsi le proprie annotazioni.

[Torna all'indice](#indice)

### Annotazioni personalizzate

Di seguito viene riportato un esempio di come scrivere un'annotazione personalizzata:

```java
public @interface GroupTODO {
    public enum Severity {CRITICAL, IMPORTANT, TRIVIAL} ;
    Severity severity() default Severity.IMPORTANT;
    String item();
    String assignedTo();
}
```

Si noti che le annotazioni personalizzate sono di tipo `@interface`.

Adesso, la si pu√≤ aggiungere, ad esempio, ad un metodo:

```java
@GroupTODO (
    severity = GroupTODO.Severity.CRITICAL;
    item = "Figure out the amount of interest per month"
    assignedTo = "Luca Foschini";
)
public void calculateInterest(float amount, float rate) { ... }
```

Questa annotazione fa parte della categoria delle annotazioni personalizzate e presenta tre membri. Se non fosse stato specificato il membro `severity` il suo valore sarebbe stato `IMPORTANT`.

[Torna all'indice](#indice)

### Limiti delle annotazioni personalizzate

- **Non** si possono avere relazioni di estensione (extends) fra tipi di annotazioni.
- I tipi di ritorno degli eventuali metodi di una annotazioni devono essere: tipi primitivi, String, Class, enum, tipi di annotation o array dei tipi appena elencati.
- Una annotation **non** puoÃÄ lanciare eccezioni ovvero non puoÃÄ avere una _throws clause_.
- **Non** sono permessi _self-reference_. Ad esempio: `AnnotationA` non puoÃÄ contenere un membro di tipo `AnnotationA`.
- **Non** sono permessi _circular-reference_. Ad esempio: `AnnotationA` non puoÃÄ contenere un membro di tipo `AnnotationB` e quest'ultimo di `AnnotationA`.

[Torna all'indice](#indice)

### Meta-annotazioni

Sono annotazioni che si specificano sulle annotazioni che vengono create. Le meta-annotazioni sono:

- `@Target`: specifica il tipo di elemento al quale si puoÃÄ allegare tale tipo di annotazione (campo, metodo, classe, interfaccia etc):

    ```java
    @Target ( { ElementType.METHOD,ElementType.PACKAGE } )
    public @interface ExampleAnnotation { ... }
    ```

- `@Documented`: specifica che le annotazioni di tale tipo faranno parte della Javadoc:

    ```java
    @Documented
    public @interface ExampleAnnotation { ... }
    ```

- `@Inherited`: questo tipo di annotazione funziona **solo** se apposta ad una classe. Il tipo di annotazione verraÃÄ automaticamente ereditato dalle sottoclassi della classe alla quale viene allegata:

    ```java
    @Target ( { ElementType.METHOD,ElementType.PACKAGE } )
    public @interface ExampleAnnotation { ... }
    ```

- `@Retention`: politica di mantenimento in memoria con cui il compilatore e JVM devono gestire le annotazioni:

    ```java
    @Inherited
    public @interface ExampleAnnotation { ... }
    ```

[Torna all'indice](#indice)

### Politiche di retention

I valori che possono essere specificati nell'annotazione `@Retention` sono:

- `@Retention(RetentionPolicy.SOURCE)`: l'annotazione permane solo a livello di codice sorgente. Dunque, non viene memorizzata nel bytecode cio√® nel file .class. Viene utilizzata solo a tempo di sviluppo da parte del compilatore. Ad esempio, l'annotazione `@Override`. Se si confrontasse la dimensione del file in cui l'annotazione √® stata scritta e quello in cui l'annotazione non √® stata scritta, si potrebbe vedere che √® la stessa.
- `@Retention(RetentionPolicy.CLASS)` (default): l'annotazione verraÃÄ registrata nel bytecode ma non verraÃÄ mantenuta dalla JVM a runtime. Dunque, non si pu√≤ usare la reflection ma solo a tempo di caricamento. Ad esempio, si pu√≤ decidere come trattare il caricamento tramite il class loader del bytecode ma poi le annotazioni non si possono sono usate a run-time.
- `@Retention(RetentionPolicy.RUNTIME)`: l'annotazione verraÃÄ registrata nel bytecode e potraÃÄ essere letta a runtime tramite reflection anche dopo il caricamento della classe da parte della JVM. √à utilizzabile anche all‚Äôinterno del codice di supporto/applicativo a tempo di esecuzione, con proprietaÃÄ eventualmente modificabili a runtime.

Le differenze sostanzialmente sono in termini di spazio quando i file vengono caricati in memoria. Nel primo caso, mom rimane nessuna traccia dell'annotazione, nel secondo e terzo si. L'ultimo caso, dato che si usa la reflection, ci sono strutture in pi√π nel file quindi l'occupazione √® maggiore.

[Torna all'indice](#indice)

### Perch√® usarle

Le annotazioni arricchiscono lo spazio concettuale di un linguaggio di programmazione. Consentono di fare programmazione dichiarativa oltre che a quella imperativa perch√® permettono di associare delle informazioni in modo dichiarativo al codice non andando a modificare il comportamento dei metodi, delle classi etc. Ad esempio, quello che viene specificato nel di file di deployment si pu√≤ fare benissimo tramite le annotazioni.

In poche parole, si aggiunge una _parola_ al codice della classe senza cambiare la logica di business.

[Torna all'indice](#indice)

## Sistemi di Nomi

Un servizio di naming √® un sistema che consente di associare ad un nome logico una risorsa (nome fisico, riferimento, oggetto).

Esempi di sistemi di nomi:

- **DNS**: a un nome logico come `https://www.google.com` corrisponde l'IP fisico del server.
- **RMI Registry (RMI)**: al nome logico corrisponde lo stub associato.
- **Portmapper (RPC)**: fornendo il numero di programma viene restituito versione, protocollo e porta.

[Torna all'indice](#indice)

### Sistemi di Discovery

√à una famiglia di sistemi di nomi. Questo sistema viene usato quando un cliente non conosce l'ambiente (piccole dimensioni) per cui viene inviata una richiesta in broadcast in modo da trovare i dispositivi che sono presenti nella rete.
Questo servizio gestisce una piccola quantit√† di nomi e il numero di scritture nella tabella √® molto alto proprio perch√® la ricerca avviene in broadcast.

<img src="./img/img46-light.png#gh-light-mode-only" alt="Servizio di Discovery">
<img class="dark-mode" src="./img/img46-dark.png#gh-dark-mode-only" alt="Servizio di Discovery">

Ad esempio, il Bluetooth usa un protocollo di Discovery.

[Torna all'indice](#indice)

### Sistemi di Directory

√à una famiglia di sistemi di nomi in cui oltre al nome logico vengono memorizzate una serie di attributi (simili ai record di un DB). Gli attributi devono essere accessibili efficientemente in lettura e scalare molto bene su numeri grandi.

<img src="./img/img45-light.png#gh-light-mode-only" alt="Servizio di Directory">
<img class="dark-mode" src="./img/img45-dark.png#gh-dark-mode-only" alt="Servizio di Directory">

Ad esempio, il protocollo LDAP consente di accedere ai laboratori di UNIBO, X.500.

[Torna all'indice](#indice)

#### Directory vs DB

A questo punto, ci si pu√≤ chiedere se le Directory sono dei DB ma la risposta √® no:

- Gli schemi nelle Directory sono prefissati mentre nei DB si devono creare con la progettazione concettuale e logica.
- Nelle Directory, le operazioni sono molto pi√π ottimizzate rispetto al DB perch√® sono pensati come strumenti da usare in ambiente distribuiti.

[Torna all'indice](#indice)

### Java Naming Directory Interface (JNDI)

JNDI √® un'interfaccia standard che consente di accedere in modo uniforme a servizi di naming gi√† esistenti. Dunque, non √® un servizio di nomi ma un'**interfaccia**!

<img src="./img/img3-light.png#gh-light-mode-only" alt="JNDI">
<img class="dark-mode" src="./img/img3-dark.png#gh-dark-mode-only" alt="JNDI">

In questo modo, si pu√≤ cambiare servizio di nomi senza preoccuparsi del codice che viene scritto lato client perch√® basta solo modificare la parte in cui si specifica quale servizio di nomi si sta usando.

[Torna all'indice](#indice)

### Interfaccia Context

`Context` √® l'interfaccia che contiene metodi per aggiungere, cancellare, cercare, ridenominare oggetti di un sistema di nomi. Invece, l'implementazione di `Context` √® `InitialContext`. I metodi che si trovano nell'interfaccia sono i seguenti:

- `bind`: consente di associare ad un nome logico un oggetto. √à importante che il nome non deve essere associato gi√† ad alcun oggetto:

    ```java
    void bind(String stringName, Object object)
    ```

- `rebind`: consente di riassegnare al nome logico un nuovo oggetto:

    ```java
    void rebind(String stringName, Object object)
    ```

- `lookup`: consente di cercare l'oggetto che corrisponde al nome logico dato come parametro di ingresso:

    ```java
    Object lookup(String stringName)
    ```
- `unbind`: consente di togliere dalla tabella la riga che corrisponde:

    ```java
    void unbind(String stringName)
    ```
- `rename`: Consente di cambiare nome logico:

    ```java
    void rename(String stringOldName, String stringNewName)
    ```

- `listBindings`: restituisce tutte le entry che si trovano nel sistema di nomi che fanno matching con la stringa di ingresso. In RMI, non √® possibile avere due entry con lo stesso nome logico ma ci potrebbero essere dei sistemi di nomi che lo consentono:

    ```java
    NamingEnumeration listBindings(String stringName)
    ```

Non a caso, in EJB 2.X prima di trovare un componente sul servizio di nomi, bisogna creare un oggetto `InitialContext`.

[Torna all'indice](#indice)

### Interfaccia DirContext

Per quanto riguarda i servizi di nomi di tipo Directory, non √® possibile usare `Context` perch√® per come √® fatto questo naming service manca la parte relativa agli attributi.
`DirContext` √® la sottoclasse di `Context` ed estende le funzionalit√† standard di naming con altre relative a attributi e ricerche su entry di directory. I metodi che si trovano nell'interfaccia sono i seguenti:

- `bind`: associa un nome a un oggetto e memorizza gli attributi specificati nella entry corrispondente. √à importante che il nome non deve essere associato gi√† ad alcun oggetto:

    ```java
    void bind(String stringName, Object object, Attributes attributes)
    ```

- `rebind`: consente di riassegnare al nome logico un nuovo oggetto:

    ```java
    void rebind(String stringName, Object object, Attributes attributes)
    ```

- `createSubcontext`: crea un sottocontesto, eventualmente con attributi. Bisogna immaginarsi come una cartella del file system. Al suo interno si possono creare altre cartelle:

    ```java
    DirContext createSubcontext(String stringName, Attributes attributes)
    ```

- `getAttributes`: restituisce gli attributi associati con l‚Äôentry specificata:

    ```java
    Attributes getAttributes(String stringName)
    ```

- `getAttributes`: restituisce gli attributi specificati nell‚Äôarray fornito:

    ```java
    Attributes getAttributes(String stringName, String [] rgstringAttributeNames)
    ```

- `modifyAttributes`: modifica gli attributi associati all‚Äôentry specificata. Viene effettuata la stessa operazione su diversi attributi. Operazioni consentite: `ADD_ATTRIBUTE`, `REPLACE_ATTRIBUTE` e `REMOVE_ATTRIBUTE`:

    ```java
    void modifyAttributes(String stringName, int nOperation, Attributes attributes)
    ```

- `modifyAttributes`: modifica gli attributi associati all‚Äôentry specificata. vengono effettuate una serie di operazioni su uno o pi√π attributi. Operazioni consentite: `ADD_ATTRIBUTE`, `REPLACE_ATTRIBUTE` e `REMOVE_ATTRIBUTE`:

    ```
    void modifyAttributes(String stringName, ModificationItem [] rgmodificationitem)
    ```

[Torna all'indice](#indice)

### Uso di JNDI

- Per prima cosa, serve scegliere un naming service provider. Ad esempio, OpenLDAP o un‚Äôaltra implementazione di LDAP. Dopo, bisogna aggiungere il nome del provider all‚Äôinsieme di propriet√† di ambiente in un oggetto `Hashtable`:

    ```java
    Hashtable hashtableEnvironment = new Hashtable();
    hashtableEnvironment.put(Context.INITIAL_CONTEXT_FACTORY, "com.sun.jndi.ldap.LdapCtxFactory");
    ```

- Dopo, bisogna aggiungere ogni informazioni addizionale necessaria al naming provider. Ad esempio, per LDAP, l'URL che identifica il servizio, context radice, nome e password per connessione:

    ```java
    hashtableEnvironment.put(Context.PROVIDER_URL, "ldap://localhost:389/dc=etcee,dc=com");
    hashtableEnvironment.put(Context.SECURITY_PRINCIPAL, "name");
    hashtableEnvironment.put(Context.SECURITY_CREDENTIALS, "password");
    ```

- Si crea l'oggetto `InitialContext`:

    ```java
    Context context = new InitialContext(hashtableEnvironment);
    ```

    Invece, se il servizio di naming √® una Directory si crea un oggetto `InitialDirContext`:

    ```java
    DirContext context = new InitialDirContext(hashtableEnvironment);
    ```

[Torna all'indice](#indice)

### Memorizzare i dati in un servizio nomi

La specifica JNDI non impone ai naming service provider la semantica dell‚Äôoperazione di memorizzazione di un binding: questo dipende dal servizio di nomi specifico che si sta utilizzando. Per memorizzare le risorse un servizio di nomi pu√≤ usare le seguenti semantiche:

- Serializzazione.
- Riferimento.
- Attributi.

[Torna all'indice](#indice)

#### Serializzazione

La semantica serialized data (serializzazione) la si usa per salvare tutto il contenuto dell‚Äôoggetto. Quando si effettua l'operazione di `lookup` si recupera il contenuto dell‚Äôoggetto per copia.

Tuttavia, non sempre una risorsa pu√≤ essere serializabile. Ad esempio, database, file, stampante etc.

[Torna all'indice](#indice)

#### Riferimento

In altri casi, quello che viene salvato √® solo il riferimento ad un oggetto. Quando il cliente fa la `lookup` viene restituito il riferimento a quella risorsa. Spesso, questo √® l‚Äôunico comportamento supportabile dal sistema di nomi.

[Torna all'indice](#indice)

#### Attributi

Non tutti i linguaggi di programmazione conoscono il concetto di oggetto. Per questo motivo, utilizzare la semantica per attributi consente eliminare il mismatch tra linguaggi differenti perch√® il programma userebbe una collezione di attributi.

[Torna all'indice](#indice)

### Configurazione di JNDI

Per accedere a uno specifico naming/directory service, occorre specificare quale service provider utilizzare, quale server etc:

- **Standard**: sono propriet√† indipendenti dal service provider che accomunano tutti i servizi di nomi. Ad esempio, LDAP, RMI etc. Si trovano nel package `java.naming`. Ad esempio, `java.naming.provider.url` o `java.naming.factory.initial`.
- **Service-specific**: propriet√† comuni per tutti i naming service provider a prescindere dall'implementazione specifica, Ad esempio, LDAP. Hanno prefisso `java.naming.service`. Ad esempio, `java.naming.ldap`.
- **Feature-specific**: comuni per tutti naming service provider che implementano una specifica feature. Ad esempio, SASL per autenticazione. Una propriet√† pi√π trasversale che interessa pi√π sistemi di nomi. Hanno prefisso `java.naming.feature`. Ad esempio, `java.naming.security.sasl`.
- **Provider-specific**: specifiche per un determinato naming service provider. Ad esempio, il servizio Sun LDAP ha una propriet√† per abilitare tracing. Ovviamente ha un prefisso unico. Ad esempio, `com.sun.jndi.ldap.trace.ber`.

Come specificare propriet√† di ambiente:

- **Attraverso i parametri di environment**: vengono passati al costruttore di `InitialContext`. Ad esempio, si crea un oggetto `HashTable`.
- **File application resource**: si modifica il file `jndi.properties` che contiene una lista di coppie attributo/valore.
- **Propriet√† di sistema**: una propriet√† di sistema √® una coppia attributo/valore che la Java runtime definisce/usa per descrivere utenti, ambiente di sistema e JVM. Per modificare/aggiungere queste propriet√† si usa la linea di comando.
- **Parametri di applet**: le applet ormai sono in disuso.

Nel caso di propriet√† presenti in pi√π sorgenti, generalmente i valori delle propriet√† sono concatenati in una lista separata da virgole. Se sono presenti pi√π valori per una propriet√† ma ci deve essere solo un valore, viene preso solo primo della lista.

[Torna all'indice](#indice)

## EJB 3.X

A seguito dei problemi elencati nel `Capitolo 2` e per contrastare la tecnologia Spring che stava prendendo piede molto in fretta, √® stata rilasciata una nuova versione.

[Torna all'indice](#indice)

### Annotazioni e Descrittori di Deployment

A partire da EJB 3.X si possono usare le annotazioni al posto del file descriptor e gli sviluppatori le preferiscono decisamente. Tuttavia, si possono continuare ad usare i descrittori.

I descrittori possono essere anche parziali e incompleti (_sparse descriptor_) cio√® si possono specificare una parte tramite annotazioni e l'altra tramite file descriptor. Lo si pu√≤ usare anche per fare override di annotazioni perch√® i descrittori sono prioritari sulle annotazioni.

[Torna all'indice](#indice)

### Tipologie di componenti

In EJB 3.X i componenti sono solo di tipo Session Bean e Message Driven Bean. Gli Entity Bean non sono pi√π gestiti dal container e per gestire la persistenza si usa lo standard JPA. Ci√≤ verr√† approfondito nel `Capitolo 6`.

Per specificare che tipo di componente si vuole usare, si aggiungono al codice le annotazioni `@Stateless`, `@Stateful` e `@MessageDriven` che devono essere specificate all'interno della classe.

[Torna all'indice](#indice)

#### Session Bean

Grazie all'uso delle annotazioni √® possibile riscrivere le interfacce in modo POJI (Plain Old Java Interface) cio√® l'interfaccia viene riscritta in un modo pi√π simile a quello di come viene scritta un'interfaccia _normale_.

```java
@Remote
public interface Payroll {
    public void setTaxDeductions(int empId, int deductions);
}
```

Le annotazioni che si usano sono: `@Remote`, `@Local`, `@WebService`. Come suggeriscono i nomi, `@Remote` viene usata quando il Session Bean √® remoto mentre `@Local` indica che il Session Bean √® locale. I Web Service verranno accennati nel `Capitolo 7`.

Queste annotazioni si possono specificare a livello di classe o di interfaccia. Nell'esempio di sopra, viene inserita a livello di interfaccia mentre di seguito la stessa interfaccia viene scritta senza annotazione perch√® verr√† specificata nella classe che lo sviluppatore andr√† a scrivere:

```java
public interface Payroll {
    public void setTaxDeductions(int empId, int deductions);
}
```

Invece, di seguito √® riportato come un pezzo di codice che mostra come venivano scritte le interfacce in EJB 2.X:

```java
// interfaccia locale di EJBHome
public interface PayrollHome extends javax.ejb.EJBLocalHome {
    public Payroll create() throws CreateException;
}

// interfaccia locale di EJBObject
public interface Payroll extends javax.ejb.EJBLocalObject {
    public void setTaxDeductions(int empId, int deductions);
}
```

Si pu√≤ notare la differenza di scrittura di codice nelle due versioni.

Anche la classe che deve scrivere lo sviluppatore con la logica di Business con l'uso delle annotazioni √® diventata molto pi√π semplice:

```java
@Stateless
public class PayrollBean implements Payroll {

    public void setTaxDeductions(int empId,int deductions) {
        ...
    }

}
```

Si noti la differenza di codice rispetto a EJB 2.X:

```java
public class PayrollBean implements javax.ejb.SessionBean {
    SessionContext cxt;
        
    public void setSessionContext(SessionContext cxt) {
        this.cxt = cxt;
    }

    public void ejbCreate() {...}
    public void ejbActivate() {...}
    public void ejbPassivate() {...}
    public void ejbRemove() {...}
        
    public void setTaxDeductions(int empId, int deductions) {
        ...
    }

}
```

Per definire che tipo di componente si sta usando lo si deve inserire a livello di file descryptor mentre in EJB 3.X basta usare un'annotazione.

[Torna all'indice](#indice)

#### Message Driven Bean

Per quanto riguarda il Message Driven Bean, si deve implementare lo stesso l'interfaccia `jms.MessageListener` come in EJB 2.X e usare l'annotazione `@MessageDriven`:

```java
@MessageDriven
public class PayrollMDB implements javax.jms.MessageListener {
    public void onMessage(Message msg) {
        ...
    }
}
```

[Torna all'indice](#indice)

### Dependency Injection

Le risorse di un Bean sono _iniettate_ dal container. In questo modo lo sviluppatore non ha pi√π visibilit√† delle API JNDI.

Di seguito √® riportato un pezzo di codice di EJB 3.X:

```java
@EJB
ShoppingCart myCart;

...

Collection widgets = myCart.startToShop("widgets");

...
```

Qui √® riportato come bisogna ottenere una risorsa in EJB 2.X:

```java
Context initialContext = new InitialContext();
ShoppingCartHome myCartHome = (ShoppingCartHome) initialContext.lookup("java:comp/env/ejb/cart");
ShoppingCart myCart = myCartHome.create();
// utilizzo del bean
Collection widgets = myCart.startToShop("widgets")

...

// necessario anche il codice per gestire esplicitamente
// l‚Äôeccezione javax.ejb.CreateException
```

La dependency injection viene realizzata sempre tramite annotazioni:

- `@EJB`: utilizzata per indicare interfacce che sono EJB 3.X o per integrare interfacce EJB di versioni precedenti.
- `@PersistenceContext`, `@PersistenceUnit`: utilizzate per l'EntityManager. Si veda `Capitolo 6`.
- `@Resource`: utilizzata per qualsiasi altro riferimento come factory di connessioni, topic/queque, EJBContext, UserTransaction etc.

L'annotazione `@Resource` pu√≤ essere specificata a livello di classe,
metodo o campo.

`@Resource` ha i seguenti membri:

- `name`: nome JNDI della risorsa. L‚Äôelemento `name` √® opzionale per la injection a livello di campo o metodo:
    - **Livello di campo**: nome di default √® il nome del campo qualificato dal nome della classe.
    - **Livello di metodo**: nome di default √® il nome della propriet√† basato sul metodo indicato dal nome della classe.
- `type`: tipo (Java language type) della risorsa. √à determinato da:
    - **Livello di campo**: tipo del campo che l‚Äôannotazione `@Resource` sta decorando.
    - **Livello di metodo**: tipo della propriet√† del componente che l‚Äôannotazione `@Resource` sta decorando.
- `authenticationType`: solo per risorse di tipo connection factory. Pu√≤ avere valore CONTAINER (default) o APPLICATION.
- `shareable`: possibilit√† di condividere la risorsa. Usato solo per risorse che sono istanze di ORB o connection factory.
- `mappedName`: nome non portabile e implementation-specific a cui
associare la risorsa description. Usato tipicamente per riferire la risorsa al di fuori dell‚Äôapplication server.

Pi√π precisamente, il container si occupa dell‚Äôinjection della risorsa nel componente o a runtime o quando esso √® inizializzato in base se l'annotazione viene specificata a livello di campo/metodo o di classe:

- **Campo**: all‚Äôinizializzazione del componente:

    ```java
    public class SomeClass {
        @Resource
        private javax.sql.DataSource myDB;
    }
    ```

- **Metodo**: all‚Äôinizializzazione del componente:

    ```java
    public class SomeClass {
        private javax.sql.DataSource myDB;
            
        ...
            
        @Resource
        private void setmyDB(javax.sql.DataSource ds) {
            myDB = ds;
        }
            
        ... 
            
    }
    ```

- **Classe**: a runtime, by need cio√® solo quando si ha necessit√† di
accedere alla risorsa iniettata:

    ```java
    @Resource(name="myMessageQueue", type="javax.jms.ConnectionFactory")
    public class SomeMessageBean { ... }
    ```

    In questo caso √® obbligatorio utilizzare gli elementi `name` e `type` perch√® altrimenti non si saprebbe a quale campo l'annotazione `@Resource` viene associata.

I vantaggi e gli svantaggi di usare un modo rispetto altro sono:

- **A tempo di all‚Äôinizializzazione**: la risorsa viene istanziata quando viene creata l'istanza, minor tempo ma si occupa pi√π spazio in memoria.
- **A tempo di caricamento**: la risorsa viene iniettata quando l'utente fa la richiesta di ottenere l'istanza dedicata. Ovviamente bisogna aspettare che si risolvano le dipendenze e ci vuole pi√π tempo.

Nel caso di risorse multiple si usa l'annotazione `@Resources` a livello classe:

```java
@Resources({
    @Resource(name="myMessageQueue", type="javax.jms.ConnectionFactory"),
    @Resource(name="myMailSession", type="javax.mail.Session")
})
public class SomeMessageBean { ... }
```

[Torna all'indice](#indice)

### Interoperabilit√† tra EJB 3.X e EJB 2.X

Ovviamente il codice deve essere riutilizzabile per non perdere tutto quello che √® stato prodotto nelle versioni precedenti.

Le nuove applicazioni EJB 3.X possono essere clienti di vecchi Bean:

```java
// Vista cliente da EJB 3.X di un bean EJB 2.X

@EJB
ShoppingCartHome cartHome;

Cart cart = cartHome.create();
cart.addItem(...);
cart.remove();
```

Come si pu√≤ notare dal codice, nell'annotazione EJB √® stato specificato `EJBHome` del componente scritto in EJB 2.X.

Anche i nuovi Bean conformi a EJB 3.X possono essere utilizzati sulle vecchie applicazioni:

```java
// Vista cliente da EJB 2.X di un bean conforme a EJB 3.X

Context initialContext = new InitialContext();
ShoppingCartHome myCartHome = (ShoppingCartHome) initialContext.lookup("java:comp/env/ejb/cart");
ShoppingCart cart = myCartHome.create();
cart.addItem(...);
cart.remove();
```

Le interfacce `EJBHome` e `EJBObject` vengono automaticamente mappate sulla classe del Bean di tipo EJB 3.X.

[Torna all'indice](#indice)

### Servizi di sistema

I servizi di sistema che sono messi a disposizione dell'EJB come visto nel `Capitolo 2` sono molteplici. Di seguito vengono spiegati ad uno ad uno.

[Torna all'indice](#indice)

#### Pooling e concorrenza

La concorrenza viene gestita in modi diversi in base se il componente ha stato oppure no:

- **Resource Pooling:** utilizzata da Session Bean di tipo stateless e dai Message Driven Bean.
- **Activation**: utilizzata da Session Bean di tipo stateful.

[Torna all'indice](#indice)

##### Resource Pooling

L'idea di base √® di evitare di mantenere un'istanza separata di ogni componente EJB per ogni cliente perch√® le richieste potrebbero non essere servite tutte dato che non si possono creare istanze illimitate.

Il ciclo di vita di uno Session Bean stateless viene riassunto nei seguenti stati:

- **No state**: non istanziato; stato iniziale e terminale del ciclo di vita.
- **Pooled state**: istanziato ma non ancora associato ad alcuna
richiesta cliente.
- **Ready state**: gi√† associato con una richiesta EJB e pronto a
rispondere ad una invocazione di metodo.

<img src="./img/img55-light.png#gh-light-mode-only" alt="Resource Pooling">
<img class="dark-mode" src="./img/img55-dark.png#gh-dark-mode-only" alt="Resource Pooling">

Quando arriva una richiesta i passaggi che vengono eseguiti sono i seguenti:

- Quando viene eseguito il deploy dell'applicazione, l'EJB container si accorge che la classe `Pippo` √® stateless perch√® trova la corrispondente annotazione.
- Il container crea un pool di istanze della classe Pippo pari a k. Non c'√® scritto da specifica quanto deve essere k.
- Se ci sono delle dipendenze a livello di classe/metodo, vengono risolte.
- Il cliente `C1` fa una richiesta e arriva al container.
- La specifica non dice come mantenere traccia di quali istanze sono usate e quali no. Un'idea √® quella di usare una tabella con scritto se l'istanza √® assegnata oppure o no. Il container va a vedere nella tabella un'istanza che √® di tipo pooled. Lo stato dell'istanza viene aggiornato a ready e viene eseguito il codice del metodo invocato.
- Alla fine, si libera l'istanza.

Se all'interno della classe √® stata specificata una variabile e il valore cambia, il comportamento diventa impredicibile perch√® alla richiesta successiva non √® detto che il cliente `C1` abbia la stessa istanza. Per mantenere stato si usano i Session Bean di tipo stateful.

Questa politica di gestione si applica anche ai Message-Driven Bean: l'unica differenza che ogni EJB container contiene molti pool, ciascuno dei quali √® composto di istanze, eventualmente di classi Message-Driven Bean diversi, appartenenti per√≤ alla stessa coda. Se si facesse come nei Session Bean di tipo stateless, si potrebbero avere due istanze nello stesso pool che appartengono per√≤ a code diverse e ci sarebbe concorrenza tra di loro.

[Torna all'indice](#indice)

##### Activation

La gestione avviene in due fasi:

- **Passivation**: disassociazione fra l'istanza stateful bean e suo oggetto EJB, con salvataggio dell‚Äôistanza su memoria (serializzazione). Il processo √® del tutto trasparente al cliente.
- **Activation**: recupero dalla memoria (deserializzazione) dello stato dell‚Äôistanza e riassociazione con oggetto EJB.

Nella specifica J2EE, non √® richiesto che la classe di uno stateful Session Bean sia serializzabile. Quindi?
Dipendenza dall‚Äôimplementazione dello specifico vendor e attenzione al
trattamento dei transient...

<img src="./img/img56-light.png#gh-light-mode-only" alt="Activation">
<img class="dark-mode" src="./img/img56-dark.png#gh-dark-mode-only" alt="Activation">

Non si pu√≤ permettere di manterere k istanze occupate senza far niente. Per superare questo problema si cerca di liberare lo stato salvandolo:

- Prima parte uguale come nel resource pooling. Quando viene restituito il risultato l'istanza non pu√≤ essere resa libera perch√® c'√® lo stato del cliente. In Java, basta prendere l'oggetto che rappresenta lo stato, lo si serializza e si salva (passivation).
- A questo punto, quando il cliente fa in seguito di nuovo la richiesta basta recuperare lo stato salvato (activation). Non √® detto che si debba usare la stessa istanza fisica.

In queste due fasi si possono associare anche metodi di callback sui cambi di stato nel ciclo di vita di un Session Bean di tipo stateful. Ad esempio, l‚Äôannotation `@javax.ejb.PostActivate` associa l‚Äôinvocazione del metodo a cui si applica immediatamente dopo l‚Äôattivazione di un‚Äôistanza.
Similmente, `@javax.ejb.PrePassivate` viene attivata prima dell‚Äôazione di passivation. Ad esempio, vengono utilizzati spesso per la chiusura/apertura di connessioni a risorse per gestione pi√π efficiente (a default vengono mantenuti e serializzati nello stato solo i riferimenti remoti ad altri bean, a SessionContext, al servizio EntityManager e all‚Äôoggetto
UserTransaction etc).

[Torna all'indice](#indice)

#### Transazionalit√†

Una transazione √® un insieme di operazioni logiche (query) a cui corrispondono operazioni fisiche di lettura e scrittura sul DB. Le propriet√† che una transazione deve rispettare sono quelle ACID (Atomicity, Consistency, Isolation e Durability) quindi la transazione √® un'unit√† indivisibile di processamento: o termina correttamente (`commit`) oppure no (`rollback`).

Le transazioni possono essere gestite dal container (Container-Managed Transaction) o manualmente dal programmatore (Bean-Managed Transaction).

[Torna all'indice](#indice)

##### Container-Managed Transaction

Le transazioni gestite dal container sono:

- La tipologia di default. Si usa l'annotazione `@TransactionManagement` che pu√≤ avere come membro o `CONTAINER` (default) oppure `BEAN`.
- Transazione associata con l‚Äôintera esecuzione di un metodo: inizio immediatamente prima dell‚Äôinizio dell‚Äôesecuzione del metodo e `commit` immediatamente prima della terminazione del metodo.
- Non si possono utilizzare metodi per gestione delle transazioni che interferiscano con gestione automatica del container. Ad esempio, √® proibito l‚Äôuso di `commit` o `rollback` di `java.sql.Connection`, di `rollback` di `javax.jms.Session` o dell‚Äôintera interfaccia j`avax.Transaction.UserTransaction`.

Per rendere pi√π flessibili le transazioni gestite dal container si usa l'annotazione `@TransactionAttribute`. Ad esempio, si consideri `BeanA` e `BeanB`. Se il `BeanA` invoca un metodo del `BeanB`, a default, viene creata un'unica grande transazione che inizia con il metodo di `BeanA` e termina alla fine quando √® stato eseguito il metodo di `BeanB`. Se si vuole usare un approccio moderno √® necessario rilassare la propriet√† ACID di una transazione cio√® non devono essere tutte sempre rispettate. Per far ci√≤ si cambia valore dell'annotazione: `REQUIRED` (default), `REQUIRES_NEW`, `MANDATORY`, `NOT_SUPPORTED`, `SUPPORTS`, `NEVER`.

<table>
  <tr>
    <th>Attributo</th>
    <th>Transazione lato cliente?</th>
    <th>Transazione lato servitore?</th>
  </tr>
  <tr>
    <td rowspan="2" align="center">Required</td>
    <td>Nessuna</td>
    <td>T2</td>
  </tr>
  <tr>
    <td>T1</td>
    <td>T1</td>
  </tr>
  <tr>
    <td rowspan="2" align="center">RequiresNew</td>
    <td>Nessuna</td>
    <td>T2</td>
  </tr>
  <tr>
    <td>T1</td>
    <td>T2</td>
  </tr>
  <tr>
    <td rowspan="2" align="center">Mandatory</td>
    <td>Nessuna</td>
    <td>Errore</td>
  </tr>
  <tr>
    <td>T1</td>
    <td>T1</td>
  </tr>
  <tr>
    <td rowspan="2" align="center">NotSupported</td>
    <td>Nessuna</td>
    <td>Nessuna</td>
  </tr>
  <tr>
    <td>T1</td>
    <td>Nessuna</td>
  </tr>
  <tr>
    <td rowspan="2" align="center">Supports</td>
    <td>Nessuna</td>
    <td>Nessuna</td>
  </tr>
  <tr>
    <td>T1</td>
    <td>T1</td>
  </tr>
  <tr>
    <td rowspan="2" align="center">Never</td>
    <td>Nessuna</td>
    <td>Nessuna</td>
  </tr>
  <tr>
    <td>T1</td>
    <td>Errore</td>
  </tr>
</table>

Di seguito viene riportata una rappresentazione grafica per fissare meglio i concetti:

- `REQUIRED`:
<img src="./img/img59-light.png#gh-light-mode-only" alt="Required">
<img class="dark-mode" src="./img/img59-dark.png#gh-dark-mode-only" alt="Required">

- `REQUIRES_NEW`:
<img src="./img/img60-light.png#gh-light-mode-only" alt="Requires New">
<img class="dark-mode" src="./img/img60-dark.png#gh-dark-mode-only" alt="Requires New">

- `MANDATORY`:
<img src="./img/img61-light.png#gh-light-mode-only" alt="Mandatory">
<img class="dark-mode" src="./img/img61-dark.png#gh-dark-mode-only" alt="Mandatory">

- `NOT_SUPPORTED`:
<img src="./img/img57-light.png#gh-light-mode-only" alt="Not Supported">
<img class="dark-mode" src="./img/img57-dark.png#gh-dark-mode-only" alt="Not Supported">

- `SUPPORTS`:
<img src="./img/img58-light.png#gh-light-mode-only" alt="Supports">
<img class="dark-mode" src="./img/img58-dark.png#gh-dark-mode-only" alt="Supports">

- `NEVER`:
<img src="./img/img62-light.png#gh-light-mode-only" alt="Never">
<img class="dark-mode" src="./img/img62-dark.png#gh-dark-mode-only" alt="Never">

Se una transazione fallisce bisogna effettuare il `rollback` della transazione. Pu√≤ essere scatenata da due cause:

- Eccezione del sistema. Il container automaticamente lancia il `rollback`.
- Invocando il metodo `setRollBackOnly` di `EJBContext`. `EJBContext` √® un'interfaccia che contente di accedere a molte funzionalit√† del container come chi √® il cliente.

√à bene ricordare che non sempre √® possibile eseguire un `rollback` di una transazione. Si consideri questo semplice esempio: `t1` apre la finestra e dopo viene eseguita `t2` ma fallisce. `t1` deve richiuderla ma per un tempo √® stata aperta. Nessuno pu√≤ garantire che non sia entrato un ladro.

√à possibile invocare anche metodi di `callback` associati alla semantica transazionale tramite l'uso dell'interfaccia `SessionSynchronization`:

- Metodo `afterBegin` invocato dal container immediatamente prima
dell‚Äôinvocazione del metodo di business all‚Äôinterno della transazione.
- Metodo `beforeCompletion` invocato dal container immediatamente prima
del commit della transazione.
- Metodo `afterCompletion` invocato dal container immediatamente dopo il
completamento della transazione (con `commit` o `rollback`).

Un esempio di codice √® riportato di seguito:

```java
import static TransactionAtributeType.*;

@Stateless
@TransactionAttribute(NOT_SUPPORTED)
public class TravelAgentBean implements TravelAgentRemote {

    public void setCustormer(Customer cust) { ... }
    
    @TransactionAttribute(REQUIRED)
    public TicketDO bookPassage(CreditCard card, double price) { ... }
}
```

[Torna all'indice](#indice)

##### Bean-Managed Transaction

La gestione delle transazioni √® a carico dele programmatore, la complessit√† √® molto maggiore ma anche la flessibilit√†. Un esempio di codice √® riportato di seguito:

```java
// EJB 3.0: Bean-managed transaction
@TransactionManagement(BEAN)
@Stateless
public class PayrollBean implements Payroll {

    @Resource UserTransaction utx;
    @PersistenceContext EntityManager payrollMgr;
    public void setTaxDeductions(int empId, int deductions) {

        utx.begin();
        payrollMgr.find(Employee.class, empId).setDeductions(deductions);
        utx.commit();
    }

    ...

}
```

[Torna all'indice](#indice)

#### Gestione delle connessioni a risorse

Un componente pu√≤ avere bisogno di utilizzare altri componenti e risorse come database e sistemi di messaging. In JEE, il ritrovamento delle risorse desiderate √® basato su un sistema di nomi ad alta portabilit√† come JNDI. Se un componente usa l'injection, sar√† il container a utilizzare JNDI per ritrovare la risorsa desiderata e non il componente stesso com‚Äôera prima di EJB 3.X.

In particolare, relativamente a risorse a database si usa la connection pooling: connessioni sono riutilizzabili per ridurre latenza e incrementare prestazioni nell‚Äôaccesso a DB. Si veda l'annotazione `@Resource`.

[Torna all'indice](#indice)

#### Persistenza

Questo Bean verr√† approfondito nel `Capitolo 6`.

[Torna all'indice](#indice)

#### Messaggistica

Questo Bean verr√† approfondito nel `Capitolo 7`.

[Torna all'indice](#indice)

#### Sicurezza

Il container EJB √® anche responsabile nello svolgere azioni di controllo dell‚Äôaccesso sui metodi del Bean cio√® verifica se il cliente ha il diritto di invocare una determinata operazione remota.

Il container EJB basa le sue decisioni di sicurezza sui concetti di realm, utenti, gruppi e ruoli.

<img src="./img/img48-light.png#gh-light-mode-only" alt="Sicurezza EJB">
<img class="dark-mode" src="./img/img48-dark.png#gh-dark-mode-only" alt="Sicurezza EJB">

Il realm √® una collezione di utenti di una singola applicazione (o di un loro insieme), controllati dalla stessa policy di autenticazione.
Possono o meno essere parte dello stesso gruppo. Ad esempio, accesso tramite username e password, firma digitale etc.

Dopo aver definito il realm, l'amministrazione deve definire gli utenti, gruppi e ruoli. Quando un utente si autentica, ad esempio tramite username e password, l'utente viene riconosciuto con quel username. Un utente pu√≤ essere associato ad un gruppo/o pi√π (ma non √® detto). I permessi vengono mappati sui ruoli cio√® il controllo degli accessi avviene su ruoli. Quindi, un utente/i o un gruppo deve essere associato poi ad un ruolo.

La configurazione della sicurezza viene tipicamente svolta a deployment time (derivanti da deployment descriptor e annotazioni).

Le annotazioni pi√π importanti sono:

- `@RolesAllowed`: il valore √® una lista di nomi di ruoli.
- `@PermitAll`: tutti possono accedere al metodo.
- `@DenyAll`: nessuno pu√≤ accedere al metodo (applicabile solo a livello di singolo metodo).
- `@RunAs`: se il metodo invoca un metodo con questa annotazione, cambia il suo ruolo temporaneamente in un altro. Si pensi quando un sistema operativo chiede di passare a privilegi di amministratore.

La determinazione dei ruoli di sicurezza svolta a runtime dal container. Infatti, il container verifica quale ruolo sta coprendo un determinato utente al momento della richiesta. Di seguito viene riportato un esempio di codice:

```java
@Stateless
public PayrollBean implements Payroll {

    public void setBenefitsDeduction(int empId, double deduction) { ... }
    public double getBenefitsDeduction(int empId) { ... }
    public double getSalary(int empid) { ... }

    // setting del salario ha un accesso pi√π restrittivo
    @RolesAllowed("HR_PayrollAdministrator")
    public void setSalary(int empId, double salary) { ... }
}
```

[Torna all'indice](#indice)

### Intercettori

Sono oggetti capaci di interporsi sulle chiamate di metodo o su eventi del ciclo di vita di Session Bean e Message-Driven Bean. Il container si interpone sempre sulle invocazioni dei metodi della logica applicativa. In particolare, si interpongono dopo l'esecuzione di tutti i servizi di sistema e prima dell‚Äôesecuzione del metodo logica applicativa.

L'intercettore √® uno strumento potente ma che bisogna usare con prudenza: cambiare stati, spargere il codice su pi√π metodi, diventa poi difficile controllare il codice. Bisogna stare attenti a mettere il codice di un bean dentro all'intercettore.

Le annotazioni che si usano sono due:

- `@Interceptors`: per associare una classe/metodo di un componente di business alla classe intercettore correlata.
- `@AroundInvoke`: per definire quale metodo della classe intercettore eseguire all‚Äôatto dell‚Äôintercettazione.

```java
//classe Profiler
public class Profiler {

    @AroundInvoke
    public Object profile() throws Exception {

        ...
         
    }
}

...

//classe intercettata
@Interceptors(Profiler.class)
public Objecty m1(...) throws ... { ... }
```

Gli intercettori possono essere definiti:

- **Specificati nel descrittore di deployment**: si applicano a tutti i metodi di business di ogni componente nel file ejb-jar.
- **Intercettori a livello di classe**: si applicano ai metodi di business della classe Bean.
- **Intercettori a livello di metodo**: per determinazioni pi√π fini e anche per fare overriding di associazioni precedenti.

[Torna all'indice](#indice)

## JPA

Una parte rilevante nello sviluppo di ogni applicazione distribuita di livello enterprise si concentra sul layer di persistenza. √à importante poter accedere, manipolare, gestire dati persistenti che tipicamente sono mantenuti in un DB relazionale.

[Torna all'indice](#indice)

### Object/Relational Mapping (ORM)

Mapping O/R si occupa di risolvere il potenziale mismatch fra i dati mantenuti in un DB relazionale e il loro processamento tramite oggetti in esecuzione. Infatti, i database relazionali sono progettati per operazioni di query efficienti su dati di tipo tabellare mentre in Java c'√® la necessit√† di lavorare invece tramite interazione fra oggetti.

[Torna all'indice](#indice)

### Java Persistence API (JPA)

JPA √® la specifica Java standard che consente il supporto al mapping O/R. Le API di persistenza sono state estese per includere anche l‚Äôutilizzo al di fuori di un container EJB. Infatti, ci sono le stesse API per sviluppare applicazioni JSE, Web e EJB.

[Torna all'indice](#indice)

### Perch√® usare JPA

Prima di JPA, il tipico modo per accedere a dati era tramite i metodi Java Data Access Object (DAO). La persistenza e la transazionalit√† sono gestite a livello di programmazione. Ad esempio, per la creazione di un nuovo dato, l‚Äôeliminazione di un dato, la ricerca su chiave primaria.

Di seguito viene riportato il codice per la ricerca di una chiave primaria: 

```java
public SampleDAO samplelookup(String id) {

    Connection c = null;
    PreparedStatement ps = null;
    ResultSet rs = null;
    SampleDAO dao = null;
    try {
        c = getDataSource().getConnection();
        ps = c.prepareStatement("SELECT ...");
        ps.setString(1, id);
        rs = ps.executeQuery();
        if (rs.first()) {
            dao = new SampleDAO(id, rs.getString(2), rs.getString(2));
        }
    }
    catch (SQLException se) {
        throw new SampleDAORuntimeException(se));
    }
    finally {
        if (rs != null) try {rs.close(); } catch (SQLException se) {}
        if (ps != null) try {ps.close(); } catch (SQLException se) {}
        if (c != null) try {c.close(); } catch (SQLException se) {}
    }
    
    return dao;
}
```

Come si pu√≤ vedere la codice, bisogna aprire la connessione, inviare la query e infine si ottengono i risultati. La programmazione risulta essere molto meno intuitiva. Gli svantaggi di usare questo approccio sono:

- No POJO.
- Ogni oggetto apre una connessione.
- Tutto dipende dal Data Source.

[Torna all'indice](#indice)

### Entity

Una Entity √® un oggetto POJO (Plain Old Java Object) e _leggero_ (non un componente pesante) cio√® pu√≤ essere trattato sia all'interno di un container ma anche all'esterno. Non c'√® nessuna necessit√† di implementare interfacce come si far per gli Entity Bean EJB 2.X. Un Entity appartiene a un dominio di persistenza nel senso che rappresenta dati di un DB. In particolare, ogni istanza corrisponde a una riga di una tabella relazionale.

Una classe Entity deve avere le seguenti caratteristiche:

- Ha la annatazione `javafx.persistence.Entity`.
- Avere un costruttore senza argomenti, `public` o `protected` (costruttori aggiuntivi sono ovviamente consentiti).
- Nessun metodo o variabile di istanza persistente deve essere dichiarata `final` perch√® i valori devono essere modificati.
- Le annotazioni di mapping possono essere applicate solo a variabili di istanza o ai metodi `getter` in stile JavaBean. Non si possono utilizzare annotazioni su entrambi i tipi in una singola classe Entity.
- Se una istanza di Entity √® passata per valore (by value) come oggetto detached, ad esempio all‚Äôinterfaccia remota di un altro Session Bean, allora la classe deve implementare l‚Äôinterfaccia `Serializable`.

Per quanto riguarda i campi persistenti:

- Variabili di istanza persistenti devono essere dichiarate `private`.
`protected`, o `package-private`, e possono essere accedute direttamente solo dai metodi della classe dell‚ÄôEntity.
- Tutti i campi non annotati `javax.persistence.Transient` sono gestiti come persistenti verso il DB.
- Per campi persistenti con valori non singoli si usa Java Collection. Ad esempio:

    ```java
    protected Set<Purchase> purchases;
    ```

Invece per le propriet√† persistenti:

- Si devono seguire le convenzioni sui metodi tipiche dei JavaBean cio√® devono avere i metodi `getter` e `setter`: `getProperty()`, `setProperty()`, `isProperty()`. Ad esempio, se √® stata creata la classe `Customer` con propriet√† persistenti, con una variabile di istanza privata chiamata `firstName` di tipo `String`, i metodi saranno:

    ```java
    public String getFirstName() {
        return name;
    }

    public void setFirstName(String firstName) {
        this.firstName = firstName;
    }
    ```

- Per le propriet√† persistenti con valori non singoli si usa Java Collection. Ad esempio:

    ```java
    public Set<Purchase> getPurchases() {
        return purchases;
    }
    ```

Ogni Entity deve avere un identificatore unico perch√® nel mondo relazionale esistono le primary key. La chiave primaria di una Entity pu√≤ essere semplice o composta:

- **Chiave primaria semplice**: si usa l'annotazione `javax.persistence.Id` sulla propriet√† o sul campo che deve ricoprire il ruolo di chiave:

    ```java
    @Entity
    public class Project {
        @Id
        private long id;
     
     ...

    }
    ```
- **Chiave primaria composita**: si usa quando un'entit√† ha pi√π campi o propriet√† come chiave primaria
persistenti. Si usano le annotazioni `javax.persistence.EmbeddedId` oppure `javax.persistence.IdClass`:

    ```java
    @Entity @IdClass(ProjectId.class)
    public class Project {
        @Id
        private int departmentId;
        @Id
        private long projectId;

        ...

    }

    public class ProjectId {
        private int departmentId;
        private long projectId;
    }
    ```
    Quando un'entit√† ha pi√π campi chiave primaria, JPA richiede la definizione di una classe ID _speciale_ collegata alla classe dell'entit√† utilizzando l'annotazione `@IdClass`. La classe ID riflette i campi della chiave primaria e i suoi oggetti rappresentano i valori della chiave primaria. 
    Un modo alternativo per rappresentare una chiave primaria composita consiste nell'utilizzare una classe incorporabile: 

    ```java
    @Entity
    public class Project {
        @EmbeddedId
        private ProjectId id;
     
        ...

    }

    @Embeddable
    public class ProjectId {
        private int departmentId;
        private long projectId;
    }
    ```
    La classe `Project` ha una primary key i cui campi sono _embeddati_ dalla classe `ProjectId`.

Per quanto riguarda la chiave primaria:

- Costruttore di default deve essere `public`.
- Implementare i metodi `hashCode()` e `equals(Object other)`.
- Serializzabile.
- Se la classe contiene campi/propriet√† multiple della classe Entity, nomi e tipi dei campi/propriet√† nella chiave devono fare match con quelli nella classe Entity.

```java
@Entity
public final class LineItemKey implements Serializable {

    public Integer orderId;
    public int itemId;
    
    public LineItemKey() {
    }

    public LineItemKey(Integer orderId, int itemId) {
        this.orderId = orderId;
        this.itemId = itemId;
    }

    public boolean equals(Object otherOb) {
        
        if (this == otherOb) { 
            return true;
        }
        
        if (!(otherOb instanceof LineItemKey)) {
            return false;
        }
        
        LineItemKey other = (LineItemKey) otherOb;
        return ((orderId==null ? other.orderId==null : orderId.equals(other.orderId)) && (itemId == other.itemId));
    }

    public int hashCode() {
        return ((orderId==null?0:orderId.hashCode())^((int) itemId));
    }

    public String toString() {
        return "" + orderId + "-" + itemId;
    } 

}
```

[Torna all'indice](#indice)

### Ereditariet√† e Polimorfismo

In JPA, c'√® il supporto all'ereditariet√† e al polimorfismo. Una classe Entity pu√≤ estendere una classe non-Entity e una classe non-Entity pu√≤ estendere Entity.

Le classi Entity possono essere sia astratte che concrete. Se una query √® effettuata su un Entity astratta, si opera su tutte le sue sottoclassi non astratte.

```java
@Entity
public abstract class Employee {

    @Id
    protected Integer employeeId;
    
    ...

}

@Entity
public class FullTimeEmployee extends Employee {

    protected Integer salary;

    ...

}

@Entity
public class PartTimeEmployee extends Employee {

    protected Float hourlyWage;

}
```

Esiste anche un'altra annotazione `@MappedSuperclass`: lo stato definito in questa classe, √® stato persistente **solo** per le sue classi figlie. Gli oggetti creati dalle classi figlie saranno persistenti ma gli oggetti marcati con `@MappedSuperclass` non sono entit√† persistenti. Questa annotazione evita di creare tabelle inutili quando non servono.

```java
@MappedSuperclass
public class Employee {

    @Id
    protected Integer employeeId;
    
    ...
}

@Entity
public class FullTimeEmployee extends Employee {

    protected Integer salary;
    
    ...
    
}

@Entity
public class PartTimeEmployee extends Employee {

    protected Float hourlyWage;
    
    ...

}
```

[Torna all'indice](#indice)

### Strategie di Mapping

Dato che si √® nel mondo ad oggetti, il provider di persistenza si deve occupare di effettuare il mapping della gerarchia di classi Entity perch√® nel mondo relazionale le tabelle sono piatte ovvero non esiste classe padre e figlia. Si usa l'annotazione `javax.persistence.Inheritance`.

- `InheritanceType.SINGLE_TABLE`: tutte i campi in un'unica tabella con un attributo chiamato discriminator che consente di stabilire il tipo di Entity. Questo pu√≤ servire per risalire alla tipologia dell'oggetto che ci interessa. Scarsa efficienza se abbiamo molti `NULL` nella tabella.
- `InheritanceType.TABLE_PER_CLASS`: ogni tabella ha colonne per ogni propriet√† comprese quelle ereditatte dalle superclassi. Non c'√® bisogno del discriminator e non √® uno schema normalizzato.
- `InheritanceType.JOINED`: ogni tabella ha le colonne con valore con le sole propriet√† definite nella classe specifica ma lo schema √® normalizzato (schema non ridondante). Se bisogna normalizzare i dati non c'√® ridondanza ma dobbiamo effettuare le join. Se la gerarchia √® estesa il costo diventa molto alto.

Il default √® `InheritanceType.SINGLE_TABLE`, usato se l'annotazione `@Inheritance` non √® specificata alla classe radice gerarchia di Entity.

La strategia `TABLE_PER_CLASS` offre una scarsa efficienza nel supporto a relazioni (e query) polimorfiche; di solito richiede query separate per ogni sottoclasse per coprire l‚Äôintera gerarchia.

Invece, utilizzando `JOINED`, ogni sottoclasse ha una tabella separata che contiene i soli campi specifici per la sottoclasse (la tabella non contiene colonne per i campi e le propriet√† ereditati). Buon supporto a relazioni polimorfiche ma richiede operazioni di join (anche multiple) quando si istanziano sottoclassi di Entity (scarsa performance per gerarchie di classi estese). Analogamente, query che intendono coprire l‚Äôintera gerarchia richiedono operazioni di join fra tabelle sottoclassi.

In conclusione, la scelta della strategia ottimale presuppone una buona conoscenza del tipo di query che si faranno sulle Entity.

[Torna all'indice](#indice)

### Molteplicit√† nelle Relazioni

Ci sono quattro tipologie di molteplicit√† che corrispondono a quelle delle relazioni E/R:

- **One-to-one**: ogni istanza di Entity √® associata a una singola istanza di un‚Äôaltra Entity. Si usa l'annotazione `javax.persistence.OneToOne` sul corrispondente campo/propriet√† persistente.
- **One-to-many**: ad esempio un ordine di vendita con associati oggetti multipli. Si usa l'annotazione `javax.persistence.OneToMany`.
- **Many-to-one**: viceversa, uno degli oggetti contenuti nell‚Äôordine di vendita. Si usa l'annotazione `javax.persistence.ManyToOne`.
- **Many-to-many**: so usa l'annotation `javax.persistence.ManyToMany`.

Nel mondo ad oggetti, non si cattura questo aspetto che c'√® nel mondo relazione per cui √® importante aggiungere l'annotazione nella classe Entity che si sta costruendo sopra al campo/propriet√† appropriata:

```java
@OneToMany
public Set<Purchase> getPurchases() {
    return purchases;
}
```

[Torna all'indice](#indice)

### Direzionalit√† delle relazioni

Le relazioni possono essere monodirezionale o bidirezionali. Nella relazione bidirezionale, ogni entit√† ha un campo o una propriet√† che riferisce l‚Äôaltra entit√†. Ad esempio, una classe `Ordine` al cui interno ha un campo che indica gli oggetti dell'ordine e una classe `Oggetto` che al suo interno ha un campo che indica a quale ordine appartiene. Questo tipo di relazioni sono utili in caso di gestione di query da parte del container, per capire se le query possono _navigare_ da un‚Äôentit√† all‚Äôaltra. Ad esempio, utilizzate per capire quali relazioni cancellare. Sembra normale che se si cancella un ordine non venga cancellato chi l'ha fatto ma il contrario. Per questo motivo √® importante stabilire chi √® il proprietario della relazione con il membro `@mappedBy`:

```java
@OneToMany(cascade=REMOVE, mappedBy="customer")
public Set<Order> getOrders() {
    return orders;
}
```

[Torna all'indice](#indice)

### Gestione a runtime di Entity

Le Entity sono gestite da un Entity Manager. Ogni istanza di un EntityManager √® associata ad un contesto di persistenza. Il contesto di persistenza √® una sorta di cache ad oggetti del database che mantiene gli Entity e che sono gestite da un singolo Entity Manager. L‚Äôinterfaccia dell‚ÄôEntity Manager definisce i metodi che sono usati per interagire con il contesto di persistenza (creazione e rimozione di istanze di Entity persistenti, ritrovamento di Entity tramite chiave primaria ed esecuzione di query).

All‚Äôinterno di tale contesto √® come se le Entity avessero con un loro ciclo di vita. Il constesto di persistenza √®, quindi, il luogo dove esistono tutte le istanze Entity.

L‚ÄôEntity Manager pu√≤ essere utilizzato demandando completamente la gestione al container oppure lo si pu√≤ gestire a livello applicativo.

[Torna all'indice](#indice)

#### Container-managed Entity Manager

Il contesto √® automaticamente propagato dal container ai componenti applicativi. L'injection avviene tramite l'annotazione `@PersistenceContext` e viene passato all'Entity Manager. In questo senso, l‚ÄôEntity Manager √® container-managed poich√© il contesto di persistenza √® direttamente passato ai componenti:

```java
@PersistenceContext
EntityManager em;
```

Il tutto √® interlacciato con le transazioni. Le transazioni JTA eseguono generalmente chiamate fra componenti applicativi che, per completare la transazione, devono avere accesso a un contesto di persistenza.

[Torna all'indice](#indice)

#### Application-managed Entity Manager

Il contesto di persistenza non √® propagato ai componenti applicativi e il ciclo di vita delle istanze dell'Entity Manager √® gestito direttamente dall‚Äôapplicazione. Viene usato quando l‚Äôapplicazione necessita di diversi contesti di persistenza e di diverse istanze di Entity Manager correlate. In questo caso, si usa il metodo `createEntityManager()` di `javax.persistence.EntityManagerFactory` per crearsi un Entity Manager:

```java
@PersistenceUnit
EntityManagerFactory emf;
EntityManager em = emf.createEntityManager();
```

[Torna all'indice](#indice)

### Entity Manager singoli vs multipli

Di solito, quando l'applicazione √® semplice e si ha un solo DB si usa un solo Entity Manager. Invece, se l'applicazione √® pi√π complessa si usano molte Entity che fanno parte di DB diversi e di conseguenza servono pi√π Entity Manager. Tuttavia, √® possibile che ci siano Entity Manager multipli verso lo stesso DB per gestire tabelle diverse e di conseguenza avere diversi contesti di persitenza per gestirli in modo diverso e separare i contesti e le diverse transazioni collegate.

[Torna all'indice](#indice)

### Ciclo di Vita

Le Entity vivono all‚Äôinterno di contesti di persistenza e ciascuna di esse pu√≤ avere quattro diversi stati:

<img src="./img/img25-light.png#gh-light-mode-only" alt="Ciclo di Vita Entity">
<img class="dark-mode" src="./img/img25-dark.png#gh-dark-mode-only" alt="Ciclo di Vita Entity">

- **New/transient entity** istanze non hanno ancora identit√† di persistenza e non sono ancora associate ad uno specifico contesto di persistenza.
- **Managed entity**: istanze con identit√† di persistenza e associate con un contesto di persistenza.
- **Detached entity**: istanze con identit√† di persistenza e correntemente
(possibilmente temporaneamente) disassociate da contesti di persistenza.
- **Removed entity**: istanze con identit√† di persistenza, associate con un contesto e la cui eliminazione dalla cache √® stata gi√† schedulata.

Le istanze Entity nello stato new diventano gestite e persistenti se viene invocato il metodo `persist()` o attraverso l‚Äôoperazione `persist()` in cascata da Entity correlate con `cascade=PERSIST` o `cascade=ALL`:

- Se `persist()` √® invocato per una istanza nello stato removed entity, questa ritorna nello stato di managed.
- Se viene fatto su una istanza nello stato detached entity viene restituita l'eccezione `IllegalArgumentException` o fallimento della transazione.

Questo comporta che i dati saranno memorizzati nel DB quando la transazione associata a `persist()` sar√† completata.

```java
@PersistenceContext
EntityManager em;

...

public LineItem createLineItem(Order order, Product product) {

    LineItem li = new LineItem(order, product, quantity);
    order.getLineItems().add(li);
    em.persist(li);

    return li;
}

// persist propagata a tutte le Entity in relazione con
// cascade element = ALL o PERSIST
@OneToMany(cascade=ALL, mappedBy="order")
public Collection<LineItem> getLineItems() {
    return lineItems;
}
```

Dallo stato managed entity, le Entity possono essere rimosse tramite `remove()` o attraverso l'operazione di rimozione in cascata da Entity correlate con `cascade=REMOVE` o `cascade=ALL`:

- Se `remove()` √® invocato su new entity, l'operazione viene ignorata.
- Se `remove()` √® invocato su detached entity viene lanciata l'eccezione `IllegalArgumentException` o fallimento del `commit` della transazione.
- Se `remove()` √® invocato su Entity gi√† in stato di removed l'operazione viene ignorata.

I dati relativi alla Entity sono effettivamente rimossi dal DB solo a transazione completata o come risultato di una operazione esplicita di `flush`:

```java
public void removeOrder(Integer orderId) {
    try {
        Order order = em.find(Order.class, orderId);
        em.remove(order);
    }
}
```

La `refresh()` nello stato managed serve quando si ha la necessit√† di aggiornarne lo stato. Soprattutto in caso di transazioni non ACID. Ad esempio, nel caso di transazioni di tipo mandatory.

Quando lo stato viene persistito con la commit verso il DB, si stacca l‚Äôoggetto dal contesto di persistenza che entra nello stato di detached. Questo pu√≤ portare a stati non significativi.

Quando si lavora con le Entity bisogna verificare sempre che le Entity siano ancora collegate e attive.

Per sincronizzarsi con il DB bisogna effetuare la `commit` della transazione. A quel punto avviene l'allineamento con il DB. Se si ha il cascading attivo o comunque relazioni bidirezionali, la `commit` crea una reazione a catena. Per forzare la sincronizzazione con DB, possibilit√† di invocare il metodo `flush()` (con solito effetto cascade).

[Torna all'indice](#indice)

### Unit√† di Persistenza

L‚Äôunit√† di persistenza √® un concetto legato al deployment in cui viene specificato il database da usare, quali sono gli Entity etc. Definisce l'insieme di tutte le potenziali classi gestite dall‚ÄôEntity Manager in un‚Äôapplicazione. Potenziali perch√® non √® detto che nell'applicazione poi vengono usate davvero le classi che modellano l'Entity. Nel caso del contesto di persitenza, si ragiona in termini di transazioni da effettuare sugli oggetti della cache che poi devono essere persistiti, non in termini di deployment delle classi. Queste due cose sono ortogonali.

Le unit√† di persistenza sono definite all‚Äôinterno di un file XML chiamato
`persistence.xml`, distribuito insieme al file EJB-JAR o WAR, a seconda
dell‚Äôapplicazione sviluppata:

```xml
<persistence>
    <persistence-unit name="OrderManagement">
        <description> Questa unit√† gestisce ordini e clienti</description>
        <jta-data-source>jdbc/MyOrderDB</jta-data-source>
        <jar-file>MyOrderApp.jar</jar-file>
        <class>com.widgets.Order</class>
        <class>com.widgets.Customer</class>
    </persistence-unit>
</persistence>
```

Ad esempio, il file sopra definisce una unit√† di persistenza chiamata `OrderManagement`, che usa una sorgente dati `jdbc/MyOrderDB` che √® _consapevole_ di JTA. Invece, gli Entity sono associati a classi di tipo `Order` e `Customer`.

Gli elementi `jar-file` e `class` specificano le classi relative all‚Äôunit√† di persistenza: classi Entity, Embeddable, e superclassi Mapped. Invece, l‚Äôelemento `jta-data-source` specifica il nome JNDI globale della sorgente dati che deve essere utilizzata dal container.

[Torna all'indice](#indice)

### Creazione di Query

√à possibile creare query invocando i metodi `createQuery()` e `createNamedQuery()` dell'Entity Manager. Le query devono essere conformi alla specifica Java Peristence Query Language e sono scritte con un liguaggio SQL like Java.

Il metodo `createQuery()` permette la costruzione di query dinamiche, ovvero query definite all‚Äôinterno della business logic:

```java
public List findWithName(String name) {

    return em.createQuery(
        "SELECT c FROM Customer c WHERE c.name LIKE :custName")
        .setParameter("custName", name)
        .setMaxResults(10)
        .getResultList();
}
```

Il metodo `createNamedQuery()` si utilizza invece per creare query
statiche, ovvero definite a livello di annotazione tramite `@NamedQuery` ma non sono query compilate prima dell'esecuzione:

```java
@NamedQuery(
    name="findAllCustomersWithName",
    query="SELECT c FROM Customer c WHERE c.name LIKE :custName")
    
    @PersistenceContext
    public EntityManager em;
    
    ...

    customers = em.createNamedQuery("findAllCustomersWithName")
    .setParameter("custName", "Smith")
    .getResultList();
```

I valori in entrambi i casi sono dinamici cio√® dipendono dai valori che le variabili assumono.

Da notare che i _parametri con nome_ sono parametri di query preceduti da `:` e sono legati al valore dal metodo `setParameter()`. Ad esempio, nell'esempio di sopra `:custName`.

[Torna all'indice](#indice)

### Loading Lazy/Eager

Nell'applicazione √® possibile controllare il caricamento dei dati:

- In caso di caricamento **lazy**, le entit√† sono caricate solo nel momento in cui si vanno ad usarle:
    ```
    @OneToMany(cascade=ALL, mappedBy="owner", fetch=EAGER)
    ```
- Se invece si usa il caricamento **eager**, l‚Äôentit√† viene caricata quando √® caricata l‚Äôentit√† padre:
    ```
    @OneToMany(cascade=ALL, mappedBy="owner", fetch=LAZY)
    ```

In generale, si usa eager per realt√† ristrette e lazy in tutti gli altri casi. √à costoso portarsi dietro tutte le relazioni in cascata ma √® utile se vengono sicuramente usate. Bisogna valutare sempre i costi e benefici.

[Torna all'indice](#indice)

### Listener di Entity

Si possono definire listener o metodi di callback che saranno invocati dal provider di persistenza alla transizione fra diversi stati del ciclo di vita delle Entity. Quindi, √® un controllo uteriore per controllare che sia possibile effettuare, ad esempio, la `persist` e cambiare lo stato. L‚Äôobiettivo √® quello di effettuare controlli e aggiornamenti prima o dopo le operazioni che riguardano la persistenza dei dati.

Per usare metodi di callback, occorre annotare i metodi di callback desiderati nella classe della Entity:

```java
@Entity
@EntityListener(com.acme.AlertMonitor.class)
public class AccountBean implements Account {

    Long accountId;
    Integer balance;
    boolean preferred;
    @Transient ClassA obj1;

    public Long getAccountId() { ... }
    public Integer getBalance() { ... }
    public boolean isPreferred() { ... }
    public void deposit(Integer amount) { ... }
    public Integer withdraw(Integer amount) throws NSFException {... }

    @PrePersist
    public void validateCreate() {

        if (getBalance() < MIN_REQUIRED_BALANCE)
            throw new AccountException("Insufficient balance to open an account");
    }

    @PostLoad
    public void adjustPreferredStatus() {
        preferred = (getBalance() >= AccountManager.getPreferredStatusLevel());
    }
}
```

o definirli all‚Äôinterno di una classe listener separata:

```java
public class AlertMonitor {
    @PostPersist
    public void newAccountAlert(Account acct) {
        Alerts.sendMarketingInfo(acct.getAccountId(), acct.getBalance());
    }
}
```

La classe `AccountBean` usa l'annotazione `@EntityListener(com.acme.AlertMonitor.class)` per indicare che la classe `AlertMonitor` contiene metodi di callback (in realt√† solo uno).

[Torna all'indice](#indice)

### Hibernate

Hibernate ha l‚Äôobiettivo di realizzare la persistenza di oggetti POJO passando dal mondo object oriented al mondo relazionale.

L‚Äôarchitettura di Hibernate permette di astrarre dalle API JDBC/JTA sottostanti. Il livello di applicazione pu√≤ essere trasparente a questi dettagli:

<img src="./img/img67-light.png#gh-light-mode-only" alt="Architettura Hibernate">
<img class="dark-mode" src="./img/img67-dark.png#gh-dark-mode-only" alt="Architettura Hibernate">

[Torna all'indice](#indice)

#### Interfaccia SessionFactory

`SessionFactory` √© l'equivalente all'`EntityManagerFactory` di JPA. Consente di creare oggetti `Session` e mantiene le risorse necessarie per cache di primo e secondo livello. Di solito si crea una `SessionFactory` per ogni DB ma niente vieta di creare pi√π `SessionFactory` per un singolo DB.

[Torna all'indice](#indice)

#### Interfaccia Session

La `Session` √® l'analogo dell'`EntityManager` in JPA. Va a gestire il ciclo di vita degli oggetti persistenti e opera da factory per gli oggetti `Transaction` cio√® ogni volta che si vuole lavorare sui dati con semantica transazionale serve ottenere questo oggetto.

[Torna all'indice](#indice)

#### Transazioni

Gli oggetti `Transaction` sono oggetti single-therad che servono ad aprire, chiudere e fare il rollback di una transazione unit√† atomiche astraendo dai dettagli delle librerie e dei framework che si usano. Le transazioni in Hibernate non sono eseguiti, a default, con semantica transazionale quindi ogni volta √® necessario crearsi un oggetto `Transaction`.

[Torna all'indice](#indice)

#### Ciclo di Vita

Gli oggetti si possono trovare in tre possibili stati:

- **transient** non appartiene al contesto di persistenza. Stato transient non √® mai associato a un contesto di persistenza e questo accade quando si definisce un‚Äôistanza fuori da una sessione.
- **persistent** appartiene al contesto di persistenza. Nello stato persistent l‚Äôstanza √® associata a una sessione e il suo stato corrisponde a una riga del DB.
- **detached** √® un istanza che non √® al momento nel contesto di persistenza poich√© √® stata scollegata.

Gli oggetti persistenti sono oggetti per cui si vuole mantenere uno stato persistente e devono essere inseriti in un contesto di persitenza con una `Session` che opera e lavora come una cache. Quando si chiude una sessione gli oggetti diventano detached e possono essere usati sapendo che non c‚Äô√® un collegamento con il DB.

Gli oggetti transient o detached hanno istanze non legate alla sessione. Modificando gli oggetti non si modifica il DB.

[Torna all'indice](#indice)

#### Il caching in Hibernate

In generale, la cache migliora la performance dei sistemi e si accede al database solo se lo stato necessario non √® presente in cache. In Hibernate esistono due livelli di cache: uno associata alla `Session` e uno associata alla `SessionFactory`. Le cache di primo livello √® usata da Hibernate all‚Äôinterno dei confini di una singola transazione principalmente al fine di ridurre il numero di query SQL generate all‚Äôinterno di una transazione. Ad esempio, se un oggetto √® modificato diverse volte all‚Äôinterno della medesima transazione, Hibernate genera un unico statement SQL UPDATE alla fine della transazione, con tutte le modifiche. Invece, la cache di secondo livello, mantiene dati a livello di `SessionFactory`, utilizzabili da diverse transazioni.

<img src="./img/img70-light.png#gh-light-mode-only" alt="Caching Hibernate">
<img class="dark-mode" src="./img/img70-dark.png#gh-dark-mode-only" alt="Caching Hibernate">

Dalla `SessionFactory` si crea un oggetto `Session`. Un primo componente `C1` si crea il proprio oggetto `Session` e lavora sulla cacha di primo livello `L1_1`. La `Session` fa una find di un dato del DB. La cache all'inizio √® vuota. Il layer di persistenza prende il dato dal DB e carica in cache l'oggetto `O1`. Non viene fatta una copia solo nella cache di primo livello, ma viene fatta una copia anche nella cache di secondo livello. Un secondo componente `C2` crea dalla stessa `SessionFactory` un nuovo oggetto `Session` e lavora sulla cache di primo livello `L1_2`. Il secondo componente non trova l'oggetto `O1` nella propria cache di primo livello `C1` ma lo trova nella cache di secondo livello `L2` e se lo porta nella propria cache di primo livello una copia di `O1` senza andare su DB.

In lettura, non ci sono problemi mentre in scrittura ci possono essere alcuni problemi. Ci sono diverse istanze dell‚Äôoggetto persistente nella cache di primo livello. Se il componente `C2` modifica l'oggetto `O1`, si ha un disallineamento perch√® la sua copia √® diversa rispetto a quella che si trova nella cache `C1` mentre in quella di secondo livello viene aggiornata.

Per l‚Äôinvalidazione della cache si usa una strategia ottimistica poich√© si assume che la maggior parte delle transazioni verso il DB non sono in conflitto con le altre transazioni. In caso di collisioni, si effettua un versioning dei dati. Si inserisce nella tabella del database una colonna in pi√π che si indica con l'annotazione `@Version`:

```java
@Entity
@Table(name = "orders")
public class Order {
    @Id private long id;
    @Version private int version;
    private String description;
    private String status;
    
    ...

}
```

Questo numero viene gestito in modo automatico dal layer di persistenza anche se si perde un p√≤ di trasparenza dato che nella tabella del DB ci sar√† una colonna in pi√π. Ogni volta che avviene una scrittura sul record del DB viene aggiornato questo valore:

```sql
update orders set description=?, status=?, version=? where id=? and
version=?
```

In questo modo, si eliminano i problemi di inconsistenza. Ad esempio, ci sono due utenti (Bob e Alice) che hanno sessioni diverse ma che condividono la cache di secondo livello. Alice decide di approvare l‚Äôordine per cui lo stato √® aggiornato sul DB. Il fatto di persistere l‚Äôaggiornamento del dato incrementa version counter a 2:

```sql
update orders set description=?, status=?, version=2 where id=? and
version=1
```

Nel frattempo Bob, ad esempio nella sua GUI, ha ancora la vecchia versione dei dati (version=1). Quando lancia un update all‚Äôordine, la query eseguita risulta essere:

```sql
update orders set description=?, status=?, version=2 where id=? and
version=1
```

Il risultato √® che questa seconda update non fa match con alcuna riga (no match con clausola WHERE). Hibernate lancia una eccezione `org.hibernate.StaleObjectStateException`. Risultato √® che Bob non pu√≤ effettuare update fino a che non ha rinfrescato la sua vista dati. Ovviamente sta al programmatore gestire opportunamente l'eccezione a livello applicativo.

Nelle ultime versioni di JPA c‚Äô√® la possibilit√† di versioning.

[Torna all'indice](#indice)

#### Fetching dei dati

Per fare fetching (cio√® caricare i dati dal DB alla memoria) si possono usare varie stretegie che si indicano a priori nel file di mapping o successivamente nelle query con override. Quindi, anche in Hibernate si possono fare caricamenti pi√π eager o pi√π lazy che impatteranno sulla cache di primo e di secondo livello, √® il programmatore che decide se fare un caricamento pi√π aggressivo o pi√π pigro. Si specifica con un parametro chiamato `FetchMode` e le modalit√† di fetching sono:

- `FetchMode.DEFAULT`: `FetchMode` √® presa del file di configurazione.
- `FetchMode.JOIN`: Hibernate recupera i dati associati, anche collezioni, utilizzando un outer join all‚Äôinterno della stessa select.
- `FetchMode.SELECT`: Hibernate effettua una seconda select separata per recuperare le entity o collection associate. Lazy fetching √® il default: la seconda select viene eseguita solo quando l‚Äôapplicazione accede veramente ai dati associati.

Usare una strategia di fetching rispetto ad un'altra ha ovviamente impatto sulle performance ottenibili.

[Torna all'indice](#indice)

#### Query By Examples (QBE)

Lo stile √® drasticamente differente da SQL per la ricerca di dati nel DB. L'idea di base √® quella di effettuare una ricerca di tipo associativa:

- Popolare parzialmente una istanza di un oggetto.
- Permettere a Hibernate di costruire trasparentemente un criterio di
scelta (criteria) usando l‚Äôistanza come esempio.

```java
// cerca gli oggetti persona tramite un oggetto di esempio
Criteria crit = sess.createCriteria(Person.class);
Person person = new Person();
person.setName("Shin");
Example exampleRestriction = Example.create(person);
crit.add(exampleRestriction);
List results = crit.list();
```

Si va quindi a costruire i criteri riempiendoli con elementi che rendono la ricerca associativa in modo trasparente cercando nel database tuple che facciano match. Il programmatore in questo modo non deve conoscere il linguaggio SQL e pu√≤ effettuare ricerche in modo trasparente attraverso il framwork stesso.

[Torna all'indice](#indice)

## JMS

Prima di parlare dello standard JMS, si vedono quali sono le caratteristiche generali di un servizio di messaggistica.

### Perch√® usare un servizio di messagistica

L‚Äôimportanza dei sistemi di messaging √® dovuto principalmente alla comunicazione disaccoppiata (loosely coupled) e asincrona ( = sincrono non bloccante). I messaggi sono lo strumento principale di comunicazione fra le applicazioni (modello a scambio di messaggi). Il software di supporto allo scambio di messaggi fornisce tutte le funzionalit√† necessarie e prende il nome di Message Oriented Middleware (MOM)/Messaging system/ Messaging server/Messaging provider/JMS provider.

I vantaggi del MOM sono l‚Äôindipendenza rispetto al dove si sta lavorando e rispetto alla locazione di rete. In particolare, non c‚Äô√® pi√π l‚Äôassunzione che il cliente conosca la locazione del servitore. Nel modello client-server, il client conosce la locazione del servitore ma questo non avviene nei MOM: √® il sistema di messaggistica che si occupa di smistare i messaggi verso il destinatario consentendo il completo disaccoppiamento. Il disaccoppiamento avviene sia nello spazio, ovvero non bisogna pi√π conoscere la locazione del destinatario, sia nel tempo, ovvero non devono essere online entrambe le entit√† contemporaneamente.

I vantaggi dal punto di vista architetturale in un‚Äôapplicazione distribuita di grandi dimensioni sono:

- La **scalabilit√†** ovvero la capacit√† di gestire un numero elevato di clienti. Se si vuole ottenere scalabilit√†, basta incrementare solo le capacit√† hardware del sistema di messaging senza effettuare cambiamenti nella logica applicativa, nell‚Äôarchitettura in modo da non avere un grosso degrado nel throughput di sistema.
- La **robustezza** ovvero i consumatori, i produttori e la rete possono avere un fault senza problemi. Quindi, grazie al MOM se avvengono dei fault in diversi punti del sistema, nelle altre isole del sistema il resto pu√≤ continuare a funzionare.

Tra gli esempi di sistemi di messaging ci sono le transazioni commerciali che usano carte di credito, i report con previsioni del tempo, i workflow, la gestione di dispositivi di rete, la gestione di supply chain, il customer care, ma soprattutto vengono usati nelle architetture distribuite e cloud a tutti i livelli (dai livelli pi√π bassi fino al livello applicativo).

Si possono avere due modelli di messaging:

- point-to-point;
- publish subscribe.

Le principali caratteristiche sono:

- affidabilit√†;
- operazioni con logica transazionale, ovvero trattano lo scambio di messaggi come transazione con la possibilit√† eventuale di persistere i messaggi;
- messaging pu√≤ essere distribuito;
- sicurezza.

I MOM poi possono supportare altre funzionalit√† come la qualit√† dei canali, transazioni sicure, auditing, load balacing etc.

[Torna all'indice](#indice)

### Modello point-to-point 

La comunicazione avviene tra due sole entit√†. Questo modello viene utilizzato quando il produttore vuole contattare solo il proprio consumatore. Ci possono essere produttori multipli, ovviamente, ma il messaggio verr√† ricevuto solo da un destinatario. La destinazione di un messaggio da parte del produttore √® una coda con nome named queue. Le code sono FIFO (per lo stesso livello di priorit√†) oppure i produttori inviano messaggi a named queue specificando un livello di priorit√† desiderato. Questo ovviamente introduce attese ma consente la priorit√†. Possono essere anche organizzate a tuple (argomenti) o guardando il payload dei messaggi con l‚Äôutilizzo di filtri per smistare i messaggi.

<img src="./img/img12-light.png#gh-light-mode-only" alt="Point-to-Point">
<img class="dark-mode" src="./img/img12-dark.png#gh-dark-mode-only" alt="Point-to-Point">

Ad esempio, questo modello serve per far parlare dei dispositivi mobili, con molte disconnessioni che appaiano e scompaiono, nel servizio, ovvero quando vi √® la necessit√† di disaccoppiare molto, il MOM si comporta come proxy che mantiene i messaggi e in un caso, se si ipotizza la disconnessione dei destinatari, si dovrebbe avere persistenza dei messaggi.

[Torna all'indice](#indice)

### Modello publish/subscriber

Il modello publish/subscriber √® un modello 1-N dove il messaggio viene consumato n volte. Un produttore invia un messaggio a una coda che si chiama named topic mentre il consumatore deve dire al MOM che √® interessato a quella comunicazione. I produttori pubblicano sul topic, mentre i consumatori si _abbonano_ al topic. Sono possibili diverse configurazioni del MOM per cui si pu√≤ ipotizzare che se non c'√® persistenza, i messaggi che sono stati inviati quando un consumatore non era presente vengono persi.

<img src="./img/img13-light.png#gh-light-mode-only" alt="Publish/Subscriber">
<img class="dark-mode" src="./img/img13-dark.png#gh-dark-mode-only" alt="Publish/Subscriber">

Ad esempio, questo modello si usa per creare un'applicazione di bacheca per richieste di lavoro.

[Torna all'indice](#indice)

### Affidabilit√† nello scambio di messaggi

Pi√π la semantica di affidabilit√† √® stringente pi√π il throughput del sistema si abbassa. Tutti i sistemi di messaging moderni supportano la persistenza dei messaggi, che eleva il livello di affidabilit√† stessa. Di solito i supporti ai sistemi di messaging utilizzano storage persistente per preservare i messaggi.

[Torna all'indice](#indice)

### Transazionalit√†

I MOM moderni supportano la transazionalit√† di messaggi. √à possibile distinguere due fasi:

- **Produzione transazionale**: il produttore pu√≤ raggruppare una serie di messaggi in un‚Äôunica transazione: o tutti i messaggi sono accodati con successo o nessuno.
- **Consumo transazionale**: il consumatore riceve un gruppo di messaggi come serie di oggetti con propriet√† transazionale e fino a che tutti i messaggi non sono stati consegnati e ricevuti con successo, i messaggi sono mantenuti permanentemente nella loro queue o topic. Per garantire transazionalit√† il MOM deve utilizzare un repository persistente.

Lo scope della transazionalit√† √® di due tipi:

- scope client-to-messaging system in cui le propriet√† di transazionalit√† riguardano l‚Äôinterazione fra ogni cliente e il sistema di messaging:
<img src="./img/img49-light.png#gh-light-mode-only" alt="Client-to-Messaging System">
<img class="dark-mode" src="./img/img49-dark.png#gh-dark-mode-only" alt="Client-to-Messaging System">
- scope client-to-client dove le propriet√† di transazionalit√† riguardano l‚Äôinsieme delle applicazioni produttore consumatore per quel gruppo di messaggi:
<img src="./img/img50-light.png#gh-light-mode-only" alt="Client-to-Client">
<img class="dark-mode" src="./img/img50-dark.png#gh-dark-mode-only" alt="Client-to-Client">

La seconda opzione √® molto complessa e non viene garantita da molti MOM. Inoltre, il sistema di messaging pu√≤ essere distribuito a sua volta. I sistemi di messaging possono realizzare un'infrastruttura in cui i messaggi sono scambiati fra server nel distribuito ma questo complica la transazionalit√†.

[Torna all'indice](#indice)

### Sicurezza

Il supporto alla sicurezza del MOM √® dato da autenticazione confidenzialit√† e integrit√†:

- L‚Äô**autenticazione** consente l‚Äôutilizzo di certificati.
- La **confidenzialit√†** √® garantita dall'encription effettuata sui messaggi in particolare sul payload.
- L‚Äô**integrit√†** con l‚Äôutilizzo di un'impronta (digest) dei messaggi.

La sicurezza e la sua gestione √® dipendente dal vendor del sistema di messaging. Con JMS non si offre un servizio diretto di sicurezza ma esistono API che consentono di implementare varie politiche di sicurezza. JMS consente unicamente di definire il servizio.

[Torna all'indice](#indice)

### Java Messaging Service (JMS)

JMS √® un insieme di interfacce Java che specificano come un cliente JMS possa accedere alle funzionalit√† di un sistema di messaging generico.

<img src="./img/img51-light.png#gh-light-mode-only" alt="JMS Architettura (1)">
<img class="dark-mode" src="./img/img51-dark.png#gh-dark-mode-only" alt="JMS Architettura (1)">

JMS √® parte della piattaforma J2EE, ma non necessita di EJB container per essere usato, √® solo fortemente integrato. Gli obiettivi sono uguali a quelli di JNDI cio√® non dipendere da un vendor specifico. Pi√π nello specifico l'architettura √® formata dalle entit√† che vengono mostrate in figura:

<img src="./img/img52-light.png#gh-light-mode-only" alt="JMS Architettura (2)">
<img class="dark-mode" src="./img/img52-dark.png#gh-dark-mode-only" alt="JMS Architettura (2)">

Le entit√† in gioco sono:

- Clienti JMS e non-JMS.
- Messaggi.
- Provider JMS (sistema di messaging dipendenti dal specifico vendor).
- Gli oggetti Destination e ConnectionFactory pubblicati tramite JNDI sul servizio di nomi.

[Torna all'indice](#indice)

### Tipi di comunicazioni

Nella comunicazione point-to-point i messaggi in una queue possono essere:

- Persistenti;
- Non persistenti.

Nella comunicazione pub/sub, i messaggi possono essere:

- Non durevoli: sono disponibili solo durante l‚Äôintervallo di tempo in cui il ricevente √® attivo. Se il ricevente non √® connesso, la semantica consente la perdita di ogni messaggio prodotto in sua assenza.
- Durevoli, invece, sono mantenuti dal sistema, che fa le veci dei riceventi non connessi al tempo della produzione dei messaggi, il ricevente non perde mai messaggi quando disconnesso.

[Torna all'indice](#indice)

### Messaggi JMS

JMS definisce i formati dei messaggi. I messaggi sono una modalit√† di comunicazione disaccoppiata fra le applicazioni. I veri formati che attualmente sono utilizzati per l‚Äôencoding dei messaggi sono fortemente dipendenti dal vendor del sistema di messaging. Un sistema di messaging pu√≤ interoperare completamente solo al suo interno. JMS fornisce, quindi, **solo un modello astratto e unificato** per la rappresentazione interoperabile dei messaggi attraverso le sue interfacce. I vari vendor spesso non riescono a comunicare perch√® vi √® una perdita di interoperabilit√† dovuta al fatto che Java lascia libert√† nella definizione dei protocolli.

Un messaggio JMS √® formato da tre parti:

- Header.
- Propriet√†.
- Body (payload).

<img src="./img/img53-light.png#gh-light-mode-only" alt="JMS Messaggio">
<img class="dark-mode" src="./img/img53-dark.png#gh-dark-mode-only" alt="JMS Messaggio">

L'header √® utilizzato per l‚Äôidentificazione del messaggio e il suo routing, include la destination e la modalit√† di consegna (persistente, non persistente), timestamp, priorit√†, campo ReplyTo che serve al ricevente per rispondere.

JMS aggiunge gradi di libert√† strutturati per aggiungere nuove feature che sono le propriet√† dei messaggi (coppie nome/valore) personalizzate dai vendor e tali propriet√† possono essere: campi application-specific, campi dipendenti da e specifici di un particolare sistema di messaging, campi opzionali etc.

Le propriet√† che si possono specificare sono: `JMSDestination`, `JMSDeliveryMode` (persistente o no), `JMSMessageID`, `JMSTimeStamp`, `JMSRedelivered`, `JMSExpiration`, `JMSPriority`, `JMSCorrelationID`, `JMSReplyTo` (destinazione fornita dal produttore, dove inviare la risposta), `JMSType` (tipo del corpo del messaggio).

L‚Äôidea di dividere l‚Äôheader dalla propiret√† √® dovuta la fatto che i MOM possono scegliere di guardare o meno alle propriet√† e pu√≤ farlo senza aprire il payload del messaggio.

Il payload ovviamente, √® il contenuto del messaggio e supporta diversi tipi di contenuto. Ogni tipo definito da una interfaccia: `StreamMessage`, `MapMessage`, `TextMessage`, `ObjectMessage`, `BytesMessage`. Ad esempio:

- `StreamMessage` contiene valori primitivi e supporta lettura sequenziale.
- `MapMessage` contiene coppie nome/valore e supporta lettura sequenziale o by name.
- `BytesMessage` contiene byte _non interpretati_ e viene utilizzato di solito per fare match con formati preesistenti.

Queste sono interfacce locali per interrogare i payload cio√® funzionano sul nodo e non si sa come viene trasmesso effettivamente il contenuto.

[Torna all'indice](#indice)

### Interfaccia Destination

L‚Äôinterfaccia `Destination` rappresenta l‚Äôastrazione di un topic o di una queue (non di un ricevitore di messaggi). Le interfacce figlie sono `Queue` e `Topic`.

<img src="./img/img14-light.png#gh-light-mode-only" alt="Interfaccia Destination">
<img class="dark-mode" src="./img/img14-dark.png#gh-dark-mode-only" alt="Interfaccia Destination">

[Torna all'indice](#indice)

### Interfaccia ConnectionFactory

L‚Äôinterfaccia `ConnectionFactory` serve per creare una connessione provider-specific verso il server JMS. √à simile al gestore di driver `java.sql.DriverManager` in JDBC. Le interfacce figlie sono `QueueConnectionFactory` e `TopicConnectionFactory`.

<img src="./img/img15-light.png#gh-light-mode-only" alt="Interfaccia ConnectionFactory">
<img class="dark-mode" src="./img/img15-dark.png#gh-dark-mode-only" alt="Interfaccia ConnectionFactory">

[Torna all'indice](#indice)

### Interfaccia Connection

L'interfaccia `Connection` √® un‚Äôastrazione che rappresenta un singolo canale di comunicazione verso il provider JMS. La connessione viene creata da un oggetto `ConnectionFactory`.

<img src="./img/img16-light.png#gh-light-mode-only" alt="Interfaccia Connection">
<img class="dark-mode" src="./img/img16-dark.png#gh-dark-mode-only" alt="Interfaccia Connection">

La connessione dovrebbe essere chiusa quando si √® terminato di utilizzare la risorsa.

[Torna all'indice](#indice)

### Interfaccia Session

L‚Äôinterfaccia `Session` √® creata da un oggetto `Connection`. Una volta connessi al JMS provider attraverso una `Connection`, tutte le operazioni si svolgono nel contesto di una sessione attiva, ogni sessione √® single-threaded, ovvero ogni operazione di invio e ricezione di messaggio avviene in modo serializzato. Le sessioni, quindi, realizzano un contesto _limitato_ con la possibilit√† di definire propriet√† transazionali. Nel caso di invio di due messaggi si ha la garanzia che il primo messaggio venga accodato nella coda prima del secondo messaggio.

<img src="./img/img17-light.png#gh-light-mode-only" alt="Interfaccia Session">
<img class="dark-mode" src="./img/img17-dark.png#gh-dark-mode-only" alt="Interfaccia Session">

[Torna all'indice](#indice)

### Interfacce Message Consumer e Message Producer

Per inviare un messaggio verso una `Destination`, il cliente deve richiedere esplicitamente all‚Äôoggetto `Session` di creare un oggetto `MessageProducer`. Analogamente per l‚Äôinterfaccia `MessageConsumer` i clienti che vogliono ricevere messaggi creano un oggetto `MessageConsumer` (collegato ad un oggetto `Destination`) attraverso `Session`.

<img src="./img/img18-light.png#gh-light-mode-only" alt="Interfaccia Message Producer">
<img class="dark-mode" src="./img/img18-dark.png#gh-dark-mode-only" alt="Interfaccia Message Producer">

Vi sono due modalit√† di ricezione dei messaggi:

- **Modalit√† blocking**: solito metodo `receive()` bloccante.
- **Modalit√† non blocking**: il cliente registra un oggetto `MessageListener`, quando un messaggio √® disponibile, il provider JMS richiama il metodo `onMessage()` di `MessageListener` (callback).

<img src="./img/img19-light.png#gh-light-mode-only" alt="Interfaccia Message Consumer">
<img class="dark-mode" src="./img/img19-dark.png#gh-dark-mode-only" alt="Interfaccia Message Consumer">

[Torna all'indice](#indice)

### Riassunto API JMS

Le API JMS possono essere riassunte nella seguente figura:

![single tier](./img/img20.png)

[Torna all'indice](#indice)

### Uso di JMS

I passi per costruire una'aplicazione JMS sono:

- Sviluppare un JMS Sender.
- Sviluppare un JMS Receiver.

I passaggi per costruire un JMS Sender sono:

- Ottenere un oggetto `ConnectionFactory` e un oggetto `Destination` (`Topic` o `Queue`) attraverso JNDI:

```java
// Ottiene oggetto InitialContext
Context jndiContext = new InitialContext();

// Trova l‚Äôoggetto ConnectionFactory via JNDI
TopicConnectionFactory factory = (TopicConnectionFactory) jndiContext.lookup("MyTopicConnectionFactory");

// Trova l‚Äôoggetto Destination via JNDI
// (Topic o Queue)
Topic weatherTopic = (Topic) jndiContext.lookup("WeatherData");
```

- Creare una `Connection`:

```java
// Richiede la creazione di un oggetto Connection
// all‚Äôoggetto ConnectionFactory
TopicConnection topicConnection = factory.createTopicConnection();
```

- Creare una `Session` per inviare/ricevere messaggi:

```java
// Crea un oggetto Session da Connection:
// primo parametro controlla transazionalit√†
// secondo specifica il tipo di ack
TopicSession session = topicConnection.createTopicSession(false, session.CLIENT_ACKNOWLEDGE);
```

- Creare un oggetto `MessageProducer` (`TopicPublisher` o `QueueSender`):

```java
// Richiede la creazione di un oggetto MessageProducer
// all‚Äôoggetto Session
// TopicPublisher per Pub/Sub
// QueueSender per Point-to-Point
TopicPublisher publisher = session.createPublisher(weatherTopic);
```

- Avviare la `Connection`:

```java
// Avvia la Connection
// Fino a che la connessione non √® avviata, il
// flusso dei messaggi non comincia: di solito
// Connection viene avviata prima dell‚Äôinvocazione
// dei metodi per la trasmissione messaggi
topicConnection.start();
```

- Inviare o pubblicare messaggi:

```java
// Creazione del messaggio
TextMessage message = session.createMessage();
message.setText("text:35 degrees");

// Invio del messaggio
publisher.publish(message);
```

- Chiudere `Session` e `Connection`:

```java
session.close();
topicConnection.close();
```

I passaggi per costruire un JMS Receiver (non-blocking) sono:

- Ottenere oggetti `ConnectionFactory` e `Destination` (`Topic` o
`Queue`) tramite JNDI.
- Creare un oggetto `Connection`.
- Creare un oggetto `Session` per inviare/ricevere messaggi.
- Creare un oggetto `MessageConsumer` (`TopicSubscriber` o `QueueReceiver`):

```java
// Crea oggetto Subscriber da Session
TopicSubscriber subscriber = session.createSubscriber(weatherTopic);
```

- Registrare `MessageListener` per modalit√† non-blocking:

```java
// Crea oggetto MessageListener
WeatherListener myListener = new WeatherListener();

// Registra MessageListener per l‚Äôoggetto
// TopicSubscriber desiderato
subscriber.setMessageListener(myListener);
```

- Avviare la `Connection`.
- Chiudere `Session` e `Connection`.

Il codice √® stato inserito solo nei punti diversi rispetto al produttore.

[Torna all'indice](#indice)

### Affidabilit√† dei messaggi

JMS offre diversi livelli di affidabilit√† dei messaggi. Il livello pi√π alto si ottiene quando si ha la persistenza dei messaggi, fattibile con la subscription durevole a un certo topic o con la ricezione da queue avendo la persistenza del messaggio spedito o ricevuto se il ricevente si √® assentato per un certo tempo con l‚Äôutilizzo di transazioni.

Nell‚Äô**affidabilit√† di base** (basic reliability) vi √® l‚Äôutilizzo di messaggi ACK, di messaggi persistenti, la possibilit√† di definire dei time-to-live, la configurazione dei livelli di priorit√† e la possibilit√† di consentire l‚Äôexpiration dei messaggi.

Nell‚Äô**affidabilit√† avanzata** (advanced reliability) si pu√≤ avere _abbonamenti_ durevoli e l‚Äôutilizzo di transazioni locali, ovvero transazioni che non possono essere garantire in tutto il percorso end-to-end ma solo tra consumatore e provider e/o tra provider e produttore.

[Torna all'indice](#indice)

### ACK

Alla ricezione di un messaggio, si possono effettuare varie operazioni: prima di tutto vi √® il processamento, dopo di che, se necessario vi √® lo scambio di ACK con varie modalit√† associate a ciascuna sessione.

Se ci sono sessioni con transazionalit√†, vi √® un ACK automatico al commitment, poi per la propriet√† del tutto o niente in caso di rollback vi √® il rinvio di tutti i messaggi. Invece, in sessioni senza transazionalit√†, il numero di ACK scambiati dipende dall‚Äôattributo specificato in `createSession()`.

I vari tipi di ACK dipendono da chi stimola l'ACK:

- **Auto acknowledgment**: ACK generato automaticamente dal supporto JMS dai metodi `MessageConsumer.receive()` o `MessageListener.onMessage()` dopo la `return` del metodo (se ha successo).
- **Client acknowledgment**: il cliente a livello applicativo si fa carico di inviare l‚ÄôACK con la chiamata al metodo `acknowledge()`, questo √® cumulativo, quindi, conferma tutti i messaggi inviati nell‚Äôintervallo che √® passato dal penultimo ACK a quello corrente.
- **Lazy acknowledgment**: viene inviato saltuariamente senza limiti nel numero di messaggi, sempre in modo cumulativo. Questo tipo di ACK √® inviato dal supporto ovvero da JMS stesso.

Tutti i tipi di messaggi ACK hanno la possibilit√† di essere duplicati e quindi ritrasmessi. Nel caso di `AUTO_ACKNOWLEDGE` nel caso persistent (supponendo il non fallimento dello storage dove sono salvati i messaggi), si pu√≤ avere la duplicazione del messaggio perch√® in caso di crash del server, quando questo torna in modalit√† up and running, si rende conto che l'ACK precedente non √® stato inviato e lo rimanda al consumer. Questo grazie allo storage persistente. In caso di `CLIENT_ACKNOWLEDGE`, ci possono essere duplicati perch√© ci possono essere situazioni simili a quella precedenti con pi√π ritrasmissioni se pi√π messaggi sono stati persi a causa della politica cumulativa. In caso di `DUPS_OK_ACKNOWLEDGE`, si ha la duplicazione ma i messaggi da rinviare potrebbero essere ancora di pi√π di quelli delle modalit√† precedenti poich√© la decisione di mandare ACK √® presa dal supporto a piacere. In generale, √® meglio che le applicazioni siano idempotenti e quindi che implementino la ritrasmissione.

In produzione si pu√≤ avere una semantica bloccante per la `send()`. Il client manda il messaggio, il server lo persiste e manda l‚ÄôACK solo dopo questa operazione. A questo punto la publish ritorna, tutto √® molto pi√π sincronizzato. L‚ÄôACK √® bloccante per la `send()` localmente al produttore. Anche in questo caso vi √® la ritrasmissione dei messaggi.

Nell‚Äôinvio dei messaggi vi sono due diversi modi di gestire la persistenza che si differenziano per la modalit√† di consegna. La modalit√† persistent richiede la persistenza quindi il provider ha la responsabilit√† di non perdere il messaggio e questo grazie allo storage √® possibile. Il non persistent non d√† garanzie rispetto al fault ma non ha problemi relativi al collo di bottiglia generato dallo storage quindi √® possibile sostenere un high rate nell‚Äôinvio con migliori performance. La modalit√† di consegna si imposta con il metodo `setDeliveryMode()` dell‚Äôinterfaccia `MessageProducer`:

```java
\\ metodo dell‚Äôinterfaccia MessageProducer
producer.setDeliveryMode(DeliveryMode.NON_PERSISTENT);
```

Vi √® un trade-off tra il numero di ACK che si pu√≤ inviare, l‚Äôoverhead che si introduce e il livello generale di affidabilit√† che si vuole raggiungere. Quanto bisogna coinvolgere la parte applicativa nella gestione degli ACK, coinvolgere molto il client nella gestione degli ACK pu√≤ aiutare a diminuire l‚Äôoverhead legato al fatto di non inviare pi√π un ACK per ogni messaggio dall‚Äôaltra parte per√≤ il livello applicativo che si prende in carico l‚Äôinvio dei messaggi deve essere ben fatto e con maggiore cura. L‚ÄôAPI permette quidi di gestire diversamente l‚Äôinvio dei messaggi.

[Torna all'indice](#indice)

### Priorit√†

Attributo che fa parte dell‚Äôheader del messaggio (`JMSPriority`), a livello di API, quindi √® una parte funzionale che tutti devono trattare. Sono attributi che sono sempre visibili dall‚ÄôAPI, questa √® una decisione forte a livello di supporto presa al momento della progettazione.

La priorit√† √® impostabile sia a livello di produttore del messaggio sia per il singolo messaggio, funziona allo stesso modo anche il `TimeToLive` (TTL). La priorit√† ha una scala di importanza da 0 a 9 e a default √® impostato a 4. Per il TTL bisogna invece impostare il valore in secondi. La priorit√† si imposta con il metodo `setPriority()` mentre il TTL si imposta con `setTimeToLive()` dell‚Äôinterfaccia `MessageProducer`:

```java
// metodi nell‚Äôinterfaccia MessageProducer
producer.setTimeToLive(60000);
producer.setPriority(7);
```

[Torna all'indice](#indice)

### Affidabilit√†

La configurazione dei livelli di affidabilit√† √® spesso determinata da scelte di default o prese alla creazione di `Destination`.

Per la basic reliability:

- Persistenza scelta a livello di singolo messaggio, ad es. interfaccia `MessageProducer`:
- Controllo degli ACK scelta a livello di sessione, ad es. interfaccia `Session`.
- Livelli di priorit√† scelti a livello di singolo messaggio, ad es. interfaccia `MessageProducer`.
- Expiration time scelto a livello di singolo messaggio, ad es. interfaccia `MessageProducer`.

Per l'advanced reliability:

- Sottoscrizione durevole scelto a livello di sessione, interfaccia `Session`.
- Transazionalit√† scelto a livello di sessione, interfaccia `Session`.

[Torna all'indice](#indice)

### Durable Subscription

Il durable subscriber si va a registrare con una identit√† univoca, perch√© un subscriber durevole potrebbe non essere sempre presente, quindi si ha bisogno di un naming durevole per ricondurre sempre i messaggi allo stesso subscriber. Il provider JMS mantiene questi messaggi fino a quando non vengono effettivamente consegnati oppure non avviene l'expiration (la scadenza). All‚Äôinterno di una singola applicazione, una sola session pu√≤ avere durable subscription a un deteminato named topic ad un determinato istante.

[Torna all'indice](#indice)

### Gestione delle transazioni di JMS

Lo scope delle transazioni in JMS √® solo fra clienti e sistema di messaging, non fra produttori e consumatori. Quindi, un gruppo di messaggi all‚Äôinterno di una singola transazione √® consegnato come un‚Äôunica unit√† lato produttore e un gruppo di messaggi in una transazione √® ricevuto come un‚Äôunica unit√† lato consumatore. Le transazioni possono essere gestite _localmente_ e sono controllate dall‚Äôoggetto `Session`. La transazione inizia implicitamente quando l‚Äôoggetto di sessione √® creato e termina all‚Äôinvocazione di `Session.commit()` o `Session.abort()`. La sessione √® transazionale se si specifica il flag appropriato all‚Äôatto della creazione. Ad esempio: `QueueConnection.createQueueSession(true, ...)`. Eventualmente le transazioni possono essere anche essere gestite in modo _distribuito_ se si vuole combinare in un unico blocco operazioni a scambio di messaggi e operazioni transazionali DB. In tal caso devono essere coordinate da un transactional manager esterno, ovvero tramite l'uso di Java Transactions API (JTA). L‚Äôutilizzo di `Session.commit()` e `Session.rollback()` √® non consentito perch√® viene eseguita tramite i metodi JTA.

[Torna all'indice](#indice)

### Selettori di messaggi

I selettori sono filtri la cui logica di filtraggio √® specificabile con stringe SQL like 92 (SQL92) che possono lavorare sui messaggi in arrivo per estrarne solo alcuni. Dal lato receiver, le applicazioni JMS possono utilizzare i selettori per scegliere i soli messaggi che sono potenzialmente di loro interesse. Non possono riferire il contenuto dei messaggi ma solo tramite propriet√† e header (non possono leggere il payload). I selettori consentono una gestione pi√π semplice e rimuovono overhead dal provider e dal supporto. Il fatto che il MOM non sia content-based √® dovuto al fatto della retrocompatibilit√† con i precedenti MOM.

[Torna all'indice](#indice)

### JMS in EJB

I MDB prelevati da un poll di istanze quando il messaggio viene ricevuto. Vi √® un JMS provider che invia i messaggi alle istanze di MDB che si sono registrati per la ricezione. Il tutto √® asincrono con l‚Äôidea che ci sia un produttore che immette i messaggi in una queue o in un topic con una semantica uno a molti. A questo punto, il messaggio da qui arriva a un listener che lo recapita al MDB con metodo di callback. A questo punto vi √® un applicazione con un EJB client che interagisce con una parte di business dell‚Äôapplicazione stessa un Business Logic Bean (un Session Bean con dietro Entity Bean per esempio), che va a interagire con con il DB, il bean in questione pu√≤ poi persistere dei dati su DB oppure diventare lui stesso un altro produttore verso un'altra destinazione JMS.

<img src="./img/img22-light.png#gh-light-mode-only" alt="JMS in EJB">
<img class="dark-mode" src="./img/img22-dark.png#gh-dark-mode-only" alt="JMS in EJB">

L‚Äôapplicazione pu√≤ per parti lavorare in modo sincrono e per altre lavorare in modo asincrono sfruttando le potenzialit√† di JMS.

[Torna all'indice](#indice)

### Enterprise Service Bus (ESB)

Il tema principale su cui si soffermano gli Enterpise Service Bus √® l‚Äôintegrazione di sistemi di grandi dimensioni. In particolare, la possibilit√† di mettere insieme parti di questi sistemi che sono legacy preesistenti e parti nuove sviluppate di recente. In questa direzione si sono sviluppati gli ESB che sono infrastrutture molto large con principi di integrazione condivisi. L‚Äôidea √® di avere un disaccopiamento forte e quindi si usano i MOM a supporto della comunicazione, l‚Äôutilizzo di SOA con l‚Äôobiettivo di avere servizi che lavorano molto e comunicano poco, in particolare solo quando vi sono riposte complete. Si mettono, quindi, insieme sistemi losely coupled con servizi a grana grossa. La parola bus significa facilitare la presentazione ovvero mettere insieme dei servizi molto eterogenei attraverso una funzionalit√† di trasformation e routing intelligence. Questo servizio garantisce anche la standardizzazione. Il modello √® asincrono e pub/sub con in mezzo un intermediario (sar√† appunto ESB che offre molte pi√π funzionalit√† di un servizio MOM), che comunque garantisce lo scambio di messaggi. Le principali caratteristiche sono:

- Disaccoppiamento.
- Gestione dei topic.
- Controllo degli accessi.
- Struttura messaggi.
- QoS configurabile.

[Torna all'indice](#indice)

#### Service Oriented Architecture (SOA)

SOA √® un'architettura software che mette a disposizione:

- Servizi a grana grossa autonomi cio√® non hanno bisogno di servizi esterni.
- Interfacce astratte ben fatte che definiscono contratti tra Consumer e Provider.
- Scambio di messaggi che compongono le operazioni invocabili sui servizi di input e output.
- Registri dei servizi con naming (in particolare trading).
- Possibilit√† di comporre i servizi in processi di business, ovvero molti servizi messi insieme seguendo le linee guide SOA.

Tutto questo ha l‚Äôobiettivo di ottenere accoppiamento debole, e quindi flessibilit√† di business, interoperabilit√† tra le applicazioni, indipendenza rispetto alle tecnologie di implementazione, grazie alle interfacce molto astratte. Un esempio √® Azure che espone API con interfacce REST.

[Torna all'indice](#indice)

#### Web Services

I Web Services sono una possibile implementazione dell'architettura SOA e facilitano l‚Äôinterazione tra applicazioni basata sul concetto di servizio, utilizzando interfacce Web, in particolare operano sulla porta 80. Tali Web services sfruttano essenzialmente tre tecnologie:

- **WSDL** √® un file contenente la descrizione del Web service, descrizione scritta in XML (indipendenti dal linguaggio) che contiene le funzionalit√† offerte da quel servizio.
- **SOAP** √® la descrizione di un protocollo per lo scambio di messaggi. In particolare, si scambiano messaggi chiamati _buste soap_ che al loro interno contengono file XML. Le buste SOAP possono essere trasmesse con HTTP per garantire massima interoperabilit√† dato che basta usare poi solo la porta 80.
- **UDDI** √® un servizio di trading che consente la discovery dei servizi, restituisce un file WSDL che contiene la descrizione di quel servizio, cosa si aspetta in termini di input e output e come collegarsi a quel servizio.

La differenza tra un Web service e un servizio di distributed object computing √® che nel caso dei Web Service non c‚Äô√® dipendenza dall‚Äôimplementazione e non ha neanche importanza il protocollo su cui viaggia.

#### Web Service Description Language (WSDL)

WSDL √® suddiviso in due parti:

- Una chiara separazione fra livello astratto (interfaccia) che contiene la definizione di operazioni di servizio come ingresso e uscita di documenti e struttura messaggi.
- Livello concreto che implementa l‚Äôinterfaccia e presenta una serie di endpoint con indirizzo di rete (binding che consente di raggiungere quel servizio)e uno di questi potrebbe essere, ad esempio, un protocollo HTTP.

Nell‚Äôarchitettura SOA non importa quale √® la tecnologia utilizzata ma si possono esporre pi√π modi di comunicazione.

<img src="./img/img23-light.png#gh-light-mode-only" alt="WSDL">
<img class="dark-mode" src="./img/img23-dark.png#gh-dark-mode-only" alt="WSDL">

[Torna all'indice](#indice)

#### Enterprise Application Integration (EAI)

L‚Äôintegrazione √® un grosso problema: solo il 10% delle applicazioni √® integrato (dati Gartner Inc.) e solo 15% di queste sfruttano middleware ad hoc. Perch√© le tecnologie passate si sono rivelate inadeguate? A causa di un‚Äôarchitettura _casuale_ che √® il risultato della composizione di diverse soluzioni adottate per i diversi sistemi nel corso degli anni, e col tempo presenta: alti costi di mantenimento, rigidit√† (applicazioni tightly-coupled), prestazioni insoddisfacenti (scarsa scalabilit√†). Sono poche le applicazioni che nascono con la volont√† di un‚Äôintegrazione forte.

L‚ÄôEnterprise Application Integration si occupa dell‚Äôintegrazione di queste applicazioni, costruendo intorno a queste applicazioni degli strumenti che le integrano.

<img src="./img/img63-light.png#gh-light-mode-only" alt="EAI">
<img class="dark-mode" src="./img/img63-dark.png#gh-dark-mode-only" alt="EAI">

Enterprise Application Integration si basa su un approccio formato da tre tipi di operazioni: extract, transform and load. Si passa, quindi, per processi batch tra un'app e un‚Äôaltra. I dati vengono trasmessi con FTP, poi li si trasforma in un formato utile per la seconda app e infine vengono passati di alla seconda app di nuovo con FTP. Questo √® il funzionamneto di molti servizi bancari.

Questa soluzione ha alte latenze al momento delle batch perch√® ci possono essere fault al momento delle transform. ESB vuole andare oltre rispetto a questa soluzione cercando di automatizzare al pi√π possibile il processo di trasmissione e trasformazione, renedendolo il pi√π possibile pulito.

La soluzione √® avere dei broker e dei orchestration engine come facilitatori della comunicazione e non pi√π provider ma entit√† intelligenti tra le due applicazioni. Le due architetture di riferimento sono hub -and-spoke e una a bus.

[Torna all'indice](#indice)

#### Hub-and-Spoke

Hub and spoke √® un‚Äôarchitettura a stella, in cui l‚Äôhub √® il nodo centrale e le applicazioni hanno un adapter a un formato comune garantito dal message broker. Una central automation engine cio√® un motore che consuma i messaggi, guarda dentro i messaggi e facendo routing intelligente tra le applicazioni li manda dove devono arrivare. Inoltre, vi sono tutti i servizi di sistema, tra cui persistenza e transazioni.

<img src="./img/img64-light.png#gh-light-mode-only" alt="Hub-and-Spoke">
<img class="dark-mode" src="./img/img64-dark.png#gh-dark-mode-only" alt="Hub-and-Spoke">

I pro dell‚Äôarchitettura a stella sono la facilit√† di gestione (centralizzata). Il principale contro √® che l‚Äôhub √® punto critico di centralizzazione. Inoltre, questa architettura ha una ridotta scalabilit√†.

[Torna all'indice](#indice)

#### Bus di Interconnessione

L‚Äôaltra architettura di riferimento √® quella a bus dove l‚Äôautomation engine risiede con l‚Äôapplicazione e non c'√® il collo di bottiglia dell‚Äôhub dell‚Äôarchitettura a stella. Il servizio a bus √® punto a punto.

<img src="./img/img65-light.png#gh-light-mode-only" alt="Bus di Interconnessione">
<img class="dark-mode" src="./img/img65-dark.png#gh-dark-mode-only" alt="Bus di Interconnessione">

I pro dell‚Äôarchitettura a bus sono la maggiore scalabilit√† (architettura meno centralizzata) mentre il contro √® la maggiore difficolt√† di gestione.

[Torna all'indice](#indice)

#### Concetti chiave di ESB

L'ESB √® la realizzazione della seconda architettura. L'idea principale √® quella di fare integrazione di servizi basata su scambio di messaggi tra applicazioni che hanno un adapter diverso e il bus deve uniformare la visione. Il bus pu√≤ essere visto come un middleware che consente di integrare il tutto. Il bus mette a disposizione:

- La possibilit√† di mandare e ricevere messaggi.
- Possibilit√† di registrare i servizi che si affacciano al bus.
- Orchestrare l'integrazione tra i vari servizi che si affacciano cio√® vuol dire gestire il flusso di esecuzione complessivo che deriva dall'interazione tra i componenti e gestisce le varie interazioni.

ESB consente di utilizzare tanti e diversi protocolli per scambiare le informazioni, senza imporre un protocollo unico. La descrizione astratta delle informazioni scambiate avviene nella parte astratta WSDL, si descriver√† con un biding concreto gli endpoint da offrire al mondo esterno, e ESB funge da _orchestratore_ nel mezzo risparmiando al programmatore di fare l‚Äôintegrazione poich√© √® compito del supporto. L‚Äôorchestrazione √® sia astratta che concreta specialmente nei routing intelligenti (ad esempio, abilitare un routing rispetto ad un altro) e nei vari servizi aggiuntivi come auditing e logging.

[Torna all'indice](#indice)

#### Java Business Integration (JBI)

Nel mondo Java a supporto di tutto questo c'√® lo standard JBI (Java Business Integration). In JBI, ci sono servizi interni ed esterni. I servizi esterni non riescono a parlare direttamente con l‚Äôorchestratore ESB perch√® usano, ad esempio, protocolli diversi. Per questi servizi servono dei binding componenent che fungono da proxy verso i servizi esterni. In particolare, essi sono degli adatatori per passare dal protocollo `A` al `B`. Poi, vi sono i servizi interni e con questi si ha la possibilit√† di utilizzare il Normalized Message Router (il bus) che si occupa dell‚Äôinterazione tra componenti cio√® del routing delle informazioni. Sopra, si ha la parte di servizi offerta dal framework tra cui l‚Äôorchestrazione dei servizi stessi offerta da BPEL (engine) che orchestra i servizi a grana grossa tramite diagrammi di flusso che gestiscono le integrazioni. Sono offerti anche servizi grafici al programmatore per l‚Äôintegrazione pi√π facile dei servizi.

La comunicazione tra componenti all‚Äôinterno del bus **non** √® diretta ma mediata tramite NMR (ESB) che agisce da mediatore fra i vari componenti, ha il compito di fare routing dei messaggi tra 2 o pi√π componenti ed √® distribuito e quindi consente di disaccoppiare Service Consumer da Service Provider garantendo un basso accoppiamento tra i componenti JBI. I messaggi sono scambiati in formato XML per cui la comunicazione √® technology-neutral tra endpoint cio√® i messaggi scambiati sono definiti in formato indipendente e neutrale da qualsiasi specifica applicazione, tecnologia o protocollo di comunicazione.

Il funzionamento dello scambio di messaggi √® il seguente:

<img src="./img/img24-light.png#gh-light-mode-only" alt="Scambio di messaggi JBI (1)">
<img class="dark-mode" src="./img/img24-dark.png#gh-dark-mode-only" alt="Scambio di messaggi JBI (1)">

Per rispondere a ciascuna richiesta, JBI √® in grado di capire quale sia il provider migliore per il componente `B`. A quel punto, `B` accetta il messaggio e continua l‚Äôinterazione. Da notare come `A` non conosce `B` ma si √® solo registrato a JBI. Quindi, i componenti SOA e il modello a scambio di messaggi √® basato su un elevato grado di disaccoppiamento tra componenti con la possibilit√† di operare su messaggi (trasformazioni) in modo trasparente.

<img src="./img/img66-light.png#gh-light-mode-only" alt="Scambio di messaggi JBI (2)">
<img class="dark-mode" src="./img/img66-dark.png#gh-dark-mode-only" alt="Scambio di messaggi JBI (2)">

JBI supporta quattro possibili pattern di scambio messaggi:

- **In-Only** per interazione/trasferimenti one-way, spesso molte integrazioni sono soddisfabili con questo pattern, prevede una conferma che tutto sia andato a buon fine.
- **Robust In-Only** per possibilit√† di segnalare fault a livello applicativo, simile a un handshake a tre vie con la conferma che le cose siano andate bene nelle due parti semantica per gli errori o danni.
- **In-Out** per interazione request-response con possibilit√† fault lato provider e ha una sola conferma da parte del consumatore.
- **In Optional-Out** per provider con risposta opzionale e possibilit√† di segnalare fault da provider/consumer (interazione completa).

[Torna all'indice](#indice)

## CORBA

Prima di iniziare questo nuovo capitolo, per fissare meglio i concetti, si consiglia di eseguire l'esercitazione su EJB. Lo startkit **corretto** si trova nella pagina `Releases`, quello fornito a lezione √® rotto e non funzionante!

EJB 3.X non √® un unico modello a componenti distribuiti basato sull‚Äôapproccio a container pesante ma esiste CORBA come potente container per oggetti distribuiti.

Si immagini di voler realizzare un sistema distribuito che funzioni derivando dall‚Äôinterazione sincrona bloccante fra pezzi di codice che non hanno il vincolo di essere scritti nello stesso linguaggio di programmazione. Con Java RMI si pu√≤ fare un‚Äôapplicazione che faccia invocazione di metodi remoti. Si vuole realizzare con CORBA la stessa cosa ma si vuole anche che cliente e servitore possano essere scritti in qualsiasi linguaggio di programmazione. CORBA √® una specifica e chi lo implementa pu√≤ decidere di supportarlo o meno.

L'obiettivo di CORBA √® lavorare con dispositivi molto leggeri e con poche risorse quindi si usa il protocollo GIOP (General Inter-ORB Protocol) per comunicare a byte. CORBA √® talmente standard de facto che persino EJB utilizza RMI sopra al protocollo CORBA.

[Torna all'indice](#indice)

### CORBA 2.X

Si parte dalla figura seguente che descrive CORBA ad oggetti (o CORBA 2.X):

![single tier](./img/img115.png)

Si ipotizzi di avere a disposizione un codice Pascal e si vuole che sia mostrato all‚Äôesterno come qualcosa ad oggetti. Il programmatore scrive quella che deve essere l‚Äôinterfaccia che deve esporre come oggetto CORBA. Il linguaggio per farlo √® CORBA IDL ed √® un semplice file piccolo che dice qual √® l‚Äôinterfaccia del software originale. A partire da questo file di interfaccia, l‚Äôinfrastruttura CORBA deve essere in grado di generare IDL Stub e IDL Skeleton. Questi si occupano dell‚Äôintegrazione del codice iniziale con CORBA e in particolare del marshalling/unmarshalling dei dati in ingresso e in uscita. Questo perch√© molto probabilmente si passer√† a quel pezzo di codice dei dati in un formato che lui non capirebbe. Lo Stub (che sta sempre vicino al cliente) prende i dati in ingresso generati dal cliente (che li rappresenta a modo suo) e li trasforma in un formato universale comprensibile da tutti. Lo Skeleton fa la cosa inversa! Prende i dati in ingresso in formato universale e li converte nel linguaggio specifico del servitore, che magari √® in C. Per la risposta stessa cosa: lo Skeleton la converte in formato universale e poi lo Stub la riconverte in linguaggio-client. I due componenti Stub e Skeleton dipendono fortemente dalla conoscenza IDL di interfaccia. IDL compiler parte da interfaccia IDL e genera Stub e Skeleton. Se si vuole prescindere completamente da linguaggio utilizzato non √® detto che l‚Äôattivazione di un servitore si faccia allo stesso modo. Ad esempio, ci sono linguaggi in cui se si fa il servitore e lo si lancia, lui √® attivo con i suoi thread. Altri in cui lui √® solo attivo, ma ci sono altri che gli danno i thread per eseguire le richieste. L‚Äôobject adapter fa questo: gestisce l‚Äôattivazione del servitore. Con poca sorpresa ci si ricorda che in EJB era roba del container.

Tutto quello appena descritto √® CORBA ad invocazione statica. Questo perch√© la generazione di Stub e Skeleton si fa staticamente in fase di sviluppo. Se l‚Äôinvocazione statica ci sta _stretta_ allora si fa altro usando DII e DSI.

![single tier](./img/img116.png)

Qui sopra viene messo un esempio di file IDL di interfaccia. Viene dato in pasto ad un compilatore IDL che genera Stub e Skeleton.

Il cliente per sapere come √® fatto il metodo CORBA che si vuole invocare, quali parametri passare, etc chiede all'implementation repository di farsi dare l‚Äôindirizzo del metodo. √à una specie di registro che per ogni oggetto CORBA tiene una riga con oggetto CORBA di come raggiungerlo. Restituisce un object reference CORBA che permette di fare la chiamata.

L‚Äôinterface repository permette di registrare le interfacce CORBA, non le implementazioni. In uno scenario statico √® ovviamente inutile perch√© il cliente deve sapere a tempo di sviluppo come funzionano le cose (altrimenti non potrebbe avere lo stub), ma in scenario dinamico le cose sono un po‚Äô diverse. Anche lo stub √® diverso. √à uno stub dinamico che si chiama DII (Dynamic Invocation Interface) che permette di fare operazioni pi√π generali e non super specializzate.

Uno dei problemi aperti di CORBA √® il fatto che non c‚Äô√® nulla per la gestione dell‚Äôimpacchettamento e del deployment del software ma tutto questo deve essere fatto a mano, quindi una volta fatta l‚Äôinterfaccia poi bisogna a mano mettere insieme tutti i vari pacchetti. Questo causa molti problemi per le infrastrutture perch√© si deve lavorare in modo diverso ogni volta e non ci sono tool automatici, nella specifica CORBA non ci sono strumenti per gestire tutti componenti e metterli nel punto giusto. Le conseguenze sono una scarsa manutenibilit√† e una scarsa penetrazione nel mercato.

[Torna all'indice](#indice)

### CORBA Component Model (CCM)

Per andare oltre a questi limiti √® stato proposto il CORBA Component Model per far si, che sia possibile creare dei component server che possano ospitare container e componenti, ovvero un‚Äôinterfaccia home e una parte di componente che permette l‚Äôesecuzione.

![single tier](./img/img26.png)

Il component server √® come deve essere fatto un processo server generico capace di ospitare oggetti CORBA. Deve saper mettere in esecuzione dei container o dei component Home e component Executors. √à sostanzialmente l‚Äôambiente dentro cui eseguono i componenti. Non direttamente...i componenti dentro
ad una struttura fatta a componenti! √à un p√≤ quello a cui assomiglia l‚Äôapplication server. √à il server dentro cui esegue il container e dentro al container i componenti. In CORBA un singolo component server pu√≤ mettere in esecuzione tanti container al suo interno: in CORBA esistono tanti container di tipo diverso, non come in EJB dove ce n‚Äô√® uno solo.

![single tier](./img/img117.png)

Component Implementation Framework (CIF) √® l'insieme di strumenti di sviluppo che permettono di automatizzare la generazione del codice per realizzare le funzionalit√† aggiuntive che ci sono in CCM e non c‚Äôerano in CORBA 2. Da CORBA 2 si √® visto che chi mette a disposizione Object Servant deve scrivere il file IDL da dare in pasto a IDL compiler per generare in modo statico Stub e Skeleton. Qui continua ad esserci l‚ÄôIDL compiler, ma √® arricchito da un altro compilatore che √® Component IDL (CIDL) Compiler (che √® parte del CIF). Grazie a questo ulteriore compilatore non si genera solo Stub e Skeleton, ma tutta una serie di altre cose:

- Descrittori di deploymentin XML.
- Altri file di interfaccia per executor.
- Pezzi di codice che aiutano esecuzione runtime dell'Object Servant.

[Torna all'indice](#indice)

![single tier](./img/img27.png)

In CCM vengono aggiunti anche gli strumenti di deployment: automatizzano la distribuzione del package sui nodi. Automatizzano il deployment di Component Assembly verso component server. Il component packaging ha funzionalit√† per fare packaging dei componenti in una applicazione. In CORBA 2 non c'√® la possibilit√† di preparare oggetti CORBA e poi ci si arrangia per il deployment. In CCM si pu√≤ assemblare l‚Äôapplicazione nel suo insieme mettendo dentro i vari componenti CCM che servono e i vari file di metalivello che descrivono le loro configurazioni e i loro vincoli di deployment. Assomiglia all‚Äôidea di fare un EAR di EJB3.

[Torna all'indice](#indice)

### Implementazioni CCM disponibili

Le principali standardizzazioni sono le seguenti:

![single tier](./img/img28.png)

Le tecnologie CORBA sono datate, CORBA ha avuto grande successo negli anni '80/'90 e ha trovato applicazione nei dipartimenti militari e nelle banche. I sistemi CORBA non hanno avuto successo perch√© Microsoft non ha mai voluto tale standardizzazione ma ha preferito i Web Services (quindi i motivi sono commerciali).

[Torna all'indice](#indice)

### Comparazione CCM vs. EJB e .NET

Rispetto ad altri framework le principali caratteristiche: 

- Linguaggio di programmazione: in EJB va tutto realizzato in Java, in .NET si possono usare diversi linguaggi di programmazione (ma vincolo di usare Windows). In CORBA si possono usare pi√π linguaggi di programmazione.
- In CORBA si hanno delle Home simili a EJB2 (che poi c‚Äô√® anche in EJB3, ma lavora dietro alle quinte).
- In EJB c'√® il container EJB. In CORBA si pu√≤ avere pi√π di un container, se serve.
- Da microsoft COM, CCM ha imparato la cosa di avere diverse interfacce mostrabili ai clienti (non si pu√≤ fare in EJB3) e ha imparato la questione degli eventi. Non √® vero che in EJB non si possono scambiare eventi, ma va fatto a mano: il container non aiuta.
- In COM o .NET si pu√≤ navigare sulle interfacce. Si pu√≤ fare in CCM, ma non su EJB.

In sintesi, CCM ha preso le tecnologie presenti sul mercato al momento della creazione della specifica cercando di prendere il meglio da tutte. Ci ha messo dentro veramente tantissima roba tanto non la implementavano loro dato che √® una specifica.

[Torna all'indice](#indice)

### Running Example

C'√® un component server che ospita dei componenti. Ce ne sono 3: componente `Rate Generator`, componente di calcolo della posizione `GPS` e un componente di display che mostra la mappa con la posizione corretta `NavDisplay`. Insieme formano un‚Äôapplicazione con un determinato flusso di esecuzione.

![single tier](./img/img29.png)

Il `Rate Generator` emette un impulso e ha una porta `Rate` che √® un parametro di configurazione definito a livello di deployment. `Pulse` √® un impulso generato ed √® un evento. `GPS` √® un ricevitore per quell‚Äôevento. Tutte le volte che `GPS` riceve l'evento `Pulse`, riaggiorna il calcolo della posizione corrente del dispositivo: la posizione √® interrogabile dall‚Äôesterno (pallino di fianco a `MyLocation`). `GPS` √® esso stesso emettitore di eventi `Ready` che vengono consumati da `NavDisplay`: lui riceve eventi `Refresh` e in risposta va ad invocare `MyLocation`. La mezzaluna rappresenta il fatto che il componente si aspetti di interagire con un altro componente che esponga la stessa interfaccia di `GPSLocation`.

[Torna all'indice](#indice)

### Componente CCM

Un componente CCM, banalmente, deve essere dichiarato come un componente e non come un oggetto. Si ha la parola riservata `component` che permette di farlo (non presente in CORBA 2, dove si possono definire solo oggetti). Il componente √® l‚Äôunit√† di composizione, di utilizzo e implementazione, √® l‚Äôunit√† base di software utilizzabile in parti diverse.

![single tier](./img/img30.png)

Per definire `RateGen` lo si definisce con la parolina `component` e poi dice che supporta l‚Äôinterfaccia `rate_control`. Esattamente come gli oggetti CORBA, anche i componenti CORBA possono sfruttare ereditariet√† e implementare interfacce. Ereditariet√† singola (figlio di un solo componente), ma implementazione multipla.

A livello di modellazione del singolo componente si hanno a disposizione le porte. Si possono definire quali porte usa.

![single tier](./img/img31.png)

In CCM, ci sono 5 tipi porte che un componente pu√≤ specificare e utilizzare. Le porte sono, sinteticamente, propriet√† di un componente:

- **Facet**: queste sono le interfacce che il componente espone verso l‚Äôesterno. Non √® una normale interfaccia: le facet possono essere multiple. Un componente pu√≤ esporre interfacce diverse a clienti diversi. Si possono definire nel linguaggio IDL con la parola chiave `provides`. Possono essere modificate runtime. Se si vuole fare il paragone con i lego rappresentano la parte sopra con i pallini.
- **Receptacles**: specifica a livello di definizione che quel componente, per lavorare correttamente, ha bisogno di facet esposte da altri. Pu√≤ avere bisogno di pi√π facets. Questa √® una cosa a cui non si √® abituati: in EJB non si dice che questo ha bisogno di un Entity Bean fatto cos√¨. La parola chiave IDL √® `uses`. Nel paragone con i lego √® il sotto del blocchetto: definisce quali sono le interfacce richieste per lavorare. Anche questo componente non esiste in CORBA 2. Si pu√≤ chiedere che durante il deployment vengano controllati i vincoli di Receptacles di cui un componente ha bisogno, controllare che vengano rispettati. Si pu√≤ sempre chiedere in fase di deployment di decidere quale binding andare ad associare nel caso ci siano pi√π vincoli di Receptacles. Quindi pu√≤ servire:

    - Staticamente per capire se un deployment √® completo e ci sono tutte le dipendenze.
    - Dinamicamente per cercare un altro componente che faccia match con il Receptacles specificato. Si parla in CCM di possibilit√† di connessione a tempo di deployment e a tempo di runtime.
- **Event Sources**: i componenti CCM possono essere produttori o consumatori di eventi. I componenti possono comunicare per scambio di eventi. In CORBA 2 gli eventi vengono aggiunti come servizio esterno, mentre in CCM fanno parte del modello. Questa porta dice che questo componente √® un produttore di eventi. Gli eventi prodotti possono essere di due tipi:

    - Ci possono essere sorgenti Publisher: la parola chiave √® `publishes` (invia un evento destinato ad una molteplicit√† di consumatori).
    - Ci possono essere sorgenti Emits: la parola riservata √® `emits` (invia un evento destinato ad un solo consumatore).

    Chi riceve eventi pu√≤ decidere di consumarli direttamente oppure pu√≤ usare un broker, cio√® un distributore di eventi! Non dissimile da un distributore di messaggi come pu√≤ essere JMS. In CORBA ce ne sono alcuni gi√† notificati come Corba Object Service Notification.
- **Event Sink**: con questa porta si specifica che il componente consuma eventi. La parola riservata √® `consumes`. Vale sia per eventi prodotti da un publisher sia per eventi prodotti da un emitter. Non ci sono differenze.
- **Attributes**: particolari propriet√† che possono essere configurate dall‚Äôesterno, tipicamente dal container, in base alle informazioni che si passano sui file di deployment descriptor. La parola chiave √® `attribute`. Il discorso da aprire √®: come √® importante nei sistemi industriali distribuiti poter definire a livello di deployment delle propriet√† configurabili esternamente. √à un discorso che si conosce molto bene, quindi non lo si apre. Questi attributi vengono definiti, viene dato loro valore, a tempo di deployment tramite file di configurazione esterni: dei descriptor di tipo XML, e la cosa non sconvolge perch√© √® stata gi√† vista anche in EJB.

[Torna all'indice](#indice)

### Gestione Lifecycle CCM

La gestione automatica del ciclo di vita non c‚Äô√® in CORBA 2. Per gestione automatica si intende quella di EJB: ci sono componenti che magari √® giusto gestire con una determinata strategia (magari sono componenti di sessione), altri in un altro perch√© sono componenti senza stato. Questa cosa la si vuole in CCM. Il concetto fondamentale per aiutare la struttura CORBA a gestire il ciclo di vita delle istanze dei componenti √® quello di passare attraverso le Home. Queste Home sono l‚Äôaggancio per gestire il ciclo di vita dei componenti in modo differenziato a seconda delle tipologie di componenti.

[Torna all'indice](#indice)

### CORBA Home

Con la parola riservata `home` si ha la possibilit√† di definire una o pi√π Home per i componenti CORBA. La Home ingloba il componente ed √® in grado di crearlo secondo quella che sar√† la specifica del ciclo di vita che desidereremo. Una Home √® in grado di gestire una famiglia di componenti: diverse Home possono gestire lo stesso componente generando comportamenti diversi a seconda del tipo di Home. Una istanza di componente, comunque, √® gestita sempre e solo da una Home.

![single tier](./img/img118.png)

Nel caso di `RateGen` qua di fianco si possono vedere come lui
sia bello runnato dalla sua Home, ma nulla vieta di
istanziarne altri 10 assegnarli ad altre 10 Home tutte diverse
con diverse istruzioni per il lifecycle e che quindi gestiranno in modo diverso il ciclo di vita di quel componente. Le Home fanno da _guscio_ per l‚Äôesecuzione delle singole istanze di componenti.

[Torna all'indice](#indice)

### Configurazione dinamica dei componenti

Di solito quando si ha un modello a componenti, viene comodo avere la possibilit√† di andare a vedere cosa un componente sa fare dinamicamente senza conoscere le caratteristiche a priori a tempo di sviluppo. Portato sul modello CCM questo significa essere in grado dinamicamente andare a vedere le porte che questo componente implementa e quali sono le loro caratteristiche! Per esempio, per una determinata Facet vedere quali operazioni ci sono dentro e con quali parametri. Vedere se ci sono dei Receptacles che costituiscono vincoli di deployment (come spiegato prima).

Per fare questo in CCM si introducono delle operazioni di introspezione. Sono analoghe alla reflection Java per scoprire funzionalit√† dei componenti in modo dinamico. Occhio che qua si lavora con CORBA, per cui il linguaggio
utilizzato potrebbe non avere questa funzionalit√†! Si devono, quindi, fare dei metadati descrittivi a livello CORBA di come sono fatte le porte del componente indipendentemente dal fatto che poi il linguaggio sottostante permetta di accedere dinamicamente alle descrizioni delle interfacce. In CCM, comunque, sono messe a disposizione delle funzionalit√† di navigazione delle descrizioni delle porte. La chiamata `getAllFacets()`, per esempio, permette di vedere runtime le caratteristiche di tutte le sue facets. La chiamata `getComponent()` permette di vedere da ogni facet a quale riferimento base √® questa collegata.

Questo codice di navigation si pu√≤ usare dentro i componenti, dentro la Home etc ma ad ogni modo √® generato automaticamente dal complilatore per componenti CORBA, cio√® il CIDL, per aiutare la realizzazione del component servant.

```
int
main (int argc, char *argv[])
{
    CORBA::ORB_var orb = CORBA::ORB_init (argc, argv);

    // Get the NameService reference...
    CORBA::Object_var o = ns->resolve_str (‚ÄúmyHelloHome");HelloHome_var hh = HelloHome::_narrow (o.in ());HelloWorld_var hw = hh->create ();

    // Get all facets & receptacles
    Components::FacetDescriptions_var fd = hw->get_all_facets (); Components::ReceptacleDescriptions_var rd = hw->get_all_receptacles ();

    // Get a named facet with a name "Farewell" CORBA::Object_var fobj = hw->provide ("Farewell");

    // Can invoke sayGoodbye() operation on Farewell after
    // narrowing to the Goodbye interface.

    ...

    return 0;
}
```

Sin questo esempio si vuole andare a recuperare una certa facet e invocare un metodo di tale interfaccia. Si parte dall‚ÄôORB che √® un servizio di nomi che d√† la possibilit√† di recuperare i servizi di base come il servizio di naming (come RMI Registry). Una volta recuperato il servizio di nomi si possono andare ad invocare dei servizi di lookup, in particolare in questo caso si fa il lookup della ComponentHome registrata come MyHelloHome, attraverso il narrowing si pu√≤ recuperare un oggetto tipato Home, su quell‚Äôoggetto si applica la create che crea il componente, a questo punto √® interrogabile e pu√≤ restituire una descrizione di tutte le facet offerte da quel compente, si pu√≤ poi con il receptable effettuare l‚Äôintrospezione, con il metodo provide possiamo chiedere il recupero del riferimento all‚Äôimplementazione di quella interfaccia, una volta ottenuto si pu√≤ fare il narrowing e a quel punto effettuare la chiamata a un metodo che ci interessa. Le interfacce in CORBA non vengono mantenute insieme alle implementazioni ma in un repository che si chiama Interface Repository. Quindi le informazioni dell‚Äôinterfaccia non sono insieme agli altri dati questo genera overhead quando bisogna recuperare molte interfacce diverse.

[Torna all'indice](#indice)

### Supporto Runtime: Funzionalit√† Component Server

Una volta capito cos‚Äôhanno in pi√π i componenti CCM rispetto agli oggetti CORBA 2, bisogna cercare adesso capire come vengono messi in esecuzione.

Un punto focale √® quello che CCM 3, oltre ai classici componenti di CORBA 2 (stub, skeleton, IDL compiler, interface
repository, object adapter etc), aggiunge il Component Server e prevede che i componenti eseguano dentro ad un Component Server:

![single tier](./img/img84.png)

Component Server fornisce l‚Äôapplication server unico di esecuzione dei container. √à un processo pesante che quindi gi√† realizza un ambiente di esecuzione attivo dentro cui andranno ad eseguire i componenti. Per√≤ non √® sufficiente avere Component Server: i componenti devono essere contenuti dentro ad un ulteriore supporto vivo che √® realizzato in termini di Container. L‚Äôidea √® che un Component Server possa ospitare pi√π container contemporaneamente. Perch√©? Perch√© diversi container possono avere diversi comportamenti. Dentro al container poi si ha, per ogni componente, la sua Home e il componente vero e proprio. √à dall‚Äôinterazione del container con la Home che scaturisce come viene gestito il ciclo di vita del componente in CCM. Ovviamente ci sono parti del codice dei Corba Component che sono invocabili solo dalla Home e altre che sono invocabili dall‚Äôesterno (le facets). Il cliente, prima di invocare le facets, ha bisogno di passare dalla Home, come visto in EJB2. Si fa dare un‚Äôistanza logica del componente e poi inizia ad invocare le facets. La Home fa da factory, crea un‚Äôistanza logica per il cliente il quale poi invoca le funzionalit√†. Per√≤ attenzione che lo fa **sempre** passando per il guscio del container ed √® per questo che si parla di modello a container pesante. Il cliente non ha mai un riferimento diretto all‚Äôistanza
dell‚Äôoggetto CORBA: ha sempre un riferimento che passa attraverso al container. O passa dal container per arrivare alla Home (prima invocazione) o passa per il container per arrivare all‚Äôinvocazione dell‚Äôoperazione esposta dalla facet (dalla seconda interazione in poi). Si ricorda che anche qui il modello di invocazione √® sincrono bloccante.

L‚Äôimmagine di prima era una piccola semplificazione di come in realt√† stanno le cose in CCM, perch√© oltre al discorso del component server e dei container, si hanno anche degli Executor a livello di Home e di component che incapsulano a loro volta la Home generica e il component che √® stato scritto. Sono necessari per gestire alcuni mismatch fra quello che si pu√≤ fare in un linguaggio di implementazione veramente utilizzato rispetto al modello CORBA e poi serve anche questo Component Context che gestisce le informazioni del componente e che rappresenta un‚Äôestensione di quello che si fa in CORBA 2 con il CORBA Object Adapter (uso risorse, attiva/disattiva in modo automatico il componente, ecc).

La cosa pi√π interessante √® vedere che in CCM hanno deciso che i componenti CORBA sono specificabili come 4 categorie principali:

![single tier](./img/img32.png)

√à un p√≤ l‚Äôanalogo di quello fatto in EJB 2.X dove esistono i Session Bean, Entity Bean e Message-Driven Bean. Qui ci sono 4 categorie di base prefabbricate:

- **Service**: pensa di esporre tramite le sue facets servizi che eseguono processamento (analogo a session bean). Qui nei service non si pu√≤ accumulare stato di sessione, quindi sono l‚Äôanalogo di Session Bean Stateless. Le invocazioni sono statiche, senza stato tra un‚Äôinvocazione e l‚Äôaltra.
- **Session**: servizi di processamento che mantengono stato per un singolo cliente. Service e session, quindi, sono il parallelo dei session bean, ma il Session √® l‚Äôanalogo dello stateful.
- **Process**: componente CCM che serve a mantenere dati durevoli (che non si vogliono perdere) che non si salvano su database relazionale, ma che si salvano su memoria persistente gestita in maniera meno strutturata (tipo senza identificatori univoci per i nostri dati).
- **Entity**: come process, solo che si salvano su database con chiave identitaria unica. Analogo degli Entity Bean in tecnologia Java.

Osservazione: non ci sono i Message-Driven Bean. Non esiste comunicazione asincrona, quindi, con poco stupore: gi√† in CORBA 2 si prevede che il modello sia sincrono bloccante. Seconda osservazione: ho capito che ci sono 4 categorie, ma come faccio a dire in CCM che il mio componente √® di tipo Service? Non lo faccio nell‚ÄôIDL, ma prendendo il mio componente e mettendolo in esecuzione dentro ad un container di tipo Session con container implementation type di tipo stateless. Sostanzialmente il comportamento e la gestione del tipo di vita di un componente non sono derivati da come si scrive il componente, ma da dove lo si mette in esecuzione. In particolare, in termini di container type e container implementation type. Ed √® per questo che esistono pi√π container in CORBA.

L‚Äôultima colonna dice semplicemente se i componenti hanno chiavi oppure no. L‚Äôunico tipo di componente identificato con identificatore univoco √® Entity, che √® quello che usiamo per mantenere stato persistente che poi mappiamo su database. Ed √® l‚Äôidentificatore unico di persistenza come l‚Äôabbiamo visto in layer di persistenza.

Il comportamento runtime di una istanza di componente, in CCM, discende da quello che noi vogliamo fare (e abbiamo 4 possibilit√† di default). Il fatto che la gestione del ciclo di vita corrispondente dipende dal container dentro cui andiamo a mettere il componente. Come facciamo a specificarlo in modo esplicito? Dentro all‚ÄôIDL del componente in modo dichiarativo (non dentro implementazione). Questo significa che a tempo di sviluppo il compilatore CIDL andr√† a realizzare dei servant e a richiamare a tempo di deployment dei container con particolare type e implementation type che realizzano quel modello di gestione del ciclo di vita. Ed √® per questo che in un component server possono esistere pi√π container: magari vogliamo far eseguire lo stesso Corba Component una volta stateful una volta stateless.

![single tier](./img/img127.png)

Ricorda che abbiamo la possibilit√† di esporre delle operazioni, ma anche di avere delle interfacce interne, cio√® metodi che appartengono al corba component ma non sono parte delle facets, ma anche metodi configurabili all‚Äôinterno tramite setter/getter.

Facendo cos√¨ noi riusciamo a disaccoppiare le politiche di
configurazione (come devo fare il deployment, come devo creare le istanze, metterle sui vari nodi, gestire il ciclo di vita) dall‚Äôimplementazione dei componenti. Importante se veniamo da CORBA 2 (l√¨ non lo possiamo fare), ma che non sconvolge noi se veniamo da EJB perch√© l√¨ si fa.

Esistono container transazionali, sui quali le invocazioni sono transazionali, oppure container stateless. Questo permette di gestire in modo articolato e differenziato come si gestisce il ciclo di vita, le transazioni, la gestione eventi e la sicurezza, che, a questo punto, sono servizi corba messi a disposizione. Molte delle configurazioni dei servizi di sistema in CCM si fanno tramite file XML. Esistono anche direttive dentro i file IDL che altrimenti mettiamo nel deployment descriptor. L‚Äôimportante da sapere √® che queste funzionalit√† vengono implementate dai container e non dai componenti dato che l‚Äôinvocazione passa sempre per il container: passando sempre di l√¨, per esempio, √® il container che pu√≤ avviare la transazione! Modello a container pesante.

[Torna all'indice](#indice)

### Exectutor

![single tier](./img/img128.png)

Ultima cosa, ma √® proprio un dettaglio. Se noi andiamo a vedere com‚Äô√® realizzato il modello ci sono anche degli Executor in CCM, e in particolare un executor per la Home e uno per il servant (la logica di business per il componente CORBA). Questi exectutor ci sono per supportare mismatch fra linguaggi di programmazione differenti, sono indispensabili per realizzare il modello a componenti e devono essere scritti dal programmatore. Il CIDL compiler scrive solo uno scheletro di queste cose, che va poi integrato. La buccia esterna di Servant, sia per la Home che per la logica di business invece viene generata completamente dal CIDL compiler. La figura finale √® quindi questa, dove abbiamo il container, il CORBA component (costituito da un main executor e da altri executor) e infine un gestore del contesto di esecuzione del componente che interagisce con il POA. La cosa importante √® che nel suo insieme il component CORBA espone le sue porte come descritto. In particolare le facets vengono gestite direttamente dal main component executor, mentre quelle di componenti e di receptacles dal CCMContext.
√à ovvio che questo √® un modello a container pensante dove ogni volta qualcuno che invoca qualcosa lo fa passando attraverso intermediari.

[Torna all'indice](#indice)

## Spring

Spring √® una soluzione a container leggero utile per sviluppare applicazioni Java SE e Java EE. Spring non √® solo un altro framework, rappresenta un approccio piuttosto unico, che ha fortemente influenzato i container successivi, verso tecnologie a microcontainer. Le principali propriet√† originali sono: la modularit√†, architettura a layer, possibilit√† di utilizzare anche solo alcune parti (i container)  in isolamento, si pu√≤ introdurre Spring incrementalmente in progetti esistenti e di imparare ad utilizzare la tecnologia _pezzo per pezzo_, supporta importanti aree non coperte da altri framework diffusi, come il management degli oggetti di business, una tecnologia di integrazione di soluzioni esistenti, maggiore facilit√† di testing, e infine √® un progetto con una community attivi.

[Torna all'indice](#indice)

### Perch√® usare Spring

Le motivazioni per cui scegliere Spring sono diverse. Spring consente l‚Äôintegrazione e la cooperazione fra componenti (secondo il semplice modello JavaBean) via dependency Injection, pone molta importanza al disaccoppiamento, mette a disposizione Test-Driven Development (TDD), ovvero la possibilit√† di effettuare testing delle classi (POJO) senza essere legati al framework, ha un uso semplificato di tecnologie diffuse e di successo utilizzando astrazioni che isolano il codice applicativo, con eliminazione di codice ridondante, e gestione di comuni condizioni di errore (caso delle unchecked exception), lascia una parziale visibilit√† quindi non vi √® totale trasparenza. La progettazione avviene per interfacce, con ottimo isolamento delle funzionalit√† dai dettagli implementativi, inoltre integra la programmazione dichiarativa via AOP che consente una facile configurazione degli aspetti, come ad esempio il supporto alle transazioni.

Spring non √® una soluzione _all-or-nothing_ cio√® si prende solo quello di cui si ha bisogno, e pone l‚Äôaccento su un‚Äôestrema modularit√† e flessibilit√†, ed √® progettata per essere facile da estendere e con molte classi riutilizzabili, ed integrabile con altre tecnologie tra le quali: EJB per J2EE, Hibernate, iBates, JDBC per l‚Äôaccesso a dati e ORM, Java Persistence API per la persistenza, Struts e WebWork per Web tier.

[Torna all'indice](#indice)

### Architettura

Il Core √® un container leggero basato sull‚ÄôInversion of Control, una parte che di questo √® il collante che consente l‚Äôinterazione tra le varie parti dell‚Äôarchitettura Spring. JEE si occupa della gestione di tutti i servizi enterpise. Il Web Tier contiene tutti i framework web che possono essere integrati con il core. DAO e ORM sono la parte rivolta verso il backend dati che riguarda la parte di persistenza tra mondo oggetti e relazionale sia la parte di gestione di transazione tutto realizzato anche grazie all‚Äôutilizzo di AOP che si pone come intermediario tra il Core, DAO e ORM.

<img src="./img/img39-light.png#gh-light-mode-only" alt="Architettura Spring">
<img class="dark-mode" src="./img/img39-dark.png#gh-dark-mode-only" alt="Architettura Spring">

Si pu√≤ sempre pensare di specializzare il framework e utilizzare le parti che ci servono, quindi si possono creare diversi scenari Spring in base alle esigenze di progettazione.

Alcuni package importanti sono:

- Il **Core Package** √® una parte fondamentale del framework. Consiste in un container leggero che si occupa di Inversion of Control o Dependency Injection. L‚Äôelemento fondamentale √® il `BeanFactory`, che fornisce una implementazione estesa del pattern factory ed elimina la necessit√† di gestione di singleton a livello di programmazione, permettendo di disaccoppiare configurazione e dipendenze dalla logica applicativa.
- Il **DAO Package** consente un livello di astrazione che non rende pi√π necessario boilerplate code per connessioni JDBC, eliminando parsing di codici di errore database-specific. La gestione delle transazioni avviene sia da codice che in modo dichiarativo, non solo per classi che implementano interfacce speciali, ma la possibilit√† √® aperta a tutti i POJO.
- Il **ORM Package** √® il livello di integrazione per il mapping da mondo relazionale a mondo a oggetti, con soluzioni diffuse per ORM, come JPA, JDO, Hibernate, iBatis. Le varie soluzioni ORM possono essere usate in combinazione con le altre funzionalit√† di Spring, come la gestione dichiarativa delle transazioni, tutte queste possono essere combinate con le altre funzionalit√† Spring, come tecnologia di integrazione.
- Il **MVC Package** implementa il pattern Model-View-Controller (MVC) per applicazioni Web, con buona separazione e indipendenza fra codice del modello di dominio e form Web ovvero la parte di presentazione e la logica applicativa a livello di control.
- Il **AOP Package** implementa l'aspect-oriented programming conforme allo standard AOP Alliance. Permette di definire, ad esempio, degli intercettori di metodo e pointcut per la logica disaccoppiamento degli aspetti in modo pulito, inoltre d√† la possibilit√† di utilizzare metadati a livello sorgente per incorporare informazioni aggiuntive di comportamento all‚Äôinterno del codice.

[Torna all'indice](#indice)

### Aspect Oriented Programming (AOP)

Aspect Oriented programming (AOP) √® un approccio di design e una tecnica per semplificare la gestione di aspetti trasversali e non strettamente legati alla logica (cross-cutting concern). Degli esempi di cross-cutting concern sono il logging, il locking, la gestione degli eventi, la gestione delle transazioni, sicurezza e auditing. AOP introduce anche nuovi strumenti che facilitano la gestione di questi aspetti tra cui: Joinpoint, Advice, Pointcut e Aspect, Weaving e Target, Introduction. L‚Äôidea di base √® quella di intercettare le chiamate da remoto.

[Torna all'indice](#indice)

#### Joinpoint

Joinpoint √® un punto ben definito all‚Äôinterno del codice applicativo, anche determinabile a runtime, dove pu√≤ essere inserita logica addizionale, alcuni esempi di joinpoint sono: l‚ÄôInvocazione di metodi, l‚ÄôInizializzazione di classi, l‚Äôinizializzazione di oggetti, ovvero la creazione di istanze.

[Torna all'indice](#indice)

#### Advice

Advice √® una parte di codice che aggiunge logica addizionale al programma, deve essere aggiunto ed eseguito ad un determinato joinpoint. I diversi tipi di Advice sono: i before advice che eseguono prima del joinpoint, after advice eseguono dopo il joinpoint, around advice eseguono attorno (around) al joinpoint.

[Torna all'indice](#indice)

#### Pointcut

Pointcut √® un Insieme di joinpoint che vengono verificati per definire quando eseguire un advice, il pointcut √® l‚Äôinsieme di tutte le invocazioni di quel metodo in una determinata classe, i pointcut possono essere messi in relazione tra di loro per decidere quando eseguirli insieme al collegato advice, con controllo fine e flessibile su come applicare advice al codice applicativo. La differenza tra pointcut e joinpoint √® la seguente: il pointcut √® l‚Äôinsieme di tutte le invocazioni di metodo in una determinata classe mentre l‚Äôinvocazione di un metodo √® un tipico joinpoint. I pointcut possono essere composti in relazioni anche complesse per vincolare il momento di esecuzione dell‚Äôadvice corrispondente.

[Torna all'indice](#indice)

#### Aspect

Aspect definisce quando e come gestire la logica per quell‚Äôaspetto, Aspect √® la combinazione di advice e pointcut.

[Torna all'indice](#indice)

#### Weaving

Weaving √® il processo dell‚Äôeffettivo inserimento di aspect dentro il codice applicativo nel punto appropriato (la traduzione di weaving √® cucire il codice nel punto appropriato), ci sono due possibilit√† per effettuare il weaving a tempo di compilazione, o a runtime ritardiamo il pi√π possibile l‚Äôinserimento dell‚Äôaspetto.

[Torna all'indice](#indice)

#### Target

Target √® un oggetto il cui flusso di esecuzione viene modificato da qualche processo AOP attraverso il weaving, in alcuni casi viene anche indicato come oggetto con advice (advised object).

#### AOP Statico

Nell‚ÄôAOP statico il processo di weaving viene realizzato a tempo di compilazione, come passo ulteriore del processo di sviluppo, durante la build dell‚Äôapplicazione, vengono aggiunti opportunamente in alcuni punti gli advice, in questo caso il weaving incide sul codice dell‚Äôapplicazione che viene eseguito e sul suo footprint, pu√≤ avvenire in diversi modi anche andando a modificare i BYTECODE. Ad esempio, in un programma Java, si pu√≤ avere weaving attraverso la modifica del bytecode di una applicazione, senza la modifica del codice sorgente, intervenendo direttamente sul bytecode stesso, i file bytecode possono essere modificati prima della messa in esecuzione questo richiede che durante la compilazione ci sia questo passaggio di modifica.

#### AOP Dinamico

Nell‚ÄôAOP dinamico il Processo di weaving √® realizzato dinamicamente a runtime, vi √® la possibilit√† di cambiare weaving senza bisogno di ricompilazione. Bisogna intercettare il punto in cui cambiare il weaving e inserire gli advice, con un continuo monitoraggio e iniezione durante l‚Äôesecuzione, questo rappresenta uno svantaggio perch√© causa un overhead durante l‚Äôesecuzione.

Spring realizza AOP sulla base dell‚Äôutilizzo di proxy, infatti se si desidera creare una classe advised, occorre utilizzare la classe ProxyFactory per creare un proxy per un‚Äôistanza di quella classe, fornendo a ProxyFactory tutti gli aspect con cui si desidera informare il proxy.

[Torna all'indice](#indice)

### Dependency Injection

La Dependency Injection √® l‚Äôapplicazione pi√π nota e di maggiore successo del principio di Inversion of Control e l‚ÄôHollywood Principle, che si traduce in _Don't call me, I'll call you_. L‚Äôidea √® che il container leggero si occupi di risolvere (injection) le dipendenze dei componenti attraverso l‚Äôopportuna configurazione dell‚Äôimplementazione dell‚Äôoggetto (push), per questo fu chiamato dependency injection. Questa idea √® opposta ai pattern pi√π classici di istanziazione di componenti o Service Locator, dove √® il componente che deve determinare l‚Äôimplementazione della risorsa desiderata (pull). Questo consente di mantenere il pi√π possibile l‚Äôimplementazione leggera.

Un esempio di dependency injection √® presente anche in EJB 3.0 attraverso le annotazioni per aggiungere tutte le informazioni utili che servono a esprimere tutte le dipendenze tra i vari componenti, con il vantaggio della flessibilit√† con l‚Äôeliminazione del codice di lookup nella logica di business, in caso di cambio delle risorse esterne non vi √® la necessit√† di cambiare il codice, la possibilit√† e facilit√† di testing con nessun bisogno di dipendere da risorse esterne o da container in fase di testing, vi √® la possibilit√† di abilitare testing automatico, ed un‚Äôelevata manutenibilit√† del codice che permette riutilizzo in diversi ambienti applicativi cambiando semplicemente i file di configurazione (o in generale le specifiche di dependency injection) e non il codice, dividendo nettamente la parte di programma da quella di configurazione.

[Torna all'indice](#indice)

#### Varianti per Dependency Injection

La dependency injection pu√≤ essere effettuate a livello di costruttore, in cui le dipendenze sono fornite attraverso i costruttori dei componenti:

```
public class ConstructorInjection {

    private Dependency dep;

    public ConstructorInjection(Dependency dep) {
        this.dep = dep;
    } 
}
```

Tuttavia, la dependency injection √® possibile anche a livello di metodi `setter` in cui le dipendenze sono fornite attraverso i metodi di configurazione (metodi `setter` in stile JavaBean) dei componenti. Questa modalit√† √® pi√π frequentemente utilizzata nella comunit√† degli sviluppatori:

```
public class SetterInjection {

    private Dependency dep;

    public void setMyDependency(Dependency dep) {
        this.dep = dep;
    } 
}
```

[Torna all'indice](#indice)

#### Oggetto BeanFactory

L‚Äôoggetto `BeanFactory` √® responsabile della gestione dei Bean che usano Spring e delle loro dipendenze. Ogni applicazione interagisce con la dependency injection di Spring (IoC container) tramite l'interfaccia `BeanFactory`. L'oggetto `BeanFactory` viene creato dall‚Äôapplicazione tipicamente nella forma di `XmlBeanFactory`. Questo oggetto `BeanFactory` legge un file di configurazione XML e si occupa di fare l‚Äôinjection, detto anche wiring della configurazione. `XmlBeanFactory` √® l'estensione di `DefaultListableBeanFactory` per leggere definizioni di Bean da un documento XML. La XML `BeanFactory` legge la configurazione da un file e attraverso il metodo `getBean()` √® possibile specificare il nome del Bean e crearlo ottenendo l'istanza logica. Le informazioni sono invece contenute tutte nel file XML:

```
public class XmlConfigWithBeanFactory { 
    public static void main(String[] args) { 
        XmlBeanFactory factory = new XmlBeanFactory(new FileSystemResource("beans.xml")); 
        SomeBeanInterface b = (SomeBeanInterface) factory.getBean("nameOftheBean"); 
    } 
}
```

Il componente che si usa che sfrutta la dependecy injection deve essere scritto in modo simile al seguente:

```
public class ConfigurableMessageProvider implements MessageProvider { 
    
    private String message;

    // usa dependency injection per config. del messaggio
    public ConfigurableMessageProvider(String message) {
        this.message = message;
    }

    public String getMessage() {
        return message;
    } 
}
```

In questo caso la dependency injection √® iniettata a livello di costruttore e nel file XML deve essere scritto nel seguente modo:

```
<beans>
    <bean id="provider" class="ConfigurableMessageProvider">
        <constructor-arg>
            <value> Questo √® il messaggio configurabile</value>
        </constructor-arg>
    </bean>
</beans>
```

Il Bean ha nome logico `provider`, la classe √® `ConfigurableMessageProvider` e dentro il tag `constructor-arg` viene specificato il parametro di ingresso.

Spring supporta diversi tipi di parametri iniettabili con cui fare injection:

- Valori semplici.
- Bean all‚Äôinterno della stessa factory (stesso file di configurazione XML).
- Bean anche in diverse factory.
- Collezioni (collection).
- Propriet√† definite esternamente.

Nei prossimi paragrafi verranno visti solo il primo e il secondo punto.

Tutti questi tipi possono essere usati sia per injection sui costruttori che sui metodi setter.

[Torna all'indice](#indice)

### Injection di valori semplici

Un esempio, di injection di valori semplici √® il seguente:

```
<beans>
    <bean id="injectSimple" class="InjectSimple">
        <property name="name">
            <value>John Smith</value>
        </property>
        <property name="age">
            <value>35</value>
        </property>
        <property name="height">
            <value>1.78</value>
        </property>
    </bean>
</beans>
```

Il Bean con nome logico `injectSimple` la cui classe √® `InjectSimple` presenta tre metodi `setter`. Ad esempio, il primo si chiama `name` e avr√† come valore `John Smith`.

[Torna all'indice](#indice)

#### Injection di un Bean all‚Äôinterno della stessa factory

L‚Äôinjection di un Bean della stessa Factory √® usata quando √® necessario fare injection di un Bean all‚Äôinterno di un altro Bean (target bean). Si Usa il tag `ref` all'interno del tag `property` o `constructor-arg` del target bean:

```
<beans>
    <bean id="injectRef" class="InjectRef">
        <property name="oracle">
            <ref local="oracle"/>
        </property>
    </bean>
</beans>
```

Il Bean con nome logio `injectRef` la cui classe √® `InjectRef`, ha il metodo setter con nome `oracle`, il cui parametro di ingresso √® un altro componente _locale_ cio√® usa la stessa factory il cui nome logico √® `oracle`. Il controllo sul tipo del Bean √® _lasco_ rispetto a quanto definito nel target perch√® se il tipo definito nel target √® un‚Äôinterfaccia, il bean injected deve essere un‚Äôimplementazione di tale interfaccia, se il tipo definito nel target √® una classe, il bean injected deve essere della stessa classe o di una sottoclasse.

[Torna all'indice](#indice)

#### Naming dei Componenti

Il ritrovamento dei Bean avviene attraverso il naming dei componenti Spring che vengono specificati nei file XML. Ogni bean deve avere un nome unico all‚Äôinterno della BeanFactory che lo contiene e la procedura di risoluzione dei nomi avviene seguendo le seguenti regole: se un tag ha un attributo di nome `id`, il valore di questo attributo viene usato come nome, se non c‚Äô√® attributo `id`, Spring cerca un attributo di nome `name`, se non √® definito n√© `id` n√© `name`, Spring usa il nome della classe del Bean come suo nome.

[Torna all'indice](#indice)

#### HelloWorld con dependency injection

Tramite una serie di esempi, si vede come la `BeanFactory` pu√≤ essere realizzata. Si parte dal seguente esempio:

```
public class HelloWorld {

    public static void main(String[] args) {
        System.out.println("Hello World!");
    }

}
```

Un programma come questo, si porta dietro alcuni problemi: se vi √® la necessit√† di cambiare il codice (e di ricompilare) per imporre una modifica del messaggio, bisogna modificarlo e ricompilarlo: il codice non √® assolutamente estensibile o modificabile.

Adesso, tramite alcune operazioni si disaccoppia l‚Äôimplementazione della logica del message provider (il messaggio da stampare) rispetto al resto del codice tramite la creazione di una classe separata:

```
public class HelloWorldMessageProvider {

    public String getMessage() {
        return "Hello World!";
    }

}
```

Si disaccoppia anche l‚Äôimplementazione della logica di message rendering (chi stampa il messaggio) dal resto del codice:

```
public class StandardOutMessageRenderer {

    private HelloWorldMessageProvider messageProvider = null;

    public void render() {
        if (messageProvider == null) {
            throw new RuntimeException("You must set the property messageProvider of class:" + StandardOutMessageRenderer.class. getName());
        }

        System.out.println(messageProvider.getMessage());
    }

    // dependency injection tramite metodo setter
    public void setMessageProvider(HelloWorldMessageProvider provider) {
        this.messageProvider = provider;
    }
    
    public HelloWorldMessageProvider getMessageProvider() {
        return this.messageProvider;
    }
}
```

La logica di message rendering √® data all‚Äôoggetto `HelloWorldMessageProvider`. La classe `StandardOutMessageRender` che ha come campo il messaggio da stampare e ha un metodo `render()` che consente di andare ad emettere un messaggio di errore se non √® stato configurato correttamente o il `MessageProvider` in caso contrario. Il metodo `getMessage()` permette di andare a stampare il messaggio di `HelloWorld` ,quindi si rende indipendente il renderer dal message provider. La dependency √® realizzata attraverso il metodo `setter`.

Mettendo insieme le due classi appena spiegati il main si scrive nel seguente modo:

```
public class HelloWorldDecoupled {

    public static void main(String[] args) {
        StandardOutMessageRenderer mr = new StandardOutMessageRenderer();
        HelloWorldMessageProvider mp = new HelloWorldMessageProvider();
        mr.setMessageProvider(mp);
        mr.render();
    }
}
```

Ma ci sono ancora dei problemi aperti, in particolare, le Implementazioni specifiche di `MessageRenderer` e di `MessageProvider` sono hard-coded nella logica applicativa, per rendere il tutto ancora pi√π disaccoppiato si fa uso di interfacce:

```
public interface MessageProvider {
    
    public String getMessage();
}
```

```
public class HelloWorldMessageProvider implements MessageProvider {
    
    public String getMessage() {
        return "Hello World!";
    }
}
```

```
public interface MessageRenderer {

    public void render();
    public void setMessageProvider(MessageProvider provider);
    public MessageProvider getMessageProvider();
}
```

```
public class StandardOutMessageRenderer implements MessageRenderer {
    // MessageProvider √® una interfaccia Java ora 
    private MessageProvider messageProvider = null; 

    public void render() {
        if (messageProvider == null) {
            throw new RuntimeException( "You must set the property messageProvider of class:" + StandardOutMessageRenderer.class. getName()); 
        }

        System.out.println(messageProvider.getMessage());
    }

    public void setMessageProvider(MessageProvider provider) {
        this.messageProvider = provider; 
    }

    public MessageProvider getMessageProvider() {
        return this.messageProvider;
    }
}
```

Scompare la dipendenza dalla classe, anche se dietro le quinte si dovr√† andare a creare le opportune classi, ora per√≤ non vi √® pi√π dipendenza da quelle classi. Rimane la responsabilit√† del `main` di effettuare la dependency injection:

```
public class HelloWorldDecoupled {

    public static void main(String[] args) {
        MessageRenderer mr = new StandardOutMessageRenderer();
        MessageProvider mp = new HelloWorldMessageProvider(); 
        mr.setMessageProvider(mp); 
        mr.render(); 
    }

}
```

Ora √® possibile modificare la logica di message rendering senza alcun impatto sulla logica di message provider. Allo stesso modo, √® possibile cambiare la logica di message provider senza bisogno di modificare la logica di message rendering.

Vi sono ancora dei problemi ovvero l‚Äôuso di differenti implementazioni delle interfacce `MessageRenderer` o `MessageProvider` necessita comunque di una modifica (limitata) del codice della logica di business del `main`. Per risolvere bisogna creare una semplice classe factory che legga i nomi delle classi desiderate per le implementazioni delle interfacce da un file (property file) e le istanzi a runtime, facendo le veci dell‚Äôapplicazione:

```
public class MessageSupportFactory {

    private static MessageSupportFactory instance = null;
    private Properties props = null;
    private MessageRenderer renderer = null;
    private MessageProvider provider = null;
    
    private MessageSupportFactory() {
        props = new Properties();
        try {
            props.load(new FileInputStream("msf.properties"));

            // ottiene i nomi delle classi per le interfacce
            String rendererClass = props.getProperty("renderer.class");
            String providerClass = props.getProperty("provider.class");
            renderer = (MessageRenderer) Class.forName(rendererClass).newInstance();
            provider = (MessageProvider) Class.forName(providerClass).newInstance();
        }
        catch (Exception ex) {
            ex.printStackTrace();
        }
    }

    static {
        instance = new MessageSupportFactory();
    }

    public static MessageSupportFactory getInstance() {
        return instance;
    }

    public MessageRenderer getMessageRenderer() {
        return renderer;
    }

    public MessageProvider getMessageProvider() {
        return provider;
    }

}
```

Il `main` diventa:

```
public class HelloWorldDecoupledWithFactory {

    public static void main(String[] args) {

        MessageRenderer mr = MessageSupportFactory.getInstance().getMessageRenderer();
        MessageProvider mp = MessageSupportFactory.getInstance().getMessageProvider();
        mr.setMessageProvider(mp);
        mr.render();

    }
}
```

File di propriet√†:

```
# msf.properties

renderer.class=StandardOutMessageRenderer
provider.class=HelloWorldMessageProvider
```

Ora le implementazioni di `MessageProvider` e `MessageRenderer` possono essere modificate tramite semplice modifica del file di propriet√†, non ha pi√π dipendenze dagli oggetti. Questa soluzione necessita di scrivere molto _glue code_ per mettere insieme l‚Äôapplicazione, bisogna scrivere una classe `MessageSupportFactory`, inoltre, l ‚Äôistanza di `MessageProvider` deve essere ancora iniettata manualmente nell‚Äôimplementazione di `MessageRenderer`.

HelloWord usando Spring:

```
public class HelloWorldSpring {

    public static void main(String[] args) throws Exception {
        // ottiene il riferimento a bean factory
        BeanFactory factory = getBeanFactory();
        MessageRenderer mr = (MessageRenderer) factory.getBean("renderer");
        MessageProvider mp = (MessageProvider) factory.getBean("provider");
        mr.setMessageProvider(mp);
        mr.render();
    }

    // Possibilit√† di scrivere il proprio metodo getBeanFactory()
    // a partire da Spring DefaultListableBeanFactoryclass
    private static BeanFactory getBeanFactory() throws Exception {
        
        DefaultListableBeanFactory factory = new DefaultListableBeanFactory();
        // creare un proprio lettore delle definizioni
        PropertiesBeanDefinitionReader rdr = new PropertiesBeanDefinitionReader(factory);
        // caricare le opzioni di configurazione
        Properties props = new Properties();
        props.load(new FileInputStream("beans.properties"));
        rdr.registerBeanDefinitions(props); return factory;
        
    }
}
```

I vantaggi raggiunti con questa soluzione sono l‚Äôeliminazione di glue code (`MessageSupportFactory`), una migliore gestione degli errori e meccanismo di configurazione completamente disaccoppiato, sparisce la dipendenza dalla classe, il messaggio `HelloWorld` non dipende pi√π dalle classi. Rimangono dei problemi, infatti, il codice di startup deve avere conoscenza delle dipendenze di `MessageRenderer`, deve ottenerle e deve passarle a `MessageRenderer`. In questo caso Spring agirebbe come non pi√π di una classe factory sofisticata, rimarrebbe al programmatore il compito di fornire il proprio metodo `getBeanFactory()` usando le API di basso livello del framework Spring.

La svolta √® lavorare nel file di configurazione, dichiarando il riferimento a un altro Bean di cui si ha bisogno, cos√¨ si chiede a Spring di assegnare il `HelloWorldMessageProvider` come provider del renderer. Si realizza cos√¨ la dipendenza tra le due, semplicemente dichiarando il tutto nel file XML di configurazione. Finalmente, si utilizza la Dependency Injection (DI) del framework Spring:

```
# File di configurazione

#Message renderer
renderer.class=StandardOutMessageRenderer
# Chiede a Spring di assegnare l‚Äôeffettivo provider alla
# propriet√† MessageProvider del bean Message renderer
renderer.messageProvider(ref)=provider

#Message provider
provider.class=HelloWorldMessageProvider
```

```
public class HelloWorldSpringWithDI {

    public static void main(String[] args) throws Exception {

        BeanFactory factory = getBeanFactory();
        MessageRenderer mr = (MessageRenderer) factory.getBean("renderer");
        // nota che non √® pi√π necessaria nessuna injection manuale
        // del message provider al message renderer
        mr.render();

    }

    private static BeanFactory getBeanFactory() throws Exception {
    
        DefaultListableBeanFactory factory = new DefaultListableBeanFactory();
        PropertiesBeanDefinitionReader rdr = new PropertiesBeanDefinitionReader(factory);
        Properties props = new Properties();
        props.load(new FileInputStream("beans.properties"));
        rdr.registerBeanDefinitions(props);
        return factory;

    }

}
```

Il metodo `main()` deve semplicemente ottenere il Bean `MessageRenderer` e richiamare `render()`, non deve ottenere prima il `MessageProvider` e configurare la propriet√† `MessageProvider` del bean `MessageRenderer`. Il _wiring_ √® realizzato automaticamente dalla Dependency Injection di Spring, non serve nessuna modifica alle classi da collegare insieme. Queste classi non fanno alcun riferimento a Spring e quindi il programmatore non deve conoscere queste cose. Nessun bisogno di implementare interfacce del framework Spring. Nessun bisogno di estendere classi del framework Spring. Le classi come POJO puri che possono essere sottoposte a testing senza alcuna dipendenza da Spring.

Pi√π usualmente, le dipendenze dei bean sono specificate tramite un file XML:

```
<beans>
    <bean id="renderer" class="StandardOutMessageRenderer">
        <property name="messageProvider">
            <ref local="provider"/>
        </property>
    </bean>
    <bean id="provider" class="HelloWorldMessageProvider"/>
</beans>
```

Di seguito viene riportato il codice rielaborato dopo l‚Äôaggiunta dei riferimenti nell'XML:

```
public class HelloWorldSpringWithDIXMLFile {

    public static void main(String[] args) throws Exception {
        BeanFactory factory = getBeanFactory();
        MessageRenderer mr = (MessageRenderer) factory.getBean("renderer");
        mr.render();
    }

    private static BeanFactory getBeanFactory() throws Exception {
        BeanFactory factory = new XmlBeanFactory(new FileSystemResource("beans.xml"));
        return factory;
    }
}
```

La factory viene creata attraverso il fileXML.

Se si volesse usare la dependency Injection in Spring con un costruttore per `MessageProvider`:

```
<beans>
    <bean id="renderer" class="StandardOutMessageRenderer">
        <property name="messageProvider">
            <ref local="provider"/>
        </property>
    </bean>
    <bean id="provider" class="ConfigurableMessageProvider">
        <constructor-arg>
            <value>Questo √® il messaggio configurabile</value>
        </constructor-arg>
    </bean>
</beans>
```

A livello di codice il `ConfigurableMessageProvider` esporr√† un campo nel costruttore che consentir√† di modificare il messaggio, il renderer continuer√† a usare il provider. Il `ConfigurableMessageProvider` sar√† una delle possibili implementazioni del `MessageProvider`, a differenza della precedente ha la stringa configurabile e non embedded.

```
public class ConfigurableMessageProvider implements MessageProvider {

    private String message;
    
    public ConfigurableMessageProvider(String message) {
        this.message = message;
    }
    
    public String getMessage() {
        return message;
    }
}
```

[Torna all'indice](#indice)

#### Considerazioni sulla dependency injection

La possibilit√† di semplice Dependency Injection tramite costruttori o metodi semplifica il testing delle applicazioni Spring. Per esempio √® semplice scrivere un test JUnit che crea l‚Äôoggetto Spring e configura le sue propriet√† a fini di testing. Il container IoC non √® invasivo: molti oggetti di business non dipendono dalle API di invocazione del container, queste possono essere portabili verso altre implementazioni di container (PicoContainer, HiveMind etc) ed √® facile _introdurre_ vecchi POJO in ambiente Spring. Le factory Spring sono leggere, esistono anche implementazioni all‚Äôinterno di singole applet o come applicazioni Swing standalone. Un altro importante aspetto, secondario ma comunque rilevante √® la possibilit√† di avere di avere unchecked runtime exception. Un'eccezione runtime exception √® un oggetto che viene generato e viene gestito tramite `try-catch`. Tuttavia, √® possibile che a tempo di esecuzione, un'eccezione non venga gestita quindi l'errore viene propagato e l'applicazione si pu√≤ interrompere. In Spring, se un'eccezione non viene catturata viene ignorata.

[Torna all'indice](#indice)

### HelloWorld con AOP

La classe `MessageWriter` scrive `World`. L'obiettivo √® quello di stampare prima la parola `Hello` e alla fine `!`:

```
public class MessageWriter implements IMessageWriter {

    public void writeMessage() {
        System.out.print("World");
    }

} 
```

Si ha bisogno di un around advice per inserire prima e dopo `World`, le parole `Hello` e `!`, mentre con il joinpoint si ha l‚Äôinvocazione del metodo `writeMessage()` dovendo intervenire prima e dopo l‚Äôinvocazione di questo metodo.

Gli advice sono scritti in Java (nessun linguaggio AOP-specific). I pointcut tipicamente specificati in file XML di configurazione. Spring supporta solo joinpoint a livello di metodo (ad esempio, impossibile associare advice alla modifica di un campo di un oggetto). Con l‚Äôidea di definire come decorator queste parti di codice, dal punto di vista dell‚Äôesecuzione questi lavorano come intercettori che consentono di cambiare il codice:

```
public class MessageDecorator implements MethodInterceptor {

    public Object invoke(MethodInvocation invocation) throws Throwable {
        System.out.print("Hello ");
        Object retVal = invocation.proceed();
        System.out.println("!");
        return retVal;
    }
}
```

I pointcut lavorano come intercettori e consentono se adeguatamente settati di cambiare la logica applicativa. Si usa la classe `ProxyFactory` per creare il proxy dell‚Äôoggetto target, anche modalit√† pi√π di base, tramite uso di possibilit√† predeterminate e file XML, senza istanziare uno specifico proxy per AOP:

```
public static void main(String[] args) {

    MessageWriter target = new MessageWriter();
    ProxyFactory pf = new ProxyFactory();
    // aggiunge advice alla coda della catena dell‚Äôadvice
    pf.addAdvice(new MessageDecorator());
    // configura l‚Äôoggetto dato come target
    pf.setTarget(target);
    // crea un nuovo proxy in accordo con le configurazioni
    // della factory MessageWriter
    proxy = (MessageWriter) pf.getProxy();
    proxy.writeMessage();
    // Come farei invece a supportare lo stesso comportamento
    // con chiamata diretta al metodo dell‚Äôoggetto target?
    
}
```

Guarda caso, anche in Spring si possono definire intercettori, ma questa volta in modo molto diverso e meno trasparente rispetto a un modello a container pesante, sfruttando i concetti di AOP e gli oggetti con proxy.

[Torna all'indice](#indice)

### Intercettori

L'intercettore Spring pu√≤ eseguire immediatamente prima o dopo l‚Äôinvocazione della richiesta corrispondente. Implementa l‚Äôinterfaccia `MethodInterceptor` o estende `HandlerInterceptorAdaptor`:

```
public class MyService {

    public void doSomething() {
        for (int i = 1; i < 10000; i++) {
            System.out.println("i=" + i);
        } 
    }

}
```

```
public class ServiceMethodInterceptor implements MethodInterceptor {

    public Object invoke(MethodInvocation methodInvocation) throws Throwable {

        long startTime = System.currentTimeMillis();
        Object result = methodInvocation.proceed();
        long duration = System.currentTimeMillis() - startTime;
        Method method = methodInvocation.getMethod();
        String methodName = method.getDeclaringClass().getName() + "." + method.getName();
        System.out.println("Method '" + methodName + "' took " + duration + " milliseconds to run");
        
        return null;
    }
}
```

Nel file di configurazione si definiscono i componenti, l‚Äôintercettore e quali sono i vari target e nei vari target si definiscono gli intercettori da utilizzare:

```
<beans>
    <bean id="myService" class="com.test.MyService"></bean>
    <bean id="interceptor" class="com.test.ServiceMethodInterceptor"></bean>
    <bean id="interceptedService" class="org.springframework.aop.framework.ProxyFactoryBean">
        <property name="target">
            <ref bean="myService"/> </property>
        <property name="interceptorNames">
            <list>
                <value>interceptor</value>
            </list>
        </property>
    </bean>
</beans>
```

[Torna all'indice](#indice)

### Transazioni verso DB

Una transazione √® un‚Äôunit√† logica di elaborazione che, nel caso generale, si compone di molte operazioni fisiche elementari che agiscono sul DB. Le propriet√† di cui deve godere una transazione si riassumono nell‚Äôacronimo ACID (Atomicity, Consistency, Isolation, Durability):

- Atomicity si basa sul principio del _tutto o niente_ cio√® o viene eseguita tutta correttamente oppure no.
- Isolation richiede che venga correttamente gestita l‚Äôesecuzione concorrente delle transazioni.
- Consistency √® garantita dal DBMS verificando che le transazioni rispettino i vincoli definiti a livello di schema del DB.
- Durability: le operazioni della transazioni devono persistere nel tempo.

Date due transazioni queste possono essere: seriali e quindi la somma del tempo di esecuzione delle due transazioni √® il tempo totale di esecuzione, oppure concorrenti e in questo caso si riduce il tempo di risposta.

<img src="./img/img68-light.png#gh-light-mode-only" alt="Seriale vs Concorrente">
<img class="dark-mode" src="./img/img68-dark.png#gh-dark-mode-only" alt="Seriale vs Concorrente">

Eseguire pi√π transazioni concorrentemente √® necessario per garantire buone prestazioni: si sfrutta il fatto che, mentre una transazione √® in attesa del completamento di una operazione di I/O, un‚Äôaltra pu√≤ utilizzare la CPU.

La concorrenza per√≤ va gestita, se le varie transazioni interferiscono tra di loro possiamo avere problemi in lettura e in scrittura. Infatti, ci sono quattro problemi principali quando si eseguono le transazioni in modo concorrente:

- **Lost Update**: due persone entrano sulla stessa riga e con la perdita di stato, per esempio entrambe comprano l‚Äôultimo biglietto rimasto.
- **Dirty Read**: qualora si voglia acquistare un biglietto per una certa data questa data √® cambiata nel frattempo. 
- **Unrepeatable read**: letto il prezzo di un biglietto dopo qualche minuto il prezzo cambia.
- **Phantom row**: nel caso in cui si vogliano comprare i biglietti di due tappe nel momento il cui si va a verificare l‚Äôacquisto le tappe sono cambiate di numero.

[Torna all'indice](#indice)

#### Lost Update

Il seguente schedule mostra un caso tipico di lost update, in cui per comodit√† si evidenziano anche le operazioni che modificano il valore del dato X e si mostra come varia il valore di X nel DB. Il problema nasce perch√© T2 legge il valore di X prima che T1 (che lo ha gi√† letto) lo modifichi (entrambe vedono l‚Äôultimo biglietto disponibile).

<img src="./img/img41-light.png#gh-light-mode-only" alt="Lost Update">
<img class="dark-mode" src="./img/img41-dark.png#gh-dark-mode-only" alt="Lost Update">

[Torna all'indice](#indice)

#### Dirty Read

In questo caso il problema √® che una transazione legge un dato che non c‚Äô√®: quanto svolto da T2 si basa su un valore di X _intermedio_, e quindi non stabile (la data definitiva non √® il 15/07/10). Le conseguenze sono impredicibili (dipende cosa fa T2) e si presenterebbero anche se T1 non abortisse.

<img src="./img/img42-light.png#gh-light-mode-only" alt="Dirty Read">
<img class="dark-mode" src="./img/img42-dark.png#gh-dark-mode-only" alt="Dirty Read">

[Torna all'indice](#indice)

#### Unrepeatble Read

Ora il problema √® che una transazione legge due volte un dato e trova valori diversi (il prezzo nel frattempo √® aumentato):

<img src="./img/img69-light.png#gh-light-mode-only" alt="Unrepeatble Read">
<img class="dark-mode" src="./img/img69-dark.png#gh-dark-mode-only" alt="Unrepeatble Read">

Anche in questo caso si possono avere gravi conseguenze. Lo stesso problema si presenta per transazioni di _analisi_. Ad esempio T1 somma l‚Äôimporto di 2 conti correnti mentre T2 esegue un trasferimento di fondi dall‚Äôuno all‚Äôaltro (T1 potrebbe quindi riportare un totale errato).

[Torna all'indice](#indice)

#### Phantom Row

Questo caso si pu√≤ presentare quando vengono inserite o cancellate tuple che un‚Äôaltra transazione dovrebbe logicamente considerare. Nell‚Äôesempio la tupla t4 √® un _phantom_, in quanto T1 non la vede.

![single tier](./img/img43.png)

[Torna all'indice](#indice)

#### Livelli di Isolamenti

Scegliere di operare a un livello di isolamento in cui si possono presentare dei problemi ha il vantaggio di aumentare il grado di concorrenza raggiungibile, e quindi di migliorare le prestazioni. Lo standard SQL definisce 4 livelli di isolamento, che sono serializable, repeatable read, read committed, uncommitted read:

- `ISOLATION_READ_UNCOMMITTED`: possono accadere letture sporche (dirty read), non ripetibili e fantasma (phantom read).
- `ISOLATION_READ_COMMITTED`: letture sporche rese impossibili, possibilit√† di accadimento di letture non ripetibili e fantasma.
- `ISOLATION_REPEATABLE_READ`: possibilit√† delle sole letture fantasma, dirty e non-repeatable rese non possibili.
- `ISOLATION_SERIALIZABLE`: tutte le possibilit√† spiacevoli sopra elencate per la lettura sono rese impossibili. Viene garantita le propriet√† ACID.

[Torna all'indice](#indice)

### Transazionalit√†

Con scarsa sorpresa in Spring, si chiama transazione locale, una transazione specifica per una singola risorsa transazionale, ad esempio un'unica risorsa di un database, mentre si chiama transazione globale, una transazione gestita dal container, questa pu√≤ includere risorse  multiple e distribuite. Il programmatore pu√≤ specificare in modo dichiarativo che un metodo di Bean deve avere propriet√† transazionali. Anche l‚Äôimplementazione delle transazioni √® basata su AOP, infatti avviene l‚Äôintercettazione di chiamate a metodi per la gestione transazioni. Nessuna necessit√† di modificare la logica di business, n√© al cambio della transazionalit√† desiderata n√© al cambio del provider di transazionalit√†.

In Spring, i livelli di propagazione delle transazioni sono:

- `PROPAGATION_REQUIRED`: supporto alla propagazione della transazione di partenza. Crea una nuova transazione se non era transazionale il contesto di partenza.
- `PROPAGATION_SUPPORTS`: supporto alla propagazione della transazione di partenza, esegue non transazionalmente se la partenza non era transazionale.
- `PROPAGATION_MANDATORY`: supporto alla propagazione della transazione di partenza; lancia un‚Äôeccezione se la partenza non era transazionale.
- `PROPAGATION_REQUIRES_NEW`: crea una nuova transazione, sospendendo quella di partenza, se esistente.
- `PROPAGATION_NOT_SUPPORTED`.
- `PROPAGATION_NEVER`.
- `PROPAGATION_NESTED`.

[Torna all'indice](#indice)

### Pooling e concorrenza

Alla base dell‚Äôarchitettura Spring, c‚Äô√® l‚Äôidea di Inversion of Control (prima che in EJB 3.0) e di container leggeri per factory per l‚Äôistanziazione, il ritrovamento e la gestione delle relazioni fra oggetti. Le factory supportano due modalit√† di oggetto:

- **Singleton (default)**: singleton vuol dire che il primo cliente che chiede alla `BeanFactory` un'istanza logica di un componente di classe `Pippo`, dato che non esiste, viene creata un'istanza, viene inizializzata, risolte le dipendenze e poi la restituir√† al cliente. Un secondo cliente chiede alla `BeanFactory` una propria istanza logica, allora la gestione a singleton porter√† la `BeanFactory` di restituire sempre un riferimento all'istanza gi√† generata in precedenza. Ideale per oggetti stateless perch√® questo riduce la proliferazione di istanze nel codice applicativo.
- **Prototype**: ogni operazione di ritrovamento di un oggetto produrr√† la creazione di una nuova istanza. Ideale per oggetti statefull.

La modalit√† singleton di Spring √® vicina a quella di EJB stateless perch√® non c'√® lo stato ma √® diversa perch√® in Spring non c'√® un pool di thread. Lo stesso vale per prototype che si avvicina agli EJB statefull ma sono diversi perch√® ogni volta quando si invoca `getBean()`, viene restituita una nuova istanza dedicata senza ottimizzazione di carico (non c'√® activation e passivation). Inoltre, in Spring le richieste non vengono intercettate per cui √® necessario crearsi a mano un altro `BeanFactory` che funge da proxy utilizzando ad esempio con AOP (concettualmente simile a interception in EJB, ma di pi√π semplice utilizzo).

[Torna all'indice](#indice)

### Autowiring

Spring pu√≤ occuparsi automaticamente di risolvere dipendenze tramite introspezione delle classi Bean. In questo modo, il programmatore pu√≤ dimenticarsi di specificare esplicitamente le propriet√† del Bean o gli argomenti del costruttore nel file XML. Le propriet√† del Bean sono risolte attraverso il matching basato su nome o su tipo:

- `autowire="name"` (configurazione di default): l‚Äôautowiring pu√≤ essere effettuato sui nomi delle propriet√† (metodi di nome `set()` del Bean).
- `autowire="type"`: il match viene fatto sui tipi degli tipi delle propriet√† del Bean (`set(ArgumentType arg)`).
- `autowire="constructor"`, il match viene fatto sui tipi degli argomenti del costruttore.

Anche in EJB esiste la stessa risoluzione delle dipendenze attraverso JNDI.

[Torna all'indice](#indice)

### Dependency checking

Il dependecy checking √® utilizzabile per controllare l‚Äôesistenza di dipendenze non risolte senza ricevere spiacevoli sorprese quando √® gi√† fatto il deployment di un Bean all‚Äôinterno di un container Spring. √à utile per tutte le propriet√† che non hanno valori configurati all‚Äôinterno della definizione del Bean, per i quali anche l‚Äôautowiring non ha prodotto alcun setting. Questa √® una caratteristica utile quando ci si vuole assicurare che tutte le propriet√† (o tutte le propriet√† di un determinato tipo) siano state configurate correttamente su un Bean. Vi sono diverse modalit√† possibili e configurabili:

- none: nessun check;
- simple: dependency checking effettuato solo per tipi primitivi e collection;
- object: dependency checking effettuato solo per altri bean associati all‚Äôinterno della stessa factory cio√® quando √® presente il tag ref local (collaborator);
- all: dependency checking effettuato per collaborator, tipi primitivi e collection.

[Torna all'indice](#indice)

### ApplicationContext

Per accedere ad alcune funzionalit√† avanzate di Spring, non √® sufficiente l‚Äôuso della semplice interfaccia `BeanFactory`, l‚Äô`ApplicationContext` √® l‚Äôestensione dell‚Äôinterfaccia `BeanFactory`. Questo oltre a fornire tutte le funzionalit√† base, integra la gestione delle transazioni e di AOP, ad esempio, non supportate dalla `BeanFactory` di base. `ApplicationContext` si utilizza in modalit√† pi√π _tradizionale_ e quindi framework-oriented cio√® invocando dal codice direttamente la chiamata di cui si ha bisogno. Le funzionalit√† aggiuntive dell‚Äô`ApplicationContext` non sono supportante di base dal `BeanFactory` perch√© in un‚Äôottica di container leggeri questo appesantirebbe tale interfaccia. Tra le funzionalit√† aggiuntive di `ApplicationContext` vi sono ad esempio:

- Gestione delle transazioni.
- Propagazione di eventi a Bean che implementano l‚Äôinterfaccia `ApplicationListener`.
- Accesso a risorse come URL e file.

Per aggiungere l‚Äô`ApplicationContext` e collegarlo alla gestione del ciclo di vita del Bean, bisogna prendere l‚Äôinterfaccia `ApplicationContextAware`, implementarla in modo da poter aggiungere il metodo di interfaccia `setApplicationContext()` che verr√† automaticamente invocato alla creazione del Bean stesso che ricever√† cos√¨ un riferimento al contesto su cui poter effettuare invocazioni:

```
public class Publisher implements ApplicationContextAware {

    private ApplicationContext ctx; 
    
    // Questo metodo sar√† automaticamente invocato da IoC container 
    public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { 
        this.ctx = applicationContext;
    }

}
```

La gestione degli eventi in `ApplicationContext` √® realizzata tramite la classe `ApplicationEvent` e l‚Äôinterfaccia `ApplicationListener` che consente la ricezione degli eventi. Se un Bean implementa l‚Äôinterfaccia `ApplicationListener` deve fare la sottoscrizione ad un `ApplicationContext` ac1. Quel Bean viene notificato ogni volta che un `ApplicationEvent` viene pubblicato in ac1. In poche parole, si tratta del design pattern `Observer`. Ci sono tre tipologie di eventi built-in:

- `ContextRefreshEvent` che consente l‚Äôinizializzazione o refresh di `ApplicationContext`.
- `ContextClosedEvent` per la chiusura di un `ApplicationContext`.
- `RequestHandleEvent` evento specifico per il Web, significa che una richiesta HTTP √® stata appena servita.

Ad esempio, qui si mostra la configurazione in `ApplicationContext.xml `del comportamento "ad ogni ricezione di un'email da un indirizzo in black list, invia un email di notifica a "spam@list.org":

```
<bean id="emailer" class="example.EmailBean">
    <property name="blackList">
        <list>
            <value>black@list.org</value>
            <value>white@list.org</value>
            <value>john@doe.org</value>
        </list>
    </property>
</bean>
<bean id="blackListListener" class="example.BlackListNotifier">
    <property name="notificationAddress" value="spam@list.org"/>
</bean>
```

La classe Bean che pubblica eventi tramite l‚Äôoggetto `ApplicationContext`:

```
public class EmailBean implements ApplicationContextAware {

    private List blackList;
    
    public void setBlackList(List blackList) {
        this.blackList = blackList;
    }

    public void setApplicationContext(ApplicationContext ctx) {
        this.ctx = ctx;
    }

    public void sendEmail(String address, String text) {
        
        if (blackList.contains(address)) {
            BlackListEvent evt = new BlackListEvent(address, text);
            ctx.publishEvent(evt); return;
        }
    }
}
```

La classe `Notifier` riceve le notifiche degli eventi generati:

```
public class BlackListNotifier implement ApplicationListener {

    private String notificationAddress;
    
    public void setNotificationAddress(String notificationAddress) {
        this.notificationAddress = notificationAddress;
    }

    public void onApplicationEvent(ApplicationEvent evt) {
        if (evt instanceof BlackListEvent) {
            // invio dell‚Äôemail di notifica all‚Äôindirizzo appropriato
        }
    }

}
```

[Torna all'indice](#indice)

## JMX

Come gi√† detto pi√π volte, si √® interessati non solo alla fase di sviluppo, ma anche all'esecuzione in ambiente reale dell‚Äôarchitettura enterprise. In questo caso, si √® particolarmente interessati al monitoraggio del sistema, quindi, vi √® la necessit√† di controllo on-line e conseguenti azioni di gestione, non solo di network equipment, ma anche di componenti applicativi e di servizio. Gli obiettivi del monitoraggio sono: la fault detection, misura di performance e riconfigurazione/re-deployment, identificazione dei colli di bottiglia. I modelli utilizzati nel monitoraggio sono i seguenti: push vs. pull, azioni reattive vs. proattive, approccio ottimistico vs. pessimistico, con manager centralizzato vs. parzialmente distribuito vs. completamente distribuito. √à importante avere protocolli e API standard per misurare le performance trattando in un certo senso il software come l‚Äôhardware dal punto di vista del monitoraggio e della misurazione.

Protocollo SNMP per la gestione e il management del mondo del networking. SNMP rappresenta uno standard, allo stesso modo si vogliono avere standard per il monitoraggio nel mondo distribuito in ambienti aperti e interoperabili. Per fare un esempio, Distributed Management Task Force (DMTF) √® un‚Äôorganizzazione per la standardizzazione per IT system management in ambienti industriali e in Internet. Gli standard DMTF permettono la costruzione di componenti per system management indipendenti dalla piattaforma e technology-neutral, abilitando cos√¨ interoperabilit√† fra prodotti per la gestione di sistemi di diversi vendor, alcuni elementi fondamentali in DMTF sono: Common Information Model (CIM), Common Diagnostic Model (CDM), Web-Based Enterprise Management (WBEM). Common Information Model (CIM) √® un modello astratto per la rappresentazione degli elementi gestiti (ad esempio, computer o storage area network) come insieme di oggetti e relazioni. CIM √® estensibile per consentire l‚Äôintroduzione di estensioni product-specific e svolge la stessa funzione del CMIB per SNMP. Common Diagnostic Model (CDM) √® un modello di diagnostica e definizione di come questo debba essere incorporato nell‚Äôinfrastruttura di management, infine Web-Based Enterprise Management (WBEM) √® un insieme di protocolli per l‚Äôinterazione fra componenti di system management (conformi a CIM e ai suoi profili) e la loro interrogazione. I profili in generale sono utilizzati in data-model molto estesi con diversi diritti e operazioni.

[Torna all'indice](#indice)

### Java Management Extensions (JMX)

Il contesto nel quale si √® inserita la specifica Java √® quella del monitoraggio nell‚Äôambiente distribuito, prima del framework Java Management Extensions (JMX) non vi era nessun approccio standardizzato in Java per far partire, gestire, monitorare e fermare l‚Äôesecuzione di componenti software.

![single tier](./img/img124.png)

I componenti software conformi alla specifica JMX vengono chiamati MBean ovvero Managed Bean. Questi MBean sono gestiti attraverso un agente che svolge il ruolo di registry, offre alle applicazioni di management (clienti di tale agente) un modo di effettuare query, interrogare i Bean e modificare i bean gestiti. L‚Äôutilizzo dell‚Äôagente consente di non avere collegamenti diretti tra componenti MBean e cliente (di management), quindi, l‚Äôagente in un certo senso rende trasparenti gli MBean. In questo modo il cliente pu√≤ demandare all‚Äôagente intermedio alcune funzionalit√† di management e questo porta a un‚Äôottimizzazione perch√© questi Managed Bean sono pi√π locali rispetto all‚Äôagente che non rispetto al cliente che magari deve comunicare attraverso internet.

### Architettura

JMX realizza e sfrutta, ancora una volta, il ben noto
principio di decoupling. Tutte le comunicazioni fra clienti e MBean avvengono attraverso il livello intermedio dell‚Äôagente.

![single tier](./img/img71.png)

JMX √® organizzato secondo un‚Äôarchitettura a tre livelli: 

- I componenti gestiti appartengono al livello Instrumentation.
- Il livello agente √® costituito dal registro per gli MBean (MBeanServer) e da alcuni servizi standard addizionali questo perch√© non c‚Äô√® mai un collegamento diretto tra cliente ed MBean.
- Il livello dei servizi distribuiti √® costituito da adattatori e connettori (adaptor e connector), necessari per supportare l‚Äôaccesso remoto al livello agente, verso web-server o altre interazioni.

### Livello instrumentation

Il livello instrumentation definisce come creare risorse gestibili tramite JMX (MBeans), ovvero oggetti che offrono metodi per interagire attraverso dei metodi per:

- La gestione di un‚Äôapplicazione.
- La gestione di un componente software.
- La gestione di un servizio.
- La gestione di un dispositivo.

JMX definisce quattro tipi di componenti MBean:

- **Standard MBean**: √® un MBean statico, creato dichiarando esplicitamente un'interfaccia Java con l‚Äôinformazione di management che l‚Äôoggetto gestito implementa.
- **Dynamic MBean**: pi√π dinamico, √® un oggetto che implementa l‚Äôinterfaccia `DynamicMBean` in cui ci sono oggetti di metalivello che specificano tutte le operazioni di management del MBean stesso.
- **Model MBean**: √® un DynamicMBean esteso con descrittori addizionali che definiscono propriet√† aggiuntive come behavioral properties, funzionalit√† orizzontali di persistenza, sicurezza, etc.
- **Open MBean**: (non di implementazione obbligatoria per essere conformi alla specifica) √® un MBean in cui i tipi utilizzati nei metodi di management hanno il vincolo ulteriore di essere inclusi in un set predefinito di classi e tipi di base, sottoinsieme di funzionalit√† standardizzate.

Il supporto ai primi tre tipi di MBean √® mandatory a partire dalla specifica JMX 1.0, si ricorda che JMX √® una specifica, con diverse implementazioni possibili, come quella di Sun o IBM Tivoli.

### Livello Agente

Il livello di agente √® costituito da un server MBean e da un insieme di servizi di agente basati sul livello di instrumentation. Vi sono quattro servizi di agente definiti nella specifica JMX: M-Let, Timer, Monitoring e Relation. Inoltre, il livello agente introduce il concetto di naming per gli oggetti, nomi che il lato cliente pu√≤ utilizzare come riferimento indiretto alle risorse gestite.

![single tier](./img/img72.png)

Il server MBean √® uno dei componenti chiave dell‚Äôarchitettura di management, esso opera come un canale di comunicazione che smista e delega tutte le invocazioni fra applicazioni di management e risorse gestite. Espone metodi per la creazione ed effettuazione di query, per invocare operazioni e per manipolare attributi su MBean. Il tipo di implementazione dei componenti MBean (Standard, Dynamic, Model, etc) √® totalmente trasparente alle applicazioni client-side di gestione, l‚ÄôMbean Server nascondendo tale implementazione semplifica anche le cose lato client.

MBeanServer √® un oggetto locale alla JVM dei componenti gestiti e non offre particolare supporto alla connessione remota. Per questo servono connettori JMX o adattatori di protocollo per accettare chiamate provenienti dall‚Äôesterno della JVM. Questi componenti (connettori/adattatori) sono spesso essi stessi degli MBean, registrati sull‚Äôagente, e forniscono una pluralit√† di differenti forme di connettivit√†.

### Livello servizi distribuiti

I connettori JMX sono strutturati in due componenti:

- Lato server, l‚Äôagente registra un server per le connessioni capace di ricevere invocazioni remote di metodo.
- Lato cliente, si pu√≤ utilizzare una vista remota del server MBean per invocare operazioni su di esso.

![single tier](./img/img73.png)

Gli adattatori di protocollo sono implementati solo lato server MBean, questi possono adattare operazioni server MBean del mondo JMX per interagire con protocolli preesistenti, o anche verso diversi modelli di informazioni, come SNMP Management Information Base, permettendo ad app di management legacy o a strumenti non-Java di interoperare con JMX.

La specifica JMX Remote API definisce come si possa fare l‚Äôadvertising e trovare agenti JMX usando infrastrutture di discovery e lookup esistenti, la specifica **non** definisce un ulteriore servizio di discovery e lookup, ma la tecnologia JMX offre una soluzione standard per l‚Äôesportazione delle API di JMX instrumentation verso applicazioni remote, basata su RMI. Inoltre, JMX Remote API definisce un protocollo opzionale, non-mandatory e pi√π efficiente, basato direttamente su socket TCP, chiamato JMX Messaging Protocol (JMXMP) per garantire la massima interoperabilit√†.

### Standard MBean

Lo standard MBean √® il modo pi√π semplice per rendere JMX-managed nuove classi Java. L'interfaccia √® statically-typed e dichiara esplicitamente gli attributi tramite metodi `getter` e `setter` e le operazioni di gestione. Convenzione sui nomi: quando un managed object viene registrato, l‚Äôagente cerca una interfaccia di management con lo stesso nome classe dell‚Äôoggetto + suffisso MBean, nel caso, navigando l‚Äôalbero di ereditariet√† della classe:

```java
public interface UserMBean{

    public long getId();
    public void setId(long id);
    public boolean isActive();
    public void setActive(boolean active);
    public String printInfo();
}

public class User implements UserMBean { ... }

public class Student extends User {

    /* anche questa classe pu√≤ essere registrata come un UserMBean */
    
    ...

}
```

### Registrazione MBean su Server

Per registrare un manageable object come un MBean √® necessario creare prima `ObjectName`. Il riferimento all‚Äôagente pu√≤ essere ottenuto da una lista di implementazioni disponibili di MBeanServer o creandolo da zero:

```java
ObjectName username = new ObjectName("example:name=user1");

List serverList = MBeanServerFactory.findMBeanServer(null);
MBeanServer server = (MBeanServer)serverList.iterator().next();

/* oppure se prima si deve creare il MBeanServer
MBeanServer server = MBeanServerFactory.createMBeanServer();*/

server.registerMBean(new User(), username);
```

La registrazione di MBean consiste semplicemente nell‚Äôassociare il manageable object con il suo nome di oggetto, una volta trovato l‚ÄôMBean server.

### Invocazione servizi di gestione

L‚Äôapplicazione di management riferisce MBean passando un riferimento a object name all‚Äôagente, per ogni operazione invocata:

```java
ObjectName username = new ObjectName("example:name=user1");

Object result = server.invoke(
    username, // nome MBean
    "printInfo", // nome operazione
    null, // no param
    null); // void signature
```

Server MBean cerca il riferimento Java corrispondente a MBean nel suo repository interno e invoca l‚Äôoperazione corrispondente (o la modifica dell‚Äôattributo) su MBean, tutto questo nascondendo le operazioni al cliente

### Meccanismo di notifica

L‚Äôarchitettura JMX definisce un meccanismo di notifica per MBean che consente di inviare eventi verso altri MBean o applicazioni di management. Gli MBean che vogliono emettere eventi di management devono implementare l‚Äôinterfaccia `NotificationBroadcaster`, gli oggetti listener per gli eventi devono invece implementare l‚Äôinterfaccia `NotificationListener` e devono effettuare loro subscription presso Mbean (locale o remoto) che fa da broadcaster. Questa subscription √® fatta attraverso il livello di agente. Le operazioni di notifica svolte da broadcaster MBean sono parte della loro interfaccia di management JMX: le applicazioni possono effettuare query sul livello agent per avere info su quali tipi di notifica gli MBean di interesse possono emettere, a tal fine, MBean broadcaster forniscono oggetti `MBeanNotificationInfo`.

La classe JMX `Notification` estende `EventObject` introducendo campi per il tipo di evento, numero di sequenza, timestamp, messaggio e dati utente opzionali, perci√≤ le notifiche possono essere filtrate, grazie all‚Äôimplementazione dell‚Äôinterfaccia `NotificationFilter` √® subscribed presso broadcaster MBean, insieme con il listener con il metodo `addNotificationListener()`, il broadcaster deve controllare se la notifica supera il filtro prima di inviarla.

```java
public interface NotificationFilter {

    public boolean isNotificationEnabled(Notification notification);
}

public interface NotificationBroadcaster {

    public void addNotificationListener(NotificationListener listener, NotificationFilter filter, Object handback) throws IllegalArgumentException;
}
```

Poich√© l‚Äôimplementazione di broadcaster MBean pu√≤ diventare anche piuttosto complessa, √® messa a disposizione una classe `NotificationBroadcasterSupport` che implementa l‚Äôinterfaccia `NotificationBroadcaster`. In questo modo i propri broadcaster MBean possono: estendere tale classe per ereditare quella implementazione dei metodi di broadcasting oppure delegare a questa classe il supporto alla gestione delle registrazioni e all‚Äôinvocazione delle notifiche. Il meccanismo di notifica √® generico e adatto a qualsiasi tipo di notifica user-defined. Comunque, JMX definisce la specifica classe `AttributeChangeNotification` per MBean che vogliano inviare notifiche sul cambiamento dei loro attributi di management, l‚Äôidea di questa classe √® facilitare la creazione di aventi di notifica per il cambio degli attributi.

### Dynamic MBean

MBean dinamici implementano l‚Äôinterfaccia generica `DynamicMBean` che offre metodi all‚Äôagente per fare il discovery di metodi e attributi di management (reale interfaccia di gestione), l‚Äôagente del server pu√≤ usare questa interfaccia per recuperare gli attributi degli MBean. I metadati che descrivono l‚Äôinterfaccia di management sono completamente sotto la responsabilit√† dello sviluppatore, mentre nello Standard MBean i metadati vengono generati dall‚Äôagente stesso tramite introspezione. Casi possibili di utilizzo di Dynamic MBean sono le situazioni in cui l‚Äôinterfaccia di management pu√≤ cambiare spesso, oppure per la necessit√† di abilitare facilmente il management su risorse esistenti.

![single tier](./img/img130.png)

In MBean dinamici, l‚Äôinterfaccia di management viene esposta tramite le classi di metadata definite in JMX API, i metadata sono ritrovati dinamicamente dall‚Äôagente come istanza della classe `MBeanInfo`, tale classe include tutti gli elementi di metadata, i quali ereditano caratteristiche comuni dalla classe `MBeanFeatureInfo`. Quindi, le informazioni che sono dentro a `MBeanInfo` possono essere modificate anche runtime. Se si ha una classe `Pippo`, e tramite `geBeanInfo()` si ottiene l'oggetto `BeanInfo` per poi andarlo a popolare.

```java
public class DynamicUser extends NotificationBroadcasterSupport implements DynamicMbean {

    // Attributi
    final static String ID = "id";
    private long id = System.currentTimeMillis();
    public Object getAttribute(String attribute) throws AttributeNotFoundException, MBeanException, ReflectionException {
        if (attribute.equals(ID))
            return new Long(id);
            throw new AttributeNotFoundException("Missing attribute " + attribute);
    }
    
    // Operazioni
    final static String PRINT = "printInfo";

    public String printInfo() {
        return "Sono un MBean dinamico";
    }

    public Object invoke(String actionName, Object[] params, String[] signature) throws ... {
        
        if (actionName.equals(PRINT))
            return printInfo();
            throw new UnsupportedOperationException("Unknown operation" + actionName);
    }

    // da definire all'interno della classe DynamicUser
    public MBeanInfo getMBeanInfo() {

        final boolean READABLE = true;
        final boolean WRITABLE = true;
        final boolean IS_GETTERFORM = true;
        String classname = getClass().getName();
        String description = "Sono un MBean dinamico";

        MBeanAttributeInfo id = new MBeanAttributeInfo(ID,long.class.getName(), "id", READABLE, !WRITABLE, !IS_GETTERFORM);
        MBeanConstructorInfo defcon = new MBeanConstructorInfo("Default", "Creates", null);
        MBeanOperationInfo print = new MBeanOperationInfo(PRINT, "Prints info", null, String.class.getName(), MBeanOperationInfo.INFO);

        return new MBeanInfo(classname,description, 
        new MBeanAttributeInfo[] { id }, 
        new MBeanConstructorInfo[] { defcon }, 
        new MBeanOperationInfo[] { print }, 
        null);
    }
}
```

Prima di fare la chiamata al metodo `invoke`, `MBeanInfo()` e va a leggere i metadati che corrispondono all'operazione. Se c'√® un match con la richiesta, si pu√≤ procedere ad eseguirla altrimenti no. I controlli vengono eseguiti tramite esplorazione dei metadati contenuti dentro a `MBeanInfo()` e vanno scritti dal programmatore.

### ModelMBean

Model MBean sono estensioni di MBean dinamici, essi forniscono un template generico per creare un‚Äôimplementazione di gestione per risorse esistenti, separare l‚Äôimplementazione di management dall‚Äôimplementazione della risorsa, ed estendere metadata di gestione per fornire informazioni addizionali e propriet√† behavioral per la gestione di queste funzionalit√† trasversali: come propriet√† di caching, propriet√† di sicurezza, propriet√† di transazionalit√†, propriet√† di persistenza. Tutte le implementazioni di JMX MBean server devono fornire almeno una implementazione dell‚Äôinterfaccia `ModelMBean` tramite la classe `RequiredModelMBean`.

```java
public interface ModelMBean extends DynamicMBean,
  PersistentMBean,
  ModelMBeanNotificationBroadcaster {

    public void setModelMBeanInfo( ModelMBeanInfo inModelMBeanInfo) throws ... ;

    public void setManagedResource(Object mr, String mr_type) throws ... ;
}

public class RequiredModelMBean implements ModelMBean, ... {

    ...

}
```

Per aggiungere politiche di gestione dei Model MBean si utilizza l‚Äôinterfaccia `Descriptor`, gli oggetti che implementano l‚Äôinterfaccia `Descriptor` sono usati nei metadati di Model MBean per aggiungere politiche. Un descrittore √® una collezione di coppie nome-valore in base alle quali l‚Äôimplementazione dell‚Äôagente adatta il suo comportamento, le classi di metadata di Model MBean estendono le classi corrispondenti usate con MBean dinamici e standard (implicitamente) e implementano l‚Äôinterfaccia `DescriptorAccess`.

```java
public interface Descriptor extends Serializable, Cloneable
{
    public String[] getFields();
    public void setField(String name, Object value);
    public void removeField(String name);

    ...

}
```

### Servizi Standard a Livello di Agente

La specifica JMX definisce quattro servizi distinti a livello di agente che devono essere disponibili su ogni implementazione conforme alla specifica:

- **M-Let Service** che permette agli MBean di essere caricati dalla rete e inclusi nel livello di agente dinamicamente a runtime.
- **Timer Service** √® uno scheduler che si occupa dell‚Äôinvio di notifiche agli altri MBean.
- **Monitoring Service** √® un MBean che svolge il ruolo di osservatore per gli attributi di management degli altri bean e che notifica le modifiche avvenute.
- **Relation Service** permette di creare associazioni fra MBean e mantiene la loro consistenza.

### Servizio di M-let

Gestisce il loading dinamico di nuove classi Java dal server MBean, che possono trovarsi su macchina locale o su macchina remota, con l‚Äôidea di spostare delle configurazioni di una applicazione verso un server remoto. Come ogni altro standard MBean, l‚Äôinterfaccia `MLetMBean` espone le operazioni di management considerate rilevanti per il servizio, come `addURL()` e `getMBeansFromURL()`. All‚ÄôURL specificato da `addURL()` si trovano i file di testo M-Let che descrivono i componenti MBean tramite MLET tag. Sposta la configurazione da macchina locale a macchina remota.

```xml
<MLET CODE = class | OBJECT =
    serfile
    ARCHIVE = "archiveList"
    [CODEBASE = codebaseURL]
    [NAME = MBeanName]
    [VERSION = version] >
    [arglist]
</MLET>
```


Ad esempio, si vuole fare un'installazione JMX in diversi uffici di un'azienda e prevede che in una rete locale ci sia un MBean Server che abbia servizi `A`, `B` e `C` a livello agente. Senza M-let, bisognerebbe installare i nodi tutti i servizi `A`, `B` e `C` ma grazie a M-let si pu√≤ velocizzare il processo. Un possibile file potrebbe essere:

```xml
<MLET CODE=com.mycompany.Foo
    ARCHIVE=‚ÄúMyComponents.jar,acme .jar‚Äù
</MLET>
```

### Servizio di Timer

Il servizio di Timer √® basato sul meccanismo di notifica di JMX. TimerMBean √® un broadcaster MBean in grado di emettere eventi, per ricevere notifiche dal timer il consumatore deve implementare l‚Äôinterfaccia `NotificationListener` e registrarsi:

```java
// fa partire il servizio di timer
List list = MBeanServerFactory.findMBeanServer(null);
MBeanServer server = (MBeanServer)list.iterator().next();
ObjectName timer = new ObjectName("service:name=timer");
server.registerMBean(new Timer(), timer);
server.invoke(timer,"start", null, null);

// configurazione di notification time
Date date = new Date(System.currentTimeMillis() + Timer.ONE_SECOND * 5);

server.invoke(timer, // MBean
"addNotification", // metodo
new Object[] { // args
    "timer.notification", // tipo
    "Schedule notification", // messaggio
    null,  // user data
    date}, // time
new String[] { String.class.getName(),
    String.class.getName(),
    Object.class.getName(), // signature
    Date.class.getName()} );

// registra il listener MBean
server.addNotificationListener(timer, this, null, null);
```

Questo √® analogo al servizio di Cron in Unix/Linux o a Task Scheduler Service su Windows NT. Per impostare il tutto √® possibile recuperare il servizio di timer quindi una volta registrato presso il server si pu√≤ richiedere l‚Äôavvio del timer.

### Servizio di Monitoring

Un insieme di MBean che possono essere utilizzati per effettuare il monitoring degli attributi di risorse gestite. Gli attributi sono variabili di stato che vengono risposte tramite interfaccia di management perch√® ci sono metodi `getter` e `setter` che possono andarli a modificarli. Le notifiche dei monitor differiscono dalle usuali notifiche di modifica di attributi perch√© si possono introdurre threshold (soglia) e periodi di granularit√†.

![single tier](./img/img75.png)

Vi sono tre implementazioni differenti:

- **Counter monitor** traccia le variazioni di attributi che si comportano come contatori con variazioni discrete. Ad esempio, una variabile `x` che √® attributo di un MBean ed √® un `Integer` e varia solo discretamente (0, 1, 2 etc).
- **Gauge monitor** per attributi `Integer` e `Float`, ad intervalli di granularit√† configurabile, con threshold. Vengono lanciate notifiche solo quando il valore soglia viene superato: o da un valore soglia tramite offset si calcola l'intervallo di offset (figura in alto) oppure si possono definire due valori soglia distinti (figura in basso).
- **String monitor** viene lanciata una notifica quando la stringa monitorata come attributo fa matching/dismatching con il valore di configurazione.

![single tier](./img/img74.png)

Da come si pu√≤ notare nella figura, la notifica non viene mai inviata quando si supera il valore soglia ma c'√® sempre un p√≤ di latenza perch√® si va a vedere il valore dell'attributo ogni tot secondi dato che ci√≤ introduce un costo (periodo di granularit√†). Un altro problema √® qunado ci sono attributi _rumorosi_, √® impensabile ad ogni variazione di segnarla al listener, per questo si cercano di fare monitoring con delle isteresi di tempo o di confidenza sugli attributi. Gli eventi sono sollevati solo quando vi sono variazioni significative. Le notifiche partono o dopo un periodo di tempo o al superamento di una certa soglia. Queste threshold servono per evitare un overhead del sistema di monitoraggio, deve occupare il 10% del carico del sistema, cos√¨ si vogliono evitare effetti di schizofrenia nelle azioni di gestioni dipendenti dal monitoraggio.

### Servizio di Relation

Permette di definire relazioni fra altri MBean e di reagire a modifiche (per esempio nel caso di dipendenze). Ad esempio, `Mbean A` deve essere presente se e solo se √® presente `MBean B`. Le notifiche sono emesse modifica nelle istanze di relazione (creazione, aggiornamento, rimozione di una di queste relazioni etc). Ad esempio, se `MBean A`, se √® registrato, deve avere per forza avere sullo stesso MBean Server anche `MBean B` e viceversa. Se c'√® la de-registrazione di uno dei due viene lanciata una notifica.

### JMX remote API

Dall‚Äôarchitettura iniziale ci si ricorda che c‚Äô√® una parte client e server con disaccoppiamento forte per ottenere la massima flessibilit√† delle interazioni dei client con MBean che siano compliant JMX. I connettori sono pezzetti software distribuiti che aiutano a collegare un'applicazione di management con l'MBean Server costituiti da un pezzettino client side (vicino al cliente che funge da Stub) e un pezzettino server side (vicino al MBean Server che funge da Skeleton). In ogni distribuzione JMX, deve esistere sempre l'implementazione del connettore RMI. Inoltre, √® disponibile un Registry RMI dove reperire uno stub RMI per il connettore.

```java
// lato cliente

JMXServiceURL url = new JMXServiceURL(service:jmx:rmi:///jndi/rmi://" + "localhost:9999/server");

JMXConnector jmxc = JMXConnector-Factory.connect(url, null);

MBeanServerConnection mbsc = jmxc.getMBeanServerConnection;

mbsc.createMBean(...);
```

Il cliente crea un RMI Connector Client configurato per connettersi al server RMI connector creato lato server: URL di servizio utilizzato deve fare match con quello usato alla registrazione del servizio di connector. Il connector client √® restituito come risultato della connessione al connector server, il cliente ora pu√≤ registrare MBean ed effettuare operazioni su di essi tramite MBeanServer remoto in modo trasparente alla distribuzione.

```java
// lato servitore
MBeanServer mbs = MBeanServer-Factory.createMBeanServer();
JMXServiceURL url = new JMXServiceURL("service:jmx:rmi:///jndi/rmi://" + "localhost: 9999/server");
JMXConnectorServer cs = JMXConnectorServerFactory.newJMXConnector-Server(url, null, mbs);
cs.start();
```
Per effettuare operazioni remote su MBean, un server per connettori RMI √® a disposizione lato server: tramite chiamata alla classe `JMXServiceURL` si crea un nuovo URL di servizio (indirizzo per il server di connector). Il server di connector RMI √® creato via `JMXConnectorServerFactory`, con parametri URL di servizio e MBeanServer. Il server di connector deve essere messo in esecuzione. URL (in formato JNDI) indica dove reperire uno stub RMI per il connettore, tipicamente in un direttorio riconosciuto da JNDI come RMI registry o LDAP: il connettore usa il trasporto di default RMI, il registry RMI in cui lo stub √® memorizzato risponde alla porta 9999 (arbitraria) su local host, mentre l‚Äôindirizzo del server √® registrato al nome "server"

L'unico connettore da specifica JMX √® quello RMI. Si possono utilizzare anche altri connettori che non sono scritti da specifica come JMXMP (ad esempio per disporre di un livello di sicurezza maggiore tramite meccanismo SSL).

Per quanto riguarda gli adattatori di protocollo, sebbene non siano definiti da specifica, non esistono particolari implementazioni diffuse. Un adattatore di protocollo √® un pezzettino software che sta solo lato MBean Server ed √® in grado di ricevere richieste in un protocollo che non √® conforme con JMX, e di tradurle nelle chiamate corrispondenti del MBean Server.

### Esempio utilizzo degli MBean

`HelloMBean.java:` interfaccia MBean che descrive le operazioni e gli attributi di management: 2 operazioni (`sayHello` e `add`) e 2 attributi (`Name` e `CacheSize`):

```java
package com.example.mbeans;

public interface HelloMBean {

    // operazioni (signature)
    public void sayHello();
    public int add(int x, int y);

    // attributi
    public String getName();
    public int getCacheSize();
    public void setCacheSize(int size);
}
```

`Hello.java` implementa l'interfaccia `HelloMBean`:

```java
package com.example.mbeans;

public class Hello implements HelloMBean {

    public void sayHello() {
        System.out.println("hello, world");
    }

    public int add(int x, int y) {
        return x + y;
    }

    /* metodo getter per l‚Äôattributo Name. Spesso gli attributi sono utilizzati per fornire indicatori di monitoraggio come uptime o utilizzo di memoria. Spesso sono read-only. In questo caso l‚Äôattributo √® una stringa */

    public String getName() {
        return this.name;
    }

    /* invece anche metodi getter e setter */
    /* invece anche metodi getter e setter */
    public int getCacheSize() {
        return this.cacheSize;
    }

    /* perch√© synchronized? Mantenere uno stato consistente per evitare modifiche concorrenti. No notifiche concorrenti, non ci sono container che si occupano della sincronizzazione quindi serve sychronized, prima non necessario con i container si occupano internamente della sincronizzazione */
    public synchronized void setCacheSize(int size) {
        this.cacheSize = size;
        System.out.println("Cache size now " + this.cacheSize);
    }

    private final String name = "My First MBean";
    private int cacheSize = DEFAULT_CACHE_SIZE;
    private static final int DEFAULT_CACHE_SIZE = 200;
}
```

`Main.java` deve semplicemente istanziare `HelloWorld` MBean, registrarlo e attendere:

```java
package com.example.mbeans;
import java.lang.management.*;
import javax.management.*;

public class Main {

    public static void main(String[] args) throws Exception {
        // ottiene il server MBean
        MBeanServer mbs = ManagementFactory.getPlatformMBeanServer();
        // costruisce ObjectName per MBean da registrare
        ObjectName name = new ObjectName("com.example.mbeans:type=Hello");
        // crea istanza di HelloWorld MBean
        Hello mbean = new Hello();
        // registra l‚Äôistanza
        mbs.registerMBean(mbean, name);
        System.out.println("Waiting forever...");
        Thread.sleep(Long.MAX_VALUE); 
    }
}
```

Esempio con uso di Notification:

```java
package com.example.mbeans;
import javax.management.*;

public class Hello extends NotificationBroadcasterSupport implements HelloMBean {

    public void sayHello() {
        System.out.println("hello, world");
    }

    public int add(int x, int y) {
        return x + y;
    }

    public String getName() {
        return this.name;
    }

    public int getCacheSize() {
        return this.cacheSize;
    }

    public synchronized void setCacheSize(int size) {
        int oldSize = this.cacheSize;
        this.cacheSize = size;
        
        /* In applicazioni reali il cambiamento di un attributo di solito produce effetti di gestione. Ad esempio, cambiamento di dimensione della cache pu√≤ generare eliminazione o allocazione di entry */
        System.out.println("Cache size now " + this.cacheSize);
        /* Per costruire una notifica che descrive il cambiamento avvenuto: "source" √® ObjectName di MBean che emette la notifica (MBean server sostituisce "this" con il nome dell‚Äôoggetto);
        mantenuto un numero di sequenza */
        Notification n = new AttributeChangeNotification( this, sequenceNumber++, System.currentTimeMillis(), "CacheSize changed", "CacheSize", "int", oldSize, this.cacheSize);
        /* Invio della notifica usando il metodo sendNotification() ereditato dalla superclasse */sendNotification(n);
    }

    ...

    @Override
    /* metadescrizione */
    public MBeanNotificationInfo[] getNotificationInfo() {
    
        String[] types = new String[] { AttributeChangeNotification.ATTRIBUTE_CHANGE };
        String name = AttributeChangeNotification.class.getName();
        String description = "√® stato cambiato un attributo!";
        MBeanNotificationInfo info = new MBeanNotificationInfo(types, name, description);

        return new MBeanNotificationInfo[] {info};
    }
    
    private final String name = "My first MBean";
    private int cacheSize = DEFAULT_CACHE_SIZE;
    private static final int DEFAULT_CACHE_SIZE = 200;
    private long sequenceNumber = 1;
}
```

### JMX con JBoss/Wildfly

L'applicazione server JBoss/Wildfly √® stata progettata considerando JMX come nucleo di base. JBoss/Wildfly √® costituito da numerosi moduli (application server non-monolitico) ed √® vista come un componente MBean che si affaccia su JMX e che pu√≤ essere monitorato, controllato e gestito usando delle chiamate all'MBean Server. Si pu√≤, quindi, attivare/disattivare un modulo sull'interfaccia MBean Server, si pu√≤ configurare ogni modulo agganciandolo ad un'implementazione diversa del servizio medesimo. Ad esempio, un modulo JMS si pu√≤ agganciare all'implementazione di JMX 1.0 piuttosto che JMX 2.0. Si pu√≤ fare l‚Äôembedding di differenti container nell‚Äôapplication server, anche a runtime (ad es. servlet container come Tomcat, Jetty, etc).

![single tier](./img/img76.png)

Da un punto di vista logico, c'√® un MBean Server che fa da bus a cui sono agganciati i vari moduli che hanno un'interfaccia MBean.

## JBoss/WildFly Clustering

Con il termine clustering, si intende un insieme di macchine tipicamente vicine che lavorano insieme con la necessit√† di alto coordinamento. In poche parole, sono armadi al cui interno ci sono molte macchine interconnesse tra di loro. Il clustering √® utile per l'esecuzione su server multipli in parallelo fornendo una visione singola ai clienti applicativi. Ad esempio, viene usato dai motori di ricerca, siti di e-commerce articolati e ad alto carico di utenti, etc. √à cruciale per la tolleranza ai guasti e disponibilit√†, load balancing e scalabilit√† (miglioramento di performance tramite semplice aggiunta di nuovi nodi al cluster e load balancing).

Il cluster √® una soluzione potente ma allo stesso tempo difficile da gestire a mano. Se si ha un'applicazione web e si vuole installare un sito e-commerce, non si pu√≤ installare su tutte le macchine del cluster il sito web perch√® URL ha l'indirizzo fisico di una sola macchina, in caso di stato le macchine devono condividerlo etc.

JBoss Application Server (AS) Clustering √® una soluzione commerciale con buona trasparenza (cluster mantenuto automaticamente, approccio modulare) e open-source.

[Torna all'indice](#indice)

### Architettura JBoss

Dalla versione 7 di JBoss si usa il servizio Infinispan per la gestione della replicazione dello stato applicativo al posto di JBoss Cache. L'architettura di JBoss si pu√≤ sintetizzare nella seguente figura:

![single tier](./img/img81.png)

JBoss √® un'implementazione, altri vendor potrebbero avere un'architettura diversa.

L‚Äôabilitazione del clustering service avviene lanciando semplicemente da linea di comando usando la configurazione _all_ di JBoss:

```
run.bat -c all
./run.sh -c all
```

In questo modo vengono abilite tutte le librerie necessarie al clustering, come `JGroups.jar` per il multicast di gruppo affidabile, `jbosscache.jar` per la cache distribuita etc.

### JGroups

JGroups √® lo strumento indispensabile che consente la comunicazione multicast in JBoss. JGroups utilizza canali di comunicazione e tiene traccia automaticamente di chi fa parte del cluster sulla base di configurazione e nome del canale JGroups utilizzato. JGroups supporta lo scambio **affidabile** di messaggi all‚Äôinterno del cluster. A default, la comunicazione multicast avviene con il protocollo UDP, ma √® data anche la possibilit√† di utilizzare TCP con connessioni punto-punto costose. UDP √® ottimo per connessioni multicast locali, quando invece si vuole lavorare con multicast remoti si pu√≤ scegliere anche TCP per una maggiore affidabilit√†, pagata per√≤ con un costo maggiore della comunicazione. A default JBoss utilizza 4 canali JGroups separati:

- Un canale usato dal servizio general-purpose di High Avaiability partition HAPartition.
- Tre canali creati da JBoss Cache, anche per supportare replicazione dello stato.

Un cluster logico (o partizione) JBoss non √® altro che l'insieme dei nodi fisici che hanno attiva un'istanza del server JBoss che sta in ascolto sullo stesso indirizzo multicast e porta degli altri nodi (condividono la stessa configurazione JGroups). Se c'√® un cluster fisico a sei nodi, si possono messere tutti i sei nodi in un cluster logico JBoss oppure prendere quattro nodi e metterli in un cluster logico e gli altri due in un altro cluster logico. Si potrebbe anche far partecipare uno stesso nodo fisico a pi√π cluster logici. Molto importante √® l‚Äôattenzione nella fase di mapping del deployment, per esempio per garantire high avaibility non si pu√≤ fare il deployment di tutti i nodi logici sulla stessa macchina fisica perch√® ci√≤ non garantirebbe in caso di fault della macchina fisica la qualit√† di high avaibility.

La configurazione della comunicazione in JGroups avviene con il file `cluster-service.xml` nella directory `/deploy`. Esso descrive la configurazione per la partizione di default del cluster. Le configurazioni JGroups sono attributi innestati di servizi MBean del cluster. L‚Äôattributo `PartitionConfig` di MBean `ClusterPartition` descrive e configura lo stack di protocolli JGroups, la configurazione di default usa UDP con IP multicast:

```xml
<mbean code="org.jboss.ha.framework.server.ClusterPartition"
name="jboss:service={jboss.partition.name:DefaultPartition}">

...

<attribute name="PartitionConfig">
<Config>
<UDP mcast_addr="${jboss.partition.udpGroup:228.1.2.3}"
mcast_port="${jboss.hapartition.mcast_port:45566}"
tos="8"

...

<! -- ping per scoprire i membri che appartengono al cluster-->
<PING timeout="2000"
down_thread="false" up_thread="false"
num_initial_members="3"/>

...

<! -- per fondere gruppi gi√† scoperti -->
<MERGE2 max_interval="100000"
down_thread="false" up_thread="false"
min_interval="20000"/>

...

<! -- timeout per failure detection -->
<FD timeout="10000" max_tries="5"
down_thread="false" up_thread="false" shun="true"/>

<! -- questo protocollo verifica se un membro sospetto √® realmente morto eseguendo nuovamente il ping di quel membro. -->
<VERIFY_SUSPECT timeout="1500" down_thread="false"
up_thread="false"/>

...

<pbcast.STATE_TRANSFER down_thread="false" up_thread="false"/>
```

`PING` √® il protocollo per la scoperta iniziale dei membri del cluster, `MERGE2` √® il protocollo per la fusione di nuovi sottogruppi gi√† discovered per una gestione dinamica dei gruppi, `FD` √® invece il protocollo per failure detection, verifica ogni X secondi il funzionamento del server.

Il clustering lavora a livello software, la failure detection √® tra gli application server. In high avaiability per cambiare versione a volte si uccidono webserver e quando questo accade il clustering lo replica con una versione gi√† aggiornata.

### HA Partition

High Avaiability (HA) Partition √® un servizio general-purpose di alta disponibilit√† (High Availability) costruita utilzzando JGroups, utilizzato per diversi compiti in JBoss AS Clustering. Fornisce un supporto per molti servizi di clustering come smart proxy lato cliente, il farming e HA-JNDI.

Esempio di configurazione HA Partition:

```xml
<mbean code="org.jboss.ha.framework.server.ClusterPartition"
name="jboss:service=DefaultPartition">
    <attribute name="PartitionName">${jboss.partition.name:DefaultPartition}</attribute>
    <! ‚Äì Indirizzo usato per determinare il nome del nodo -->
    <attribute name="NodeAddress">${jboss.bind.address}</attribute>
    <! -- deadlock detection abilitata o no -->
    <attribute name="DeadlockDetection">False</attribute>
    <! -- Max time (in ms) di attesa per il completamento del trasferimento di stato -->
    <attribute name="StateTransferTimeout">30000</attribute>
    <! -- configurazione protocolli JGroups -->
    <attribute name="PartitionConfig">...</attribute>
</mbean>
```

Per fare parte dello stesso cluster, i nodi devono semplicemente avere lo stesso `PartitionName` e gli stessi elementi `PartitionConfig`. Necessit√† di configurare i protocolli JGroups e la definizione di timeout ad alto livello per gestire la replicazione, per esempio il tempo massimo per sincronizzare lo stato tra diversi nodi.

Il deployment pu√≤ avvenire in due modi: vi √® la possibilit√† di deployment omogeneo in cui avviene la replica su tutti i nodi logici del cluster, questo facilita la gestione ed evita diversi possibili problemi ed √® reso automatico attraverso farming, oppure deployment disomogeneo generalmente sconsigliato dagli sviluppatori JBoss, per diverse ragioni, come avere dei componenti solo in alcuni nodi del cluster. Il clustering omogeno √® quello pi√π utilizzato.

Uno dei problemi da risolvere quando si porta EJB su un cluster √® quello di decidere dove eseguire il servizio JNDI ( su un nodo o pi√π nodi, nel secondo caso bisogna tenere aggiornate tutte le entry).

Il cliente non usa pi√π JNDI centralizzato, ma utilizza un proxy HA-JNDI per invocare la JNDI lookup lato server. Ad ogni nodo del cluster, il servizio HA-JNDI mantiene una parte di albero JNDI (context tree). Ogni nodo, quindi, ha sua copia locale di parte dell‚Äôalbero JNDI. All‚Äôatto del lookup: se il nome ricercato √® presente nella copia locale viene restituita la risposta. Se il binding non √® nella copia locale dell‚Äôalbero del nodo interrogato, allora il proxy HA-JNDI si coordina con gli altri proxy usando JGroups. Se non viene trovato nulla in nessun JNDI del cluster viene restituito `NameNotFoundException`. Questa ricerca su pi√π livelli, con un livello locale e un livello distribuito con coordinamento forte, consente di limitare i colli di bottiglia e per diminuire il coordinamento tra i nodi.

![single tier](./img/img83.png)

Si ipotizzi di avere un Session Bean che deve fare una lookup sul servizio di nomi. La lookup arriva a HA-JNDI proxy che va a vedere se nella sua copia parziale JNDI √® presente il binding richiesto. Lo spazio di nomi JNDI √® parzialmente replicato e partizionato cio√® non √® detto che un'entry sia presente in tutti i nodi ma neanche in nessuno. Se il binding non √® presente, il proxy HA-JNDI fa richieste in contemporanea, tramite una richiesta multicast, agli altri nodi. Tutti i nodi che presentano quel nome rispondono alla richiesta del `Nodo 1` e verr√† aggiunta una nuova entry alla copia locale. Per questo motivo, i componenti locali JNDI possono avere alberi pi√π estesi rispetto ai loro HA-JNDI.

La fault tollerant viene garantita nel seguente modo: si ipotizzi che il grado di replicazione sia due. Questo vuol dire che un nome sar√† presente in due tabelle JNDI. Se il nome √® presente nel `Nodo 1` e `Nodo 2` e il `Nodo 1` va down, allora il nome, dato che √® presente solo su un nodo, verr√† replicato anche sul `Nodo 3`.

### Load-Balancing

Vi sono due tipi di configurazione per la comunicazione client-to-cluster: 

- **JBoss fat client**: i clienti usano HA smart proxy che contengono logica di load balancing (ad es. Round Robin) e capacit√† di resilienza (failover) in caso di guasti. La logica di HA smart proxy, che √® una sorta di stub molto pesante, pu√≤ essere modificata e plugged-in da parte del programmatore, che pu√≤ implementare differenti politiche di failover e load balancing basate su pesi differenziati e carico. I clienti EJB usano necessariamente HA Smart Proxy, che realizza uno stub RMI significativamente accresciuto.
![single tier](./img/img126-light.png)
Il fat client √® una sorta di grande stub RMI detto HA-RMI, che contiene al suo interno la lista dei nodi disponibili e le varie politiche di load balancing che si possono attuare tra cui sono disponibili Random Robin, Round Robin, First Available e First Available All Identical Proxies. Se avviene una modifica nella composizione del cluster, all'invocazione seguente il server fa piggybacking con un protocollo dedicato della lista aggiornata, la lista dei nodi √® mantenuta automaticamente lato server tramite JGroups cio√® quando viene fatta una richiesta da parte del cliente, nella risposta viene restituita anche la lista dei nodi disponibili. Per ottenere la lista dei nodi la prima volta, il cliente o fa una richiesta multicast oppure √® stata distribuita in modo statico. Dal lato client side, le comunicazioni sono intercettate tramite meccanismi trasparenti che si occupano di load balancing e failover all‚Äôinvocazione di metodi nell‚Äôinterfaccia dello stub.
- **JBoss thin client**: tutto √® gestito lato server utilizzando un proxy locale e la logica di load-balancing + failover √® lasciata allo sviluppatore che pu√≤ adottare soluzioni hardware o software gi√† esistenti come Apache mod_jk oppure Apache mod_cluster. I clienti principalmente sono clienti Web che accedono trasparentemente attraverso Apache mod_jk/mod_cluster.
![single tier](./img/img125-light.png)

### JBoss Cache

JBoss Cache √® un framework per il supporto a cache distribuita, che pu√≤ essere utilizzato anche in altri ambienti AS. Essa realizza il caching di oggetti Java acceduti frequentemente per motivi di performance. In JBoss, fornisce servizi di caching per sessioni HTTP, per stati di session bean EJB 3.X, per Entity EJB 3.X. Ogni servizio di cache √® definito in un Mbean separato con il suo canale JGroups. JBoss Cache √® cluster-aware: lo stato √® mantenuto consistente fra i vari nodi nel cluster, per questo vi √® tolleranza ai guasti in caso di server crash, con necessit√† di invalidazione e/o aggiornamento dello stato nella cache.

### Infinispan

Infinispan sostituisce JBoss Cache. Infinispan √® un framework open-source basato su JGroups come supporto di comunicazione utilizzabile anche al difuori di JBoss. Svolge il ruolo di infrastruttura di caching e replicazione per sessione HTTP, stato di stateful Session Bean, nomi JNDI e replicazioni e secondo livello di Hibernate. Infinispan ha quattro strategie di caching:

- **Locale**: l'oggetto √® mantenuto solo in copia locale al nodo. Non c'√® replicazione sul claster. 
- **Replicazione**: strategia pi√π onerosa perch√© con questa strategia Infinispan va a replicare tutti gli oggetti in cache su tutti i nodi del cluster. Tipicamente √® adatta per piccoli cluster, perch√© il carico di rete necessario per tenere informati i nodi √® alto di conseguenza √® scarsamente scalabile.
- **Distribuzione** strategia che prevede che il dato sia salvato in un sottoinsieme dei nodi del cluster. Tutti gli oggetti in cache sono replicati solo su sottoinsieme fisso (configurabile) di nodi del cluster. Ovviamente vi sono minori performance quando oggetti non disponibili localmente ma in generale ma migliore scalabilit√†. Vi √® un trade-off tra grado di replicazione e tempo di risposta, inoltre bisogna tenere conto della dimensione della cache che deve contenere questi dati.
- **Invalidazione** strategia utilizzata quando nella fase di scrittura si va a invalidare copie di quello stato disponibili in altri nodi del cluster, per non avere letture inconsistenti. Non vi √® replicazione, ma rimozione di entry non valide. Tipicamente √® utilizzata per dati comunque disponibili su datastore persistente.

Replicazione e invalidazione possono avvenire in modo bloccante o non-bloccante. Nel caso non-bloccante si ha una coda con modifiche/invalidazioni multiple. Questa strategia garantisce migliori performance perch√® le modifiche avvengono in batch, ma possono esservi errori riportati in log ed eventualmente utilizzati in rollback se si trattano transazioni. Quando si agisce in modo non bloccante si mantiene il log delle operazioni da effettuare, quindi, √® possibile in caso di fault rendere consistente la situazione su altri nodi.

Quando la cache si riempe, bisogna scegliere che oggetto rimuovere. Il processo di rimozione delle entry non pi√π utilizzate √® detto eviction. In Infinispan la rimozione √® solo locale. Esistono varie strategie come unordered (random), FIFO, LRU (last recent used).

Il cache loader √® il caricamento in anticipo di oggetti nella cache tramite la connessione fra Infinispan come servizio e versione su memoria persistente, ad esempio file system, DB, cloud store come AmazonS3. Se la passivazione √® abilitata, la scrittura in datastore avviene solo in caso di eviction.

Anche nelle cache come nei DB, vi sono diversi livelli di isolation e locking delle risorse:

- REPEATABLE_READ sono possibili phantom read. 
- READ_COMMITTED possibili non repeatable read ma maggiori performance.
- Optimistic locking e verifiche a posteriori in fase di commit.

### Replicazione Stato HTTP

La replicazione dello stato HTTP di sessione √® gestita da JBoss, la configurazione all di JBoss include session state replication. Occorre configurare session state replication in modo opportuno. Lo stato di sessione HTTP viene replicato automaticamente su tutti i nodi del cluster.

In alternativa, per applicazioni Web √® possibile configurare il cluster in modalit√† sticky session. Si pu√≤ gestire lo stato mantenendolo in un solo nodo del cluster, quindi, non vi √® replicazione questo porta numerosi vantaggi in termini di performance di utilizzo delle risorse ma di contro la caduta del server produce la perdita dello stato di sessione. Si pu√≤ chiedere un clustering con sticky session (nessuna replicazione di sessioni HTTP) di inviare tutte le richieste dello stesso cliente vengono allo stesso nodo del cluster.

Il modulo di JBoss che si occupa di gestire lo stato di sessione (non solo HTTP) √® JBoss Cache/Infinispan.

### Replicazione Stato EJB

Per Stateless Session Bean, data la mancanza di stato, le chiamate possono essere bilanciate su ogni nodo del cluster, si guadagna molto in scalabilit√† in questo caso. Nel caso di Stateful Session Bean, lo stato replicato e sincronizzato sul cluster, quindi ad ogni modifica sullo stato di uno di questi bean, entra in azione Session State replication di JBoss Cache o di Infinispan, questo ovvamente ha un costo. Dipende dalla strategia di Cache adottata (locale, replicazione e distribuzione). Per gli Entity Bean, non si prevede il supporto al clustering perch√® non sono interrogabili da remoto dai clienti e quindi non prevista abilitazione clustering. Si pu√≤ decidere di replicare solo la cache di secondo livello Hibernate con Infinispan. Infine, per i Message Driven Bean, la gestione √® uguale ai Stateless Session Bean. Si usa HornetQ che √® un supporto MOM creato da JBoss.

Il modulo di JBoss che si occupa di gestire lo stato di sessione (non solo EJB) √® JBoss Cache/Infinispan.

### Clustering di Componenti EJB

Come deve essere organizzato in questo caso HA smart proxy rispetto i diversi casi di Stateless Session Bean, Stateful Session Bean, MessageDriven Bean ed Entity Bean.

Nel migliore dei casi, √® sufficiente uso di una annotazione specifica e proprietaria di JBoss, per informare il container EJB di JBoss che il componente considerato deve essere clustered. L'annotazione `@Clustered` applicabile a:

- Stateless Session Bean con smart proxy a cui sono applicabili diverse politiche di load balancing, come RoundRobin (default), FirstAvailable, FirstAvailableIdenticalAllProxies (tutti smart proxy per un bean verso stesso nodo), RandomRobin.
- Statefull Session Bean con smart proxy, con diverse politiche di load balancing FirstAvailable (senza abilitazione esplicita replicazione stato).
- Message Driven Bean le politiche di load balancing sono RoundRobin, Random, Custom (tramite implementazione interfaccia ConnectionLoadBalancingPolicy).
- Entity Bean non hanno problemi perch√© sono gestiti internamente quindi non possono essere gestiti dallo smart proxy lato client.

### Configurazione di JBoss/WildFly

Le opzioni di configurazione di JBoss/WildFly ovvero dell‚Äôapplication server:

- La configurazione `standalone.xml` √® la default configuration file per standalone server. Contiene tutti i metadati di configuration, inclusi per subsystem, networking, deployment, socket binding. Usata automaticamente quando si fa partire standalone server. Offre il supporto di Java EE Web-Profile ed alcune estensioni come RESTFul Web Services e invocazioni remote EJB 3.X.
- La configurazione `standalone-full.xml` fornisce il supporto per tutti subsystem eccetto high availability (HA)Supporto di Java EE Full-Profile e tutte funzionalit√† server. - La configurazione `standalone-ha.xml` include tutti i subsystem di default pi√π l‚Äôaggiunta mod_cluster per il supporto al thin client e JGroups per standalone server, cos√¨ che possa partecipare in un cluster high-availability. Questo √® il profilo di default per funzionalit√† di clustering.
- La configurazione `standalone-full-ha.xml` include supporto per ogni subsystem, inclusi quelli richiesti per high availability (HA).
- La configurazione `standalone-load-balancer.xml` configura automaticamente l‚Äôuso di proxy front-end Undertow (Web server) per lavorare da load balancer. Undertow si connetter√† ai nodi server veri e propri usando le sue richieste built-in per clienti e proxy protocolli supportati: HTTP, AJP, HTTP2, H2C (clear text HTTP2).

## Big Data

Al giorno d'oggi, sempre pi√π sistemi sono costituiti e caratterizzati da enormi moli di dati da gestire, originati da sorgenti altamente eterogenee e con formati altamente differenziati, oltre a una qualit√† estremamente eterogenea (fonte dei dati).

[Torna all'indice](#indice)

### Definizione

In letteratura, esistono molte definizioni di Big Data. La definizione seguente si basa sulla regole delle 5V cio√® un sistema per essere definito Big Data deve rispettare tutti questi punti:

- **Volume**: quando la dimensione dei dati √® molto grande. Ad esempio, Terabyte.
- **Variet√†**: le diverse tipologie di dati con cui si lavora. Ad esempio, dati strutturati, non strutturati, semistrutturati.
- **Velocit√†**: la velocit√† con cui i dati arrivano:
    - **Stream**: flusso continuo dei dati e lavorarli man mano che arrivano.
    - **Real time**: per processare il dato si ha bisogno di un periodo di tempo che pu√≤ essere anche molto lungo. Si rispetta un vincolo temporale. Ad esempio, il vincolo temporale √® processare il dato entro 5 minuti ma il vincolo pu√≤ essere anche 5 ore.
    - **Interactive**: interazione con l'utente durante il processamento.
    - **Batch**: un insieme di dati viene raggruppato per un periodo di tempo specifico e poi processato.
- **Valore**: √® il valore del dato. I dati fini a se stessi non hanno alcuna importanza. Per essere davvero utili devono poter essere convertiti in informazioni preziose che permettono alle aziende di verificare ed eventualmente modificare le sue mosse.
- **Veridicit√†**: i dati provvengono da origini diverse creando confusione. Si indica, quindi, il livello di affidabilit√† o inaffidabilit√† dei dati.

Altre definizioni di Big Data includono anche un'altra V cio√® la **variabilit√†** cio√® il significato o l‚Äôinterpretazione di uno stesso dato pu√≤ variare in funzione del contesto in cui questo viene raccolto ed analizzato. Il valore, quindi, non risiede solamente nel dato, ma √® strettamente collegato al contesto in cui da cui si ricava.

![single tier](./img/img85.png)

Il processamento dei Big Data pu√≤ avvenire in due modi: o tramite stream processing o tramite batch processing.

[Torna all'indice](#indice)

### Stream Processing

Questo tipo di processamento √® orientato ad applicazioni che richiedono on-the-fly processing, filtering e analisi di flussi di dati come ad esempio l'uso di sensori (ambientali, industriali, video sorveglianza, GPS, etc), log di file di server network/Web/application, dati di transazioni ad alto rate (transazioni finanziarie, chiamate telefoniche) etc. Un sistema stream processing famoso √® InfoSphere Streams sviluppato da IBM.

![single tier](./img/img90.png)

Il modello di programmazione √® basato su grafi dataflow costituiti da datasource (input), operatori e sink (output). Gli operatori vengono raggrupati in Processing Element (PE) che √® l'elemento minimo della computazione.

![single tier](./img/img88.png)

I cerchi rappresentano i PE, i quadratini piccoli sono i singoli pezzettini di informazione mentre in grigio sono riportati i nodi. Il deployment e il supporto runtime sui nodi viene garantito dall'infrastruttura. Come si pu√≤ vedere dalla figura i PE vengono replicati per garantire scalabilit√†, fault tollerant etc.

![single tier](./img/img89.png)

Un'applicazione Streams non √® altro che un grafo diretto (eventualmente anche ciclico) costituito da operatori PE i quali processano dati chiamati Streams.

Un'istanza di InfoSphere Streams √® un ambiente runtime costituito da un set di risorse su cui √® possibile eseguire una collezione di job. Il job √® un'applicazione InfoSphere Streams di cui √® fatto il deployment su una istanza ed √® costituito da uno o pi√π PE.

I job vengono inviati a una singola istanza e nessun'altra istanza √® a conoscenza dei job. Ad esempio, si installa InfoSphere Streams su un set di risorse `A`, `B`, `C` e `D`. Si pu√≤ configurare `istanza1` per utilizzare le risorse `A` e `B` e configurare `istanza2` per utilizzare le risorse `B`, `C` e `D`. I job che si inviano a `istanza1` non sono a conoscenza dei job che si inviano a `instance2`, anche se condividono una risorsa comune `B`.

Anche se le istanze possono condividere le risorse, non vi √® alcuna interferenza logica con altre istanze. Per evitare qualsiasi interferenza fisica, ad esempio legata alla competizione per i cicli della CPU, √® possibile allocare risorse esclusivamente alle istanze.

Un PE √® l'unit√† di esecuzione fondamentale che √® eseguita da una istanza. Pu√≤ incapsulare un singolo operatore o diversi operatori.

Il programmatore, quindi, deve scrivere solo la logica applicativa dei PE perch√® a tutto il resto ci pensa il framework.

![single tier](./img/img91.png)

Un operatore √® un blocco fondamentale per Streams Processing Language. Gli operatori processano dati chiamati Streams e possono generare nuovi Streams di output.

Uno Stream √® una sequenza infinita di tuple strutturate. Possono essere consumate da operatori o in modo singolo o attraverso la definizione di una finestra. La tupla √® una lista strutturata di attributi e dei lori tipi.

Invece, la finestra √® un gruppo finito e sequenziale di tuple in un flusso. La finestra √® basata su contatori, tempo, valore di attributi, punctuation mark etc. Ogni operatore, ad esempio, potrebbe lavorare su una finestra di tre tuple e quindi le operazioni vengono eseguite su tre tuple alla volta.

[Torna all'indice](#indice)

### Batch Processing

Probabilmente il padre storico di impatto industriale √® il progetto Apache Hadoop. √à un framework open source che vede Yahoo come principale contributor. Il progetto si suddivide in tre sottoprogetti:

- **Hadoop Common**: package di facilities comuni.
- **Hadoop Distributed File System (HDFS)**: file system distribuito.
- **MapReduce**: framework per processing distribuito di grandi insiemi di
dati su cluster.

#### Hadoop Distributed File System (HDFS)

Prende ispirazione da Google file system. √à un file system scalabile, distribuito, portabile, scritto in Java per framework Hadoop. HDFS pu√≤ essere parte di Hadoop o un file system distribuito stand-alone general-purpose. HDFS √® costituito da:

- **NameNode** che gestisce i metadata del file system cio√® in quale nodo o nodi vengono salvati i dati.
- **DataNode** che memorizzano i veri dati.

HDFS memorizza file di grandi dimensioni in blocchi distribuiti sul cluster, garantisce affidabilit√† e fault-tolerance tramite replicazione su nodi multipli ed √® progettato specificamente per deployment su hardware low-cost.

Hadoop pu√≤ lavorare su qualsiasi file system distribuito ma sfrutta conoscenza di localit√† per ottimizzazione, quindi HDFS particolarmente adatto.

[Torna all'indice](#indice)

#### MapReduce

MapReduce √® modello di programmazione e un framework software sviluppato originariamente da Google. Questo modello √® stato implementato anche nel framework open source da parte di Yahoo. L'obiettivo √® quello di semplificare il processamento di enormi moli di dati in parallelo su cluster di grandi dimensioni usando hardware low-cost, in modo affidabile e fault-tolerant. Il processamento deve avvenire su:

- Dati non strutturati (filesystem).
- Dati strutturati (db).

L'architettura di riferimento √® quella master/slave. Il master contiene:

- **Job tracker**: responsabile dello scheduling dei job task che eseguono MapReduce, monitora gli slave e riesegue i job con fallimenti.
- **Task tracker**: eseguono MapReduce.
- **NameNode** (HDFS).
- **DataNode** (HDFS).

I nodi slave includono:

- **Task tracker**: eseguono MapReduce e sono sotto il coordinamento del master.
- **DataNode** (HDFS).

![single tier](./img/img86.png)

L'idea alla base si basa sul _divide et impera_ cio√® prendere un problema e scomporlo in sotto-problemi. Ci sono due passi fondamentali:

- **Map step**: il nodo master riceve l'input del problema e lo suddivide e lo divide in sotto-problemi pi√π piccoli, distribuiti verso i nodi worker. In poche parole, l'input viene diviso in chunk (blocchi) di misura appropriata, che vengono assegnati a nodi worker. I nodi worker possono farlo a loro volta (struttura gerarchica ad albero multi-livello). Un worker risolve un problema piccolo e riporta il sotto-risultato al master. La funzione di Map, _mappa_ il file di input in coppie `<key, value>` pi√π piccole e di utilizzo intermedio.
- **Reduce Step**: un nodo master raccoglie le risposte ai sottoproblemi e li combina in modo predefinito per ottenere la risposta complessiva. Prende i valori intermedi dei nodi di Map e li processa restituendo il risultato complessivo.

Si consideri il seguente esempio: si vuole contare le occorrenze di ogni parola su un set di file di ingresso. Ci sono 2 file di ingresso:

- file1 = `hello world hello moon`
- file2 = `goodbye world goodnight moon`

A un nodo viene assegnata la funzione di Map del primo file ottenedo i seguenti risultati parziali:

```
<hello, 1>
<world, 1>
<hello, 1>
<moon, 1>
```

Mentre a un altro nodo viene assegnata la funzione di Map del secondo file ottenedo i seguenti risultati parziali:

```
<goodbye, 1>
<world, 1>
<goodnight, 1>
<moon, 1>
```

Per ottimizzare i trasferimenti da un nodo ad un altro, in realt√† viene eseguita un'altra funzione che prende il nome di funzione di Combine e aggrega i risultati parziali dei nodi. Il primo nodo avr√† le seguenti coppie chiave-valore:

```
<moon, 1>
<world, 1>
<hello, 2>
```

Invece, il secondo:

```
<goodbyte, 1>
<world, 1>
<goodnight, 1>
<moon, 1>
```

Prima di passare alla funzione di Reduce, Il framework raccoglie queste coppie e riordina gli output dei Map. Questa fase prende il nome di shuffle and sort. A questo punto, i risultati parziali vengono inviati alla funzione di Reduce ottenendo il risultato finale:

```
<goodbyte, 1>
<goodnight, 1>
<moon, 2>
<world, 2>
<hello, 2>
```

Sia gli input che gli output dei job sono memorizzati nel file system integrato in Hadoop. Il framework gestisce tutte le problematiche di scheduling, monitora e riesegue i task con fallimenti/guasti.

Quello che il programmatore deve scrivere sono tre funzioni:

- Map.
- Combine.
- Reduce.

Al resto ci pensa il framework.

Un secondo esempio per chiarire tutti i concetti visti √® il seguente:

![single tier](./img/img87.png)

Spark √® l'evoluzione di Hadoop. Infatti, usa il pi√π possibile la memoria RAM, per evitare i rallentamenti causati dalle letture e scritture su disco.

Per rendere l'approccio batch-processing simile a quello stream-processing, √® possibile creare delle finestre di dimensioni inferiori rispetto a quelle usate normalmente. Esiste una versione di Spark che prende il nome di Spark Stream.

[Torna all'indice](#indice)

## Node.js

Node.js √® una tecnologia Javascript che si usa lato server-side, supporta efficientemente l'I/O in modo asincrono non-bloccante, **non** utilizza thread/processi dedicati, garantisce scalabilit√†, ed esaspera il concetto di _server stateless_.

In particolare, Node.js √® molto utilizzato nella programmazione web per la scrittura di applicazioni web, √® possibile usarlo sia per chiamare le funzioni core su file system e networking ma vi sono anche framework pi√π larghi per facilitare lo sviluppo delle applicazioni web stesse, associabile anche a DevOps e tecnologie front-end.

[Torna all'indice](#indice)

### Utilizzo di JavaScript

L‚Äôuso di JavaScript sia lato cliente che lato servitore ha alcuni vantaggi tra cui il non uso del context switch. Se si sta programmando lato client side si utilizza il DOM e non si accede al persistent storage mentre lato server si √® pi√π interessanti a lavorare con lo storage.

Per usare Node.js √® necessario renderlo fruibile √® necessario appoggiarsi ad un run-time enviroment del linguaggio JavaScript supportato da Google Chrome V8 engine. Il codice JavaScript viene compilato con una buona efficienza a run-time. Vi √® la massima concorrenza e scalabilit√† per questo di solito si evita di utilizzare pi√π thread dedicati e concorrenti. Il funzionamento √® sempre non bloccante, persino per chiamate I/O-oriented.

[Torna all'indice](#indice)

### Event Loop

L‚Äôidea di base √® gestire tutto con l‚Äôevent loop: un ciclo infinito di elaborazione che si appoggia sull‚Äôutilizzo di uno stack o coda (dipende dall'implementazione). Sullo stack sono depositate le operazioni da eseguire, che puoi vengono processate e di conseguenza una volta eseguite vengono rimosse dallo stack e si procede con la valutazione. In questo modo, √® possibile la valutazione di alcune funzioni che possono essere accodate e mano a mano smaltite dall‚Äôevent-loop. In sintesi, al posto di thread, si usa un event loop con stack che riduce fortemente overhead di context switching. L‚Äôevent loop utilizza il framework CommonJS, leggermente pi√π _simile_ a un vero linguaggio di programmazione OO.

Ha senso utilizzare questa strategia perch√© a seconda del tipo di operazione, come l‚Äôaccesso alle cache di primo o secondo livello, alla memoria, al disco o alla rete, sono richiesti molti pi√π cicli di CPU per effettuare queste operazioni. Se ci si blocca in attesa di queste risorse per certe operazioni, rimangono ferme delle risorse attive come i thread. Se questo √® vero bisogna strutturare l‚Äôapplicazione sfruttando il parallelismo e quindi generando nuove richieste di risorse al sistema poich√© con il parallelismo si creano nuovi thread e processi. A livello di sistema si utilizza la `select` che consente di gestire le operazioni non bloccanti a evento. In questo modo, √® possibile realizzare dei servitori anche mono-processo (nel caso estremo) che concorretemene gestiscono la molteplicit√† di richieste senza doversi bloccare su operazioni di lettura in genere pi√π fastidiose da questo punto di vista.

[Torna all'indice](#indice)

### Thread vs Asynchronous Event Driven

Nelle applicazioni event-driven vi √® un solo processo che fa fetching di eventi da una coda, li estrae e li processa. Per quanto riguarda un‚Äôapplicazione multi-threaded tipicamente questo lavora bloccando il chiamante in attesa che arrivi del lavoro da smaltire da un thread listener che poi delega la computazione a un pool di thread. Il modello di base √® quello di incoming request cio√® si aspettano richieste, mentre nel caso event-driven vi √® una serie di eventi da processare in una coda che vengono processati dal singolo processo dell‚Äôevent-loop. Se un‚Äôapplicazione multi-thearded nell‚Äôoperazione di lettura generalmente si blocca, nel paradigma event-driven la stessa lettura sar√† un evento che dovr√† essere processato e ci√≤ accadr√† solo quando il dato che si vuole leggere sar√† disponibile, utilizzando callback che notificano l‚Äôaver completato l‚Äôesecuzione dell'evento. In un server multithead se una richiesta prevede diverse operazioni questi thread si bloccheranno per molto tempo nell‚Äôattesa che tutte le operazioni vengano effettuate. Nel caso event-driven, l‚Äôidea √® quella di mantenere uno stato aggiornato man mano che arrivano nuovi dati per capire quando √® il momento di processare l‚Äôevento. Per quanto riguarda l‚Äôapplicazione multi-threaded vi √® context swiching per passare da un thread bloccato in attesa di una risorsa ad un altro, ci√≤ causa un notevole overhead, mentre nel caso dell‚Äôevent-driven non c‚Äô√® context switch e non c‚Äô√® content della CPU che √® sempre detenuta dall‚Äôevent loop. Questo in termini di scalabilit√† ha un grosso vantaggio relativo all‚Äôoverhead creato dal cambio di contesto dal caricamento del processo e dallo scheduling di quello successivo relativo al context switch. Nei sistemi multithread a causa degli accessi concorrenti a uno stato condiviso vi √® anche il problema della sincronizzazione in accesso, quindi locking delle risorse. Nel caso nell‚Äôevent-driven asincrono non esiste per costruzione questo tipo di problema essendovi un unico processo. Quando l‚Äôapplicazione √® event-driven si necessita di un supporto diverso che possiede primitive asincrone e non bloccanti.

![single tier](./img/img92.png)

[Torna all'indice](#indice)

### Thread vs Event

Per gestire una richiesta a un server web, nel multithread si ha l‚Äôinvocazione di una read request letta dalla socket, poi si processa la richiesta e si manda una risposta `sendReply`, che rappresenta l‚Äôoperazione di scrittura:

```
request = readRequest(socket);
reply = processRequest(request);
sendReply(socket, reply);
```

La prima operazione bloccante √® la `readRequest` su cui si blocca il thread in attesa, il blocco √® sulla `read` a livello di sistema. Sull‚Äôoperazione di lettura il processo si sospende e quindi avviene il context switching.

```
startRequest(socket);
listen("requestAvail", processRequest);
listen("processDone", sendReplyToSock);
```

La prima invocazione del modello a eventi √® una `startRequest` sulla socket, quindi, la lettura √® gestita ad evento, si vuole iniziare la ricezione di una richiesta da un potenziale cliente. La parte successiva √® un metodo di callback che si vuole attivare quando la richiesta √® disponibile. Il modello lavora a callback e il sistema chiama quando l‚Äôevento si verifica. Quando la richiesta √® arrivata inizia il processamento. Per questo motivo si passa a una programmazione funzionale. In modo simile si ha una `listen` che aspetta la callback dell‚Äôevento di processing terminato ovvero `processDone`. Infatti, anche la write viene gestita ad evento. In questa implementazione non c‚Äô√® context swithing, ma vi √® un event loop che consuma le operazioni richieste e le va ad eseguire utilizzando le callback, una volta eseguita passer√† alla successiva.

```
readRequest(socket, function(request) {
    processRequest(request,
        function (reply) {
            sendReply(socket, reply);
        });
}
```

Il tutto si pu√≤ organizzare con una `readRequest` che accetta come argomenti, una socket e un‚Äôinvocazione di una funzione. Al momento della disponibilit√† dell‚Äôevento di lettura, il supporto passa la richiesta letta, la funzione esegue il codice e processa la richiesta, la `processRequest` ricever√† la richiesta che riceve come secondo parametro un‚Äôinvocazione di funzione. All‚Äôinterno della stessa si annida una funzione per la `sendReply()`.

Di seguito √® riportato un esempio di stack con event loop, idea e che sullo stack sono caricate man mano le richieste che si vogliono eseguire con le funzioni `readRequest` e `processRequest`:

![single tier](./img/img93.png)

Sullo stack vengono caricate le funzioni che si vogliono eseguire, per esempio volendo servire una richiesta `index.html`, vi √® sempre un evento di base che √® l‚Äôevent loop che √® idle cio√® in attesa di eventi da processare. Quando arriva una richiesta HTTP, l‚Äôevento di `socket_readable` viene caricato sulla coda, si crea un nuovo un evento per il parsing della richiesta, per farlo ci si rende conto che √® necessario caricare il file `index.html`. Quando il caricamento √® avvenuto vengono gestite le richieste con la callback fino a risvuotare la coda.

L‚Äôevent loop √® costituito da un `while` infinito che effettua la `pop()` (estrae dallo stack l'evento) e la `call()` all‚Äôarrivo di una richiesta:

```
while(true) {
    if (!eventQueue.notEmpty()) {
        eventQueue.pop().call();
    }
}
```

Se un'operazione di `call()` dura molto tempo √® necessario che venga restituito subito il controllo. Quando, l'operazione che ha richiesto molto tempo termina (es. lettura su DB), questo provoca un `push()` di un evento sullo stack. In questo modo si ottiene la massima sincronicit√† e non serve pi√π effettuare context switching.

In caso di operazione sincrona si ha un'attesa molto lunga, e si inizia a eseguire solo da quel momento in cui √® presente il risultato e solo a questo punto si effettua il processing del risultato stesso:

![single tier](./img/img94.png)

Nel caso asincrono con thread in parallelo si ha lo stesso problema cio√® vi √® sempre molto attesa. Inoltre, creare nuovi thread ha in s√© un costo:

![single tier](./img/img95.png)

Se si gestisce tutto in modo asincrono non bloccante l‚Äôapproccio diventa single-thread:

![single tier](./img/img96.png)

Quando si interoga il DB, si passa la query e si definisce la funzione di callback da invocare nel momento in cui arriva il risultato. La chiamata non diventa bloccante poich√© la query verr√† eseguita in background e nel momento in cui il risultato √® disponibile invoca la `doSomething` per gestire l‚Äôevento e verr√† inserito l'evento nello stack. La chiamata non √® bloccante e il processo pu√≤ subito fare qualcos‚Äôaltro. La CPU in questo modo √® sempre occupata a fare qualcosa. In questo caso non si paga l‚Äôoverhead del context switch.

√à importante che la funzione di callback non richieda molto tempo per l‚Äôesecuzione. I task CPU intensive vanno contro al modello stesso e possono portare a ritardi consistenti e blocchi, non garantendo pi√π la concorrenza. Il tutto funziona bene dal momento che la computazione √® parcellizzata in modo corretto, con task che eseguono concorrentemente, senza che nessuno di questi si appropri per troppo tempo della risorsa e ritardi l‚Äôesecuzione di tutti gli altri.

![single tier](./img/img97.png)

Per eseguire operazioni come il processamento di DB, letture di file da file system, ci sono dei thread dedicati ma il suo numero √® molto inferiore a quello che si avrebbe adottando un approccio basato su thread. Infatti, applicazioni JavaScript (di scripting in generale) in attesa su richieste I/O tendono a degradare significativamente performance. Per evitare blocking, Node.js utilizza la stessa natura event driven di JavaScript, associando callback alla ricezione di richieste I/O. Gli script Node.js in attesa su I/O **non** sprecano molte risorse (popped off dallo stack automaticamente quando il loro codice non-I/O related termina la sua esecuzione).

Viene esasperato il concetto di _server stateless_ perch√® il server non mantiene stato. Ogni evento viene messo sulla coda e l'event loop processa un evento indipendentemente dal precedente. Dato che √® costoso adottarlo in questo modello, se ci fosse bisogno di stato bisognerebbe usare i cookie e quindi lo si mantiene lato client side.

[Torna all'indice](#indice)

### Moduli

Con Node.js si pu√≤ lavorare a moduli. Questi moduli realizzano funzionalit√† e logica applicativa consentendo di non scrivere sempre lo stesso codice per la gestione delle callback e degli eventi. Il core di Node.js consiste di circa una ventina di moduli, alcuni di pi√π basso livello come per la gestione di eventi e stream, altri di pi√π alto livello come HTTP.

[Torna all'indice](#indice)

#### Modulo HTTP

Il modulo pi√π usato √® HTTP. Il modulo viene caricato tramite la `require`:

```
// carica il modulo http per creare un http server
var http=require('http');
// configura HTTP server per rispondere con Hello World
var server=http.createServer(function(request,response) {
    response.writeHead(200, {"Content-Type":"text/plain"});
    response.end("Hello World\n");
});
// ascolta su porta 8000
server.listen(8000);
// scrive un messaggio sulla console terminale
console.log("Server running at http://127.0.0.1:8000/");
```

Si pu√≤ richiedere la creazione di un HTTP server che sia in grado di rispondere con un `Hello World` e si pu√≤ invocare questo server, il tutto √® gestito con funzioni non bloccanti ed √® in grado di reagire generando una richiesta HTTP quando riceve una richiesta. A questo punto si pu√≤ mettere in ascolto il servitore sulla posta 8000 che √® pronto a rispondere.

[Torna all'indice](#indice)

#### NPM

Il core di Node.js √® stato progettato per essere piccolo e snello, i moduli che fanno parte del core si focalizzano su protocolli e formati di uso comune. Per ogni altra cosa, si usa NPM: chiunque pu√≤ creare un modulo Node con funzionalit√† aggiuntive e pubblicarlo in NPM.

NPM √® un package manager di grande successo e in forte crescita, che semplifica sharing e riuso di codice JavaScript in forma di moduli. In generale √® preinstallato con distribuzione Node, esegue tramite linea di comando e permette di ritrovare moduli dal registry pubblico in http://npmjs.org.

[Torna all'indice](#indice)

#### Modulo FS

Il modulo di gestione dei file si chiama FS. Una volta caricato il modulo con la `require` si pu√≤ effettuare la `read`, questo scatena la lettura e si passa la funzione che dovr√† essere scatenata e per leggere il file. Notare che in Node.js il primo parametro √® sempre quello di errore il secondo √® il contenuto del file. Il file deve essere piccolo perch√© altrimenti l‚Äôoperazione di console diventerebbe troppo lunga e bloccherebbe l‚Äôevent loop.

```
var fs = require("fs");
// modulo fs richiesto oggetto fs fa da wrapper a chiamate bloccanti sui file
// read() a livello SO √® sincrona bloccante mentre
// fs.readFile √® non-bloccante
fs.readFile("smallFile", readDoneCallback); // inizio lettura

function readDoneCallback(error, dataBuffer) {
    // convenzione Node per callback: primo argomento √® oggetto
    // js di errore
    if (!error) { 
        console.log("smallFile contents", dataBuffer.toString());
    }
}
```

[Torna all'indice](#indice)

#### Modulo Stream

Node.js contiene moduli che producono/consumano flussi di dati (stream), questo pu√≤ essere modo utile per strutturare server, per elaborare contenuti di grosse dimensioni e spezzare il carico in arrivo, per il modello concorrente √® importante che non vi siano task pensanti. Stream supporta la gestione di flussi di dati utile per lavorare con file di grosse dimensioni, stream a livello di rete. Questi stream possono essere elaborati e trasformati dinamicamente. Si possono costruire stream anche dinamicamente e aggiungere moduli sul flusso. Ad esempio stream.push(Encryption). Vi sono diversi tipi di stream: Readable stream (es: fs.createReadStream), Writable stream (es. fs.createWriteStream), Duplex stream (es. net.createConnection), Transform stream (es. zlib, crypto).

Per la lettura nel caso di stream si lavora con file di grandi dimensioni. Si crea un read stream e si lavora ad evento sul quale possiamo registrare un listener che viene invocato all‚Äôarrivo di ciascun chunk di file:

```
var readableStreamEvent = fs.createReadStream("bigFile"); 
readableStreamEvent.on('data', function (chunkBuffer) { console.log('got chunk of', chunkBuffer.length, 'bytes'); }); 
//operazione eseguita ogni volta che arriva un chunck di dati

readableStreamEvent.on('end', function() { 
    // Lanciato dopo che sono stati letti tutti i datachunk fine dello stream
    console.log('got all the data');
}); 

readableStreamEvent.on('error', function (err) { 
    console.error('got error', err);
});
//gestione a evento dell‚Äôerrore
```

Listener √® la funzione da chiamare quando l'evento associato viene lanciato, mentre Emitter √® il segnale che un evento √® accaduto. L‚Äôemissione di un evento causa invocazione di TUTTE le funzioni listener. In seguito a emit, i listener sono invocati in modo sincrono-bloccante e nell‚Äôordine con cui sono stati registrati. Senza listener non sono possibili operazioni.

Per quanto riguarda la scrittura √® possibile creare uno stream output. Quando viene terminata l‚Äôoperazione di scrittura viene emesso l‚Äôevento di fine end. Una volta invocata l‚Äôoperazione di scrittura sar√† anche emesso un evento di fine della scrittura che pu√≤ essere recuperato e aggiunto al log-file per capire se la scrittura √® andata a buon fine:

```
var writableStreamEvent = fs.createWriteStream('outputFile‚Äô);
writableStreamEvent.on('finish', function () {
    console.log('file has been written!');
});

writableStreamEvent.write('Hello world!\n');
writableStreamEvent.end();
```

[Torna all'indice](#indice)

#### Modulo Net

Esiste un modulo di rete Node.js, chiamato Net, che fa da wrapper per le chiamate di rete di SO, include anche funzionalit√† di alto livello, come:

```
var net = require('net‚Äô); 
net.createServer(processTCPconnection).listen(4000); 
```

Crea una socket per una connessione TCP, fa binding del server su una porta (4000 in questo caso) e si mette in stato di listen per connessioni, per ogni connessione TCP, invoca la funzione `processTCPconnection`:

```
// lista di client connessi
var clients = [];
function processTCPconnection(socket) {

    // aggiunge il cliente alla lista
    clients.push(socket);
    socket.on('data', function (data) {
        // invia a tutti i dati ricevuti
        broadcast("> " + data, socket);
    });

    socket.on('end', function () {
        // remove socket
        clients.splice(clients.indexOf(socket), 1);
    });

}

// invia messaggio a tutti i clienti
function broadcast(message, sender) {

    clients.forEach(function (client) {
        if (client === sender)
        return;
        client.write(message); 
    });
}
```

La funzione `processTCPConnection` aggiunge la lista di clienti connessi alla socket. Dopo di che all‚Äôarrivo dei dati questi possono essere elaborati. In questo caso all‚Äôarrivo di un nuovo dato viene invocata la funzione di callback function, successivamente vengono inviati in broadcast tutti i dati ricevuti. Infine, con il broadcast tutti i dati vengono inviati ai vari clienti con la funzione broadcast. L‚Äôaltro evento importante √® la fine della connessione per rimuovere la connessione dalla lista dei client una volta terminata la connessione stessa, ancora una volta tutto √® gestito in callback.

[Torna all'indice](#indice)

#### Modulo Express

Express.js √® il framework pi√π utilizzato oggi per lo sviluppo di applicazioni Web su Node.js, molto flessibile e con ottime performance e consente di utilizzare diverse opzioni e motori di templating. Mette a disposizione eseguibili per rapida generazione di applicazioni ed √® ispirato e basato sul precedente `Sinatra`:

```
var express=require('express‚Äô);
var app=express();
app.get('/', function(req,res) {res.send('Hello World!‚Äô); }); 
var server=app.listen(3000,function() {
    var host=server.address().address;
    var port=server.address().port;
    console.log('Listening at http://%s:%s',host,port);
});
```

Codice per attivare il server web e restituisce un `Hello World!` relativo alla pagina di ingresso.

[Torna all'indice](#indice)

## Docker

Microservizi e container costituiscono un‚Äôalternativa pi√π moderna al tradizionale modello software basato sull‚Äôarchitettura monolitica.

[Torna all'indice](#indice)

### Microservizi

Per avere applicazioni molto portabili e scalabili √® importante esprimerle in termini di micro-servizi, ovvero piccoli componenti che compongono un‚Äôapplicazione distribuita costituita da servizi deploiabili separatamente che eseguono funzioni specifiche di business e comunicano con interfacce web. I micro-servizi sono piccoli blocchi di codice riutilizzabili che compongono l‚Äôapplicazione. L‚Äôobiettivo √® quello di rendere l‚Äôapplicazione scalabile e meno sottoposta all‚Äôincremento del tempo necessario al deployment nell‚Äôambiente dei DevOps.

![single tier](./img/img98.png)

Il vantaggio enorme introdotto da tale paradigma di programmazione √® tangibile in termini di scalabilit√† dell‚Äôapplicazione e relative performance, in termini di fault tolerance e manutenibilit√† dell‚Äôapplicazione stessa. Al contrario, in una applicazione monolitica √® necessario replicare tutta l‚Äôapplicazione quando magari solo una funzionalit√† di questa √® un collo di bottiglia per le performance. Con la suddivisione e in micro-servizi si pu√≤ replicare solo il micro-servizio che fa da collo di bottiglia. Questo √® molto interessante in un‚Äôarchitettura orizzontale dove si replicano sui vari host solo i servizi pi√π richiesti.

![single tier](./img/img99.png)

Le applicazioni monolitiche hanno una cos√¨ detta struttura a silos con una parte di applicazione e una parte di database. VI √® una fase intermedia detta Internally Componentized Application, visibile in framework come EJB dove i container accedono a un unico database, per poi passare all‚Äôarchitettura a micro-servizi ogni servizio ha la sua parte di database replicata. Questo concetto che pu√≤ inizialmente sembrare controintuitivo in realt√† aumenta molto la scalabilit√† del sistema poich√© il database relazionale pu√≤ diventare un collo di bottiglia negli accessi nelle letture e scritture consistenti. Inoltre, non vi √® pi√π un single point of failure quindi in caso di crash del database di un micro-servizio gli altri rimangono up and running senza essere affetti dal fallimento del singolo. Infine, si pu√≤ utilizzare il tipo di storage migliore per la necessit√† del servizio, per esempio storage relazione o non relazionali etc.

[Torna all'indice](#indice)

### DevOps

Legato al mondo dei micro-servizi vi √® quello dei DevOps. I DevOps garantiscono uno sviluppo agile dell‚Äôapplicazione consentendo di unire la parte applicativa a quella infrastrutturale, velocizzando il processo di cambiamento e correzione delle applicazioni. L‚Äôidea di mettere insieme micro-servizi e DevOps sopraggiunge per la necessit√† di preparare l‚Äôambiente per controllare le nuove release, installarle, verificarle e poter facilmente tornare indietro, garantendo QoS consistenza ed evitando crash e altri problemi.

I DevOps vanno nella direzione del continuo ciclo di sviluppo, seguendo le fasi di Design Build Deploy teste e Release senza mai fermarsi in un ciclo infinito. Per questo un‚Äôapplicazione pu√≤ continuamente essere aggiornata durante la sua esecuzione senza la necessit√† di interrompere o interferire con l‚Äôattuale versione. Il continuo processo di test e rilascio √® per struttura pi√π semplice da utilizzare in un‚Äôapplicazione a micro-servizi.

[Torna all'indice](#indice)

### Container

Il container √® la piattaforma per il micro-servizio. Il container √® un artefatto che si porta dietro tutto il necessario per l‚Äôesecuzione del micro-servizio, non sono necessari altri supporti esterni. I micro-servizi possono essere contenuti in un container che diventa un modo per trasportare il micro-servizio da una parte ad un‚Äôaltra. Un‚Äôaltra caratteristica fondamentale √® che sia auto-contenuto ovvero contiene la logica applicativa, tutta a parte di deployment e operation garantendo la correttezza dell‚Äôesecuzione. Il container richiama sia il concetto sia auto contenimento che di standardizzazione. Il container, quindi, √® in grado di contenere il micro-servizio e tutto il suo supporto dato dai DevOps.

![single tier](./img/img129.png)

Da un punto di vista tecnico si possono mettere a confronto i container con le macchine virtuali. I container al contrario delle macchine virtuali consentono di non avere pi√π il sistema operativo guest in ciascuna virtualizzazione, ma tale sistema operativo si trova al di sopra dell‚Äôinfrastruttura. Per la gestione dei container vi √® un container engine che poggia sul sistema operativo e garantisce l‚Äôisolamento dei container e da la visione al container di avere accesso diretto alle chiamate del sistema operativo e alle risorse. Quindi, il container engine crea spazi isolati per i container dandogli l‚Äôastrazione necessaria rispetto al sistema operativo. Dal punto di vista delle performance i container sono molto pi√π veloci per l‚Äôavvio di un container si parla di centesimi di secondi/secondi, mentre per una virtual machine di grosse dimensioni di minuti. L‚Äôisolamento del container a livello di SO garantisce l‚Äôisolamento delle risorse, poich√© il container vede il SO come se fosse suo e della sicurezza. Dal punto di vista delle risorse, i container le percepiscono isolate anche se alcune risorse come networking memoria etc non sono semplici da isolare.

![single tier](./img/img100.png)

Dal punto di vista del marketing la containerizzazione ha avuto un grande successo poich√© risolve a tutti gli effetti il problema _non funziona su questa macchina_, poich√© il container risolve tutte le dipendenze oltre che a fornire il servizio preposto, √® leggero perch√© condivide il kernel con altri container ed esegue come processo isolato. Inoltre, ha una maggiore efficienza rispetto alla virtual machine nei processi di lettura e scrittura, inoltre con l‚Äôutilizzo di immagini si hanno servizi facilmente riproducibili e scalabili.

I container sono la giusta piattaforma per un micro-servizio, poich√© sono soluzioni leggere e virtualizzate oltre ad essere corretti, auto contenuti e ben isolati, sono in grado allo stesso tempo di condividere le parti di supporto interne al kernel del sistema operativo e non sono specifici per una piattaforma per questo sono estremamente portabili. Infine, possono ospitare i micro-servizi e le loro applicazioni con tutte le loro parti e le loro dipendenze.

[Torna all'indice](#indice)

### Docker

Docker √® un insieme di tool che facilita la gestione di container, inizialmente lavorava solo su Linux ma al momento funziona anche su Windows, √® molto diffuso a partire dal 2013 anno di creazione del progetto.

Docker offre molti strumenti non solo per ospitare container ma anche per gestirli, controllare le migrazioni dei componenti e le loro immagini. Infatti, √® molto utile per indicare cosa installare e i componenti da utilizzare. I micro-servizi possono essere ospitati e controllati dal container facilmente. Docker pu√≤ consigliare come progettare e pacchettizzare componenti autonomi. Inoltre, i container offrono la possibilit√† di accedere con funzioni web ai micro-servizi ospitati, instandoli e reinstallandoli facilmente. Per Docker basta utilizzare una piattaforma hardware, il sistema operativo, le librerie di sistema e le dipendenze dei processi durante la fase di sviluppo test e produzione del software. Dal punto di vista dell‚Äôingegneria del software, in cui si √® passati da un concetto di applicazione a quello di servizio, il processo di creazione viene basato nella realizzazione sui container e sullo sviluppo con i DevOps.

![single tier](./img/img101.png)

I componenti dell'insfrastruttura sono: cliente, host, registry (repository).

Il Docker daemon gestisce i componenti Docker come ad esempio le immagini. Il Docker Client √® la parte utilizzata dagli utenti per interagire con Docker Daemon, in particolare pu√≤ utilizzare comandi, come `docker run` che avvia il container. I Docker registry salvano le immagini mentre Docker Hub e Docker Cloud sono registry pubblici. A default, Docker cerca immagini su Docker Hub si pu√≤ eventualmente anche eseguire un registry personale. I registry sono i componenti di distribuzione per Docker.

I Docker container contengono tutto ci√≤ che √® necessario ad un‚Äôapplicazione per eseguire e l‚Äôapplicazione stessa, sono simili a una directory in quanto il container in esecuzione vede un file system proprio e isolato risptto al resto, dove sono presenti tutti i componenti necessari ad eseguire l‚Äôapplicazione e sono creati a partire da un‚Äôimmagine Docker. Gli stati possibili per un container Docker sono: `run`, `started`, `stopped`, `moved`, e `deleted`. I container sono i _run components_ di Docker.

[Torna all'indice](#indice)

### Gestione del ciclo di vita del container

La figura seguente mostra i passi della gestione del ciclo di vita del container:

![single tier](./img/img102.png)

Registry locale o remoto da cui richiedere e scaricare immagini con operazione di `pull`, oppure inviare aggiornamenti delle immagini presenti con l‚Äôoperazione di push. Inoltre, √® presente un backup locale in cui salvare immagini con `save` o caricarle con `load`. Le immagini possono essere istanziate sul container con il comando di `run`, di seguito il container pu√≤ essere avviato con `start`, fermato con `stop` oppure riavvito con `restart`. Se vengono effettuati cambiamenti di configurazioni aggiunta di librerie nel filesystem con la `commit` si pu√≤ aggiornare l‚Äôimmagine ed eventualmente aggiungere nuove informazioni attraverso tag. Il DockerFile in modo assertivo enuncia delle direttive che attraverso l‚Äôoperazione di build consentono di creare nuove immagini.

[Torna all'indice](#indice)

### Immagini Docker

La gestione delle immagini in Docker √® automatizzata e ottimizzata. Le immagini create sono organizzate su layer poich√© si utilizza una logica di composizione, che consente una volta creata un‚Äôimmagine di accedervi in sola lettura, ogni immagine √® read-only, per ogni modifica in scrittura viene aggiunto un nuovo layer all‚Äôimmagine senza modificare il layer precedente questo approccio √® detto copy-on-write. In sintesi, si lavora per differenze ogni nuovo layer aggiunge le differenze rispetto al layer precedente. L‚Äôimmagine finale √® la somma di tutti i layer creati per quell‚Äôimmagine. Ogni layer √® univocamente identificato da un hash con l‚Äôalgoritmo SHA-256 crittograficamente sicuro per l‚Äôidentificazione dell‚Äôimmagine. Se sono gi√† stati scaricati layer per un‚Äôimmagine **non** sar√† necessario scaricarli nuovamente, dovranno essere scaricati unicamente i layer mancanti per una determinata immagine. Nel Docker Daemon viene fatto caching di layer e questo evita di scaricare nuovamente gli stessi layer garantendo un grande vantaggio in termini di efficienza nell‚Äôutilizzo del disco e facilit√† nella modifica.

![single tier](./img/img103.png)

Convenzioni per il naming delle immagini, devono essere indicati il nome dell‚Äôhost nei registry e la porta, username, reponame ed eventuali tag:

```
[hostname[:port]]/[username]/reponame[:tag]
```

Il DockerFile √® un file di configurazione che serve per definire e creare nuove immagini. Il `run` nel DockerFile √® una direttiva per lanciare le configurazioni e il software. Facilita la configurazione dell‚Äôimmagine e la crea. Il DockerFile presente parte da due immagini preesistenti che vengono modificate, con l‚Äôaggiunta di layer software vengono aggiunti layer all‚Äôimmagine stessa:

![single tier](./img/img104.png)

Docker non √® solo un insieme di strumenti ma un framework che pu√≤ lavorare ad eventi nella gestione dei container in esecuzione. Il programmatore pu√≤ intercettare tutti gli eventi del container:

![single tier](./img/img105.png)

Docker possiede molti plugin tra questi sono molto importanti i plugin di rete e per questo Docker consente di connettere risorse e container all‚Äôesterno e all‚Äôinterno, gestione dei volumi etc. Un‚Äôaltra parte importante √® la persistenza prevede diverse modalit√†, come montare un‚Äôarea di memoria vedendola come un file system ovvero uno storage virtuale persistente (sar√† realizzato in memory), d√† la possibilit√† di vedere il file system locale ospitante, oppure di avere una sandbox detta Docker Area che limita lo spazio di visibilit√† per il container.

Queste configurazioni avanzate vengono indicate nel Docker Compose, file che configura il deployment. Ad esempio, come lanciare il container, la porta disponibile, come comunicano. Con il Docker Compose si agisce solo in locale, quindi, possono essere utilizzate immagini remote, ma prima devono essere scaricate in locale.

Per quanto riguarda la scalabilit√†, si usa Docker Swarm, che √® un orchestratore di risorse container, √® un engine che elabora degli script di configurazione. L'allocazione di Docker Swarm √® statica, per questo motivo se bisogna aumentare le risorse non si riesce e quindi, non si ottiene scalabilit√†. L'utente dovrebbe richiedere tramite deployment nuove istanze ma il tutto √® gestito in modo statico.

[Torna all'indice](#indice)

## Kubernetes

Kubernetes √® un orchestratore di container compatibile con Docker, la gestione dei container √® dinamica e non statica, questo gli consente di offrire molte pi√π funzionalit√† rispetto a Docker Swarm. Kubernetes √® pensato per lavorare in ambienti cloud, infatti da una parte, quella interna, √® un orchestratore di container dall‚Äôaltra parte esternamente si interfaccia con i Virtual Infrastructure Manager, ovvero con i controllori di API Rest, che dispongono i cloud provider per poter andare prendere le risorse che servono per formare l‚Äôinfrastruttura fisica su cui distribuire i container. Questo strumento facilita molto la migrazione dei container da un‚Äôambiente locale a uno pi√π largo come il cloud. I benefici sono la gestione fine grained e dinamica rispetto a tutte le problematiche di management come scaling e automatizzazione del rollout e del rollback. Una volta sviluppata una nuova versione √® possibile mandare ovunque in produzione e tornare indietro senza problemi in caso di bug o errori. Kubernetes consente di effettuare il rollback facilmente. Poi vi √® la gestione dello scaling con la possibilit√† di scaling intelligente fine grained e definibile dal programmatore e non solo con Round Robin, poi vi √® tutta la parte di fault tolerance e la possibilit√† di portare i carichi su cloud diversi.

L‚Äôobiettivo principale di Kubernetes √® nascondere la complessit√† di gestione di grandi quantit√† di container fornendo agli utilizzatori un set di API Rest. Kubernetes √® estremamente protabile, infatti, si interfaccia con tutte le principali Cloud Platform private o pubbliche come Amazon AWS, Azure, Openstack, o resource manager come Apache Mesos. Per un orchestratore del genere √® fondamentale fornire il deployment di applicazioni multi-container, garantire la continuit√† dei servizi grazie alla sua gestione di fault tolerance, rollback e rollout, scalare autonomamente e dinamicamente le applicazioni e rendere tutta l‚Äôarchitettura indipendente dall‚Äôinfrastruttura sottostante.

[Torna all'indice](#indice)

### Architettura

L‚Äôarchitettura di Kubernetes √® abbastanza complessa: prevede di avere una serie di nodi worker chiamati Node all‚Äôinterno dei quali sono istanziati i container. Questi nodi sono controllati da diversi componenti di controllo racchiusi nel Control Plane, ognuno di loro √® dotato di un agente locale Kubelet per interagire con il Control Plane e una parte per la comunicazione detto kube-proxy. L‚Äôarchitettura ha componenti tipici del cloud come il componente API, oppure gli agenti locali su tutti i nodi presenti che consentono di gestire il ciclo di vita dei container. La parte di controllo attraverso il cloud controller manager parla con un cloud provider pubblico attraverso le Cloud Provider API.

![single tier](./img/img106.png)

L‚Äôarchitettura √® di tipo master-slave. Il nodo master pu√≤ essere uno o pi√π di uno, poich√© viene replicato al fine della fault tolerance, le repliche per√≤ agiscono come un componente solo. L‚Äôetcd rappresentato come un database √® l‚Äôunico componete che mantiene lo stato dell‚Äôinfrastruttura. Lo stato √® mantenuto il pi√π locale possibile e auto contenuto per evitare di creare delle dipendenze nel distribuito fra le varie macchine, in questo modo tutte le macchine worker possono agire anche nel caso in cui momentaneamente perdano la connettivit√† con il controller per garantire il massimo disaccoppiamento e asincronicit√† possibile. Infine, vi √® il client che pu√≤ richiedere le funzionalit√† di Kubernetes per effettuare il deployment delle applicazioni.

![single tier](./img/img107.png)

[Torna all'indice](#indice)

### Etcd 

L'etcd √® un archivio chiave-valore distribuito fortemente consistente che fornisce un modo affidabile per memorizzare i dati a cui √® necessario accedere da a sistema distribuito o cluster di macchine. Gestisce le elezioni dei _leader_ durante le partizioni di rete e pu√≤ tollerare il guasto della macchina, anche nel nodo master.

[Torna all'indice](#indice)

### Controller Manager

Il controller manager Kubernetes √® un demone che incorpora i loop di controllo principali gestiti con Kubernetes. In Kubernetes, un controller √® un loop di controllo che osserva lo stato condiviso del cluster attraverso l'API server e apporta modifiche tentando di spostare lo stato corrente verso lo stato desiderato. Esempi di controller forniti oggi con Kubernetes sono il controller di replica, controller degli endpoint, controller dello spazio dei nomi e controller degli account di servizio.

[Torna all'indice](#indice)

### Cloud Controller Manager

Il cloud-controller-manager √® un componente del Control Plane di Kubernetes che incorpora la logica di controllo specifica del cloud. Il cloud-controller-manager consente di fra interagire il cluster a quello del provider cloud API e separa i componenti che interagiscono con quella piattaforma cloud da componenti che interagiscono solo con il cluster. Disaccoppiando la logica di interoperabilit√† tra Kubernetes e l‚Äôinfrastruttura cloud sottostante il componente cloud-controller-manager abilita il cloud provider a rilasciare funzionalit√† a un ritmo diverso rispetto al progetto Kubernetes. Il cloud-controller-manager √® strutturato utilizzando un meccanismo di plug-in che consente l‚Äôintegrazione delle piattaforme di diversi provider cloud con Kubernetes.

[Torna all'indice](#indice)

### Kubelet

Il kubelet √® il principale node agent che esegue su ogni nodo, questo componente logico pu√≤ registrare il nodo con l'APIserver. Il kubelet funziona in termini di PodSpec, un PodSpec √® un oggetto YAML o JSON che descrive un pod. Di conseguenza il kubelet accetta una serie di PodSpec forniti attraverso vari meccanismi (principalmente tramite l'apiserver) e assicura che i container descritti in quelle PodSpecs siano running e in salute.

[Torna all'indice](#indice)

### Pod

Un Pod √® un'astrazione Kubernetes che rappresenta un gruppo di uno o pi√π application container (come Docker) e alcune risorse condivise per quei container. Tali risorse includono: archiviazione condivisa, come volumi, networking, come indirizzo IP cluster univoco ed informazioni su come eseguire ciascun contenitore, come la versione dell'immagine del contenitore o specifiche porte da usare. Un pod modella un host logico specifico dell'applicazione e pu√≤ contenere diverse application container che sono strettamente accoppiati.

Per esempio, il pod potrebbe includere sia il contenitore che il Node.js e un container diverso che alimenta i dati da pubblicare dal Node.js web server. I container in un pod condividono l‚Äôindirizzo IP e lo spazio delle porte, sono sempre co-localizzati e co-schedulati, ed eseguiti in un contesto condiviso sullo stesso nodo.

I pod sono l'unit√† atomica sulla piattaforma Kubernetes: quando creiamo una distribuzione su Kubernetes, che la distribuzione crea pod con container al loro interno (invece di creare direttamente i container). Ogni Pod √® legato al nodo in cui √® programmato e vi rimane fino alla cessazione o cancellazione. In caso di guasto di un nodo, i Pod identici sono schedulati su altri nodi disponibili nel cluster.

[Torna all'indice](#indice)

### Service

I service sono un modo astratto per esporre un'applicazione in esecuzione su un set di podin comunicazione uno con l‚Äôaltro per erogare il service. I pod vengono creati e distrutti per corrispondere allo stato del cluster. Ogni Pod ottiene il proprio indirizzo IP, tuttavia il set di pod in esecuzione in un momento specifico pu√≤ essere diverso. I service sono astrazioni che definiscono un insieme logico di pod e una policy con cui accedervi.

[Torna all'indice](#indice)

### Kube proxy

Il proxy di rete Kubernetes viene eseguito su ciascun nodo worker. Espone i service definiti come indicato nell‚ÄôAPI Kubernetes su ogni nodo e fa un semplice inoltro di flusso TCP, UDP e SCTP o round Robin TCP, UDP e inoltro SCTP attraverso un insieme di backend.  Gli IP e le porte del cluster di servizio sono ritrovati attraverso un ambiente compatibile con i Docker-links, variabili che specificano le porte aperte dal proxy service. C'√® un componente aggiuntivo opzionale che fornisce DNS cluster per questi IP cluster. L'utente deve creare un servizio con l'apiserver API per configurare il proxy.

Stub locale che abilita tutta la parte di comunicazione. Uno per nodo che poi abilita tutte le comunicazioni di quel nodo.

[Torna all'indice](#indice)

### Scheduler

Lo scheduler √® la parte del controllo che si occupa dello scheduling, controlla la creazione dei Pod e trova il nodo migliore per ospitare quel Pod. Filtra i nodi per verificare quale soddisfi i requisiti di programmazione specifici per quel Pod. Se non ci sono nodi adatti, il Pod rimane non schedulabile. Per ogni nodo adatto e utilizzabile, lo Scheduler stima un punteggio eseguendo una serie di funzioni, il Pod √® schedulato sul nodo adatto con il pi√π alto punteggio, lo scheduler quindi notifica al server API questa decisione in un processo chiamato binding.

[Torna all'indice](#indice)

### Volumi

Kubernetes supporta diversi tipi di volumi. Due tipi principali sono: i tipi di volume effimero, questi hanno la durata di un Pod, quando un Pod cessa di esistere, Kubernetes distrugge i volumi effimeri. I volumi persistenti che esistono oltre la durata di un Pod, Kubernetes non distrugge i volumi persistenti. Per qualsiasi tipo di volume in un dato Pod, i dati vengono conservati durante i riavvii del contenitore. Al suo interno, un volume √® una directory accessibile ai container in un Pod. Massima interoperabilit√† con gli strumenti preesistenti quindi con tutti gli storage anche cloud.

[Torna all'indice](#indice)

### Network

Non andando nel dettaglio sulla rete, si ricorda che la gestione della rete pu√≤ essere anche piuttosto complessa in Kubernetes, poich√© vi sono i Pod che si mostrano internamente con indirizzi privati, che per√≤ utilizzando indirizzi di rete possono essere messi in comunicazione con altre macchine, anch‚Äôesse con una interfaccia di rete. Tutti i mapping per far comunicare le macchine sono gestite dal networking di Kubernetes.

[Torna all'indice](#indice)

### Modello dichiarativo

In Kubernetes, il modello dichiarativo funziona in questo modo:

- Dichiarare lo stato (dal punto di vista del deployment) desiderato delle applicazioni (microservizi) in un file manifest.
- Pubblicare lo stato sul server API Kubernetes.
- Kubernetes memorizza lo stato nell'etcd (cluster store) come stato desiderato dall'applicazione.
- Kubernetes implementa lo stato desiderato sul cluster.
- Kubernetes implementa i loop, attraverso il kube-controller-manager, per assicurarsi che lo stato attuale dell'applicazione non vari dallo stato desiderato.

[Torna all'indice](#indice)

### Concetti di base di Kubernetes

### Pod

Nel mondo Kubernetes, l'unit√† atomica di programmazione √® il Pod. Non √® possibile eseguire un container direttamente su un Kubernetes cluster come in Docker, il container deve sempre essere eseguito all'interno di Pods. Anche se √® possibile eseguire pi√π contenitori all'interno dello stesso Pod, ogni Pod ospita solitamente un contenitore. I Pod sono anche l'unit√† minima di ridimensionamento, se fosse necessario ridimensionare un‚Äôapp, si aggiungono o si rimuovono Pod. Non si scala l‚Äôapplicazione aggiungendo pi√π contenitori a un Pod esistente. I Pod sono mortali e quindi sono inaffidabili. Quando un Pod si interrompe in modo imprevisto, Kuberntes non lo riporter√† in vita, ma ne inizializza uno nuovo al suo posto.

[Torna all'indice](#indice)

### Service

Per superare l'inaffidabilit√† dei Pod entrano in gioco i Servizi. I servizi forniscono una rete affidabile per una serie di Pod. I servizi hanno un front-end che consiste in un nome DNS stabile, un indirizzo IP e una porta. Sul back-end viene eseguito il bilanciamento dinamico su un set di Pod. I Pod vanno e vengono, il Service osserva i cicli di vita dei Pod e si aggiorna automaticamente, nel frattempo continua a fornire l'endpoint di rete stabile. La mappatura tra Service e Pod viene eseguita tramite label e selettori di label.

[Torna all'indice](#indice)

### Deployment

I Pod non si auto-riparano, non si ridimensionano e non consentono facili aggiornamenti o rollback. I deployment si occupano di tutto questo, perci√≤ i Pod sono eseguiti e gestiti grazie al deployment. Un unico deployment pu√≤ gestire solo un singolo tipo di Pod. Ad esempio, se √® presente un'app con un Pod per il frontend web e un altro Pod per il backend, ci sar√† bisogno bisogno di due implementazioni. Dietro le quinte, i deployment sfruttano un altro oggetto chiamato set di repliche. Le distribuzioni utilizzano i set di repliche per fornire self-healing e scalabilit√†.

[Torna all'indice](#indice)

### Kubernetes Storage

Kubernetes ha un sottosistema di archiviazione ricco di funzionalit√†. Indipendentemente dal tipo di spazio di archiviazione di cui si dispone e da dove proviene, quando questo viene esposto nel cluster √® detto Volume. Il sottosistema di volumes persistenti di Kubernetes √® un insieme di oggetti API che consentono alle app di utilizzare spazio di archiviazione. Ad alto livello, i Persistent Volumes (PV) sono il modo utilizzato per mappare lo storage esterno sul cluster, le Persistent Volume Claims (PVC) sono come i biglietti che autorizzano le applicazioni (Pod) a utilizzare un PV.

[Torna all'indice](#indice)

### Daemons set

Sono utili quando √® necessaria una replica di un particolare Pod in esecuzione su ogni nodo del cluster. Alcuni esempi includono i Pod di monitoraggio e la registrazione dei Pod.

[Torna all'indice](#indice)

### Jobs and Cronjobs

Sono utili quando √® necessario eseguire un determinato numero di un particolare Pod e bisogna garantire che andranno a buon fine.

[Torna all'indice](#indice)

### Spazio dei nomi

Un cluster virtuale (un singolo cluster fisico pu√≤ eseguire pi√π cluster virtuali) destinato ad ambienti con molti utenti si diffonde in pi√π team o progetti, per isolare i problemi. Inoltre, a uno spazio dei nomi pu√≤ essere assegnata una quota di risorse per evitare di consumare pi√π delle risorse complessive  presenti nel cluster fisico.

Per vedere in piccolo il funzionamento di Kubernetes si pu√≤ utilizzare Minicube. Minicube √® uno strumento che semplifica l‚Äôesecuzione di Kubernetes in locale, √® un cluster con un singolo nodo all‚Äôinterno di una Virtual Machine.

[Torna all'indice](#indice)

### Cluster initialization

```
$ minikube start 
$ kubectl cluster-info
Kubernetes master is running at https://192.168.99.100:8443 CoreDNS is running at https://192.168.99.100:8443/api/v1/namespaces/kubesystem/services/kube-dns:dns/proxy 
```

```
$ kubectl get nodes
NAME STATUS ROLES AGE VERSION
minikube Ready master 40d v.1.10.0
```

Launch Dashboard

```
$ minikube dashboard
```

[Torna all'indice](#indice)

## FaaS

Cos√¨ come l‚Äôinternet wireless ha dei cavi da qualche parte, le architetture serverless continuano ad avere dei server da qualche parte. Come sviluppatore, non bisogna pensare a questi server ma ci si focalizza solo sul codice. Il serverless consente di costruire ed eseguire applicazioni e servizi senza preoccuparsi di scalare i server. Ci√≤ che serve all‚Äôesecuzione √® gestito implicitamente.

In un‚Äôapplicazione serverless, il supporto lavora a callback. Il programmatore non deve gestire con degli strumenti il deployment delle applicazioni. Il programmatore carica l‚Äôapplicazione su una piattaforma e non deve fare altro. Non esiste in s√® per s√® un server ma c'√® una piattaforma. In questo senso √® simile a map-reduce poich√© il programmatore implementa unicamente le funzioni di map e reduce. La parte di risorse √® gestita in automatico dalla piattaforma. Tutto il focus √® sulla business logic e non sulla gestione o sull‚Äôapprovvigionamento dell‚Äôinfrastruttura, non vi √® alcun costo relativo al controllo attivo di risorse e alla scalabilit√†.

[Torna all'indice](#indice)

### Serverless come Baas+FaaS

Analizzando le possibili soluzioni nel cloud, FaaS si trova tra piattaforma PaaS e software SaaS, quindi come un Back-end as a Service e Function as a Service (BaaS + FaaS). Ci si trova in questa zona perch√© l‚Äôidea √® quella di avere una serie di servizi di back-end e ci sia modo di concentrarsi solo sulla logica applicativa senza una conoscenza forte pregressa dei servizi di sistema. Ci sono delle API che facilitano lo sviluppo senza configurare il back-end e di configurarlo. Ad esempio, connessioni al database, configurazione del database etc.

![single tier](./img/img108.png)

Back-end as a Service (BaaS) significa esternalizzazione tutti i servizi di sistema mettendo a disposizione API per questi servizi (autenticazione, database, notifiche etc).

FaaS che consente di dichiarare la logica applicativa, funziona a eventi, la funzione si attiva all‚Äôarrivo di un evento da gestire e computare, restituisce un risultato e infine la funzione scompare. Le funzioni possono avere stato se questo √® mantenuto dal back-end, oppure se questo viene mantenuto lato client, ma non √® mai mantenuto all‚Äôinterno della FaaS. Le funzioni FaaS, infatti, sono stateless eseguono in ambienti effimeri e con una semantica-event driven. FaaS scala automaticamente e con grana fine.

[Torna all'indice](#indice)

### Architettura

Di seguito viene riportata una possibile architettura di riferimento:

![single tier](./img/img109.png)

Alla piattaforma FaaS arrivano richieste da diverse fonti e attraverso diverse richieste, il dispacher fa dispach presso i worker dell‚Äôevento, i worker eseguono la logica applicativa e restituiscono una risposta a seguito della computazione. Il vantaggio dal punto di vista del programmatore √® che non deve avere conoscenza dell‚Äôarchitettura, dal punto di vista del cloud abbiamo massima portabilit√† e leggerezza. Il problema per√≤, sono i vincoli legati alla piattaforma stessa poich√© se una funzione utilizza una quantit√† eccessiva di risorse e la sua computazione impiega troppo tempo, fa crollare le prestazioni complessive del sistema. Per questo Amazon e altri provider hanno dato limitazioni in termini di risorse (memoria) e tempo di utilizzo, quindi, ci sono vincoli temporali sulle esecuzioni oltre che sulle risorse che se non vengono rispettati portano alla uccisione di quella funzione che non causa problemi in quanto effimera.

Le risorse cloud oggi non sono pi√π unicamente disponibili in un punto geograficamente molto distante, ma sono distribuite in punti molto vicini in micro-datacenter. Ci√≤ prende il nome di edge computing. Pensando in questo caso al cloud computing come batch e dividendo in task molto piccoli il lavoro, se non vi sono vincoli stringenti di QoS si possono sfruttare le FaaS e pagare meno.

Tra le piatatforme emergenti open-source per FaaS vi sono OpenFaaS, OpenWhisk, Fission e Knative.

[Torna all'indice](#indice)

### OpenWhisk

Le caratteristiche principali sono:

 - Il gateway API NGINX prende tutte le richieste API da un client. Funge da punto di accesso.
 - Il controller, gestisce le richieste ed effettua il load balancing.
 - Apache Kafka √® un middleware MOM pub-sub che permette le comunicazioni asincrone ad eventi per massima asincronicit√† e disaccoppiamento forte delle richieste in arrivo rispetto all‚Äôesecuzione delle funzioni.
 - Invoker esegue le funzioni FaaS.
 - Apache CouchDB viene utilizzato per il salvataggio di funzioni parametri e risultati, √® molto scalabile in modo orizzontale.

![single tier](./img/img110.png)

Da notare come nelle nuove piattaforme si utilizzino sempre gli stessi modelli architetturali e strumenti gi√† ben noti nel cloud.

[Torna all'indice](#indice)

### Knative

Knative √® legato a Kubernetes, nasce con l‚Äôidea di avere la possibilit√† di spalmare i carichi di lavoro in workload che possono essere messi in esecuzione su Kubernetes che siano stateless. Con il deploy e il management, non √® propriamente una piattaforma FaaS, bens√¨ trasforma le risorse Kubernetes in workload serverless.

![single tier](./img/img111.png)

L‚Äôidea √® che Knative faciliti un deployment veloce di container serverless con scaling automatico. Per il networking e il routing si usa Istio che serve a gestire la comunicazione tra Pod Kubernetes. Sono possibili snapshot di configurazioni a runtime.

![single tier](./img/img112.png)

Dal punto di vista del disaccoppiamento dei servizi, i servizi vengono eseguiti runtime questi generano eventi che fungono da trigger per i servizi. Si ripensa completamente alla computazione, infatti, vi √® totale indipendenza tra consumatori e produttori, i nuovi servizi vengono eseguiti a runtime. CloudEvents come standard per la descrizione di eventi.

![single tier](./img/img113.png)

Dal punto di viste delle performance, queste piattaforme al di fuori degli eventi non lavorano benissimo, c‚Äô√® variabilit√† estrema nei tempi di valutazione della stessa FaaS anche sulla stessa piattaforma in questo senso.

[Torna all'indice](#indice)

## Confronto tra Tecnologie

<table>
  <tr>
    <th>Caratteristiche</th>
    <th>EJB 2.X</th>
    <th>EJB 3.X</th>
    <th>CCM</th>
    <th>Spring</th>
  </tr>
  <tr>
    <td>Container</td>
    <td>Pesante</td>
    <td>Pesante</td>
    <td>Pesante</td>
    <td>Leggero (con ApplicationContext si possono richiamare i metodi del container diventando un container pesante)</td>
  </tr>
  <tr>
    <td>Servizi</td>
    <td>Transazionalit√†, Messaggi, Persistenza</td>
    <td>Transazionalit√†, Messaggi, Persistenza</td>
    <td>Transazionalit√†, Messaggi, Persistenza</td>
    <td>Transazionalit√†, Messaggi, Persistenza</td>
  </tr>
  <tr>
    <td>Linguaggio</td>
    <td>Java</td>
    <td>Java</td>
    <td>Lavora con diversi tipi di linguaggi</td>
    <td>Java</td>
  </tr>
  <tr>
    <td>Componente</td>
    <td>Session Bean (calcolo computazionale), Message Driven Bean (attivazione per gestire messaggi), Entity Bean (dati del DB)</td>
    <td>Session Bean (calcolo computazionale), Message Driven Bean (attivazione per gestire messaggi)</td>
    <td>Rispetto a CORBA i componenti vengono distribuiti, Facet (interfacce offerte), Receptacle (quali interfacce si aspetta), Event Source, Event Sink </td>
    <td>Componenti non dipendono da Spring, classi POJO che diventano componenti Oggetti POJO </td>
  </tr>
  <tr>
    <td>Creazione nuovi componenti Lifecycle</td>
    <td>Creazione dell'interfaccia EJBHome (prima richiesta del cliente) e EJBObject (intercetta le chiamate successive) oppure EJBLocalHome e EJBLocalObject</td>
    <td>Interfaccia POJI, EJB Home e Object sono trasparenti non a carico del programmatore (vista pi√π moderna)</td>
    <td>Component Home che si fa carico del Lifecycle, contatto tra componente e container (diversi tipi di lifecycle management)</td>
    <td>Oggetti POJO utilizzabili grazie alla dependency injection (risolta dal container)</td>
  </tr>
  <tr>
    <td>Sviluppatore</td>
    <td>Conoscenza approfondita di EJB</td>
    <td>Conoscenza pi√π di alto livello</td>
    <td>Conoscenza approfondita di CCM</td>
    <td>Conoscenza pi√π di alto livello</td>
  </tr>
  <tr>
    <td>Intercettori</td>
    <td>Container nel mezzo</td>
    <td>Container nel mezzo</td>
    <td>Container nel mezzo</td>
    <td>AOP</td>
  </tr>
  <tr>
    <td>Annotazioni</td>
    <td>No</td>
    <td>Si</td>
    <td>No</td>
    <td>Si</td>
  </tr>
  <tr>
    <td>Deployment</td>
    <td>File XML</td>
    <td>Annotazioni e retrocompatibilit√† con file XML</td>
    <td>File XML</td>
    <td>Annotazioni e file XML</td>
  </tr>
</table>
